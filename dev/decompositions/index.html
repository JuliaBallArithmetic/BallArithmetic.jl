<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Matrix Decompositions · BallArithmetic.jl</title><meta name="title" content="Matrix Decompositions · BallArithmetic.jl"/><meta property="og:title" content="Matrix Decompositions · BallArithmetic.jl"/><meta property="twitter:title" content="Matrix Decompositions · BallArithmetic.jl"/><meta name="description" content="Documentation for BallArithmetic.jl."/><meta property="og:description" content="Documentation for BallArithmetic.jl."/><meta property="twitter:description" content="Documentation for BallArithmetic.jl."/><meta property="og:url" content="https://juliaballarithmetic.github.io/BallArithmetic.jl/decompositions/"/><meta property="twitter:url" content="https://juliaballarithmetic.github.io/BallArithmetic.jl/decompositions/"/><link rel="canonical" href="https://juliaballarithmetic.github.io/BallArithmetic.jl/decompositions/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">BallArithmetic.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Matrix Decompositions</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Recommended-Extensions"><span>Recommended Extensions</span></a></li><li><a class="tocitem" href="#SVD-Certification-Methods"><span>SVD Certification Methods</span></a></li><li><a class="tocitem" href="#Rigorous-vs-Non-Rigorous-Results"><span>Rigorous vs Non-Rigorous Results</span></a></li><li><a class="tocitem" href="#Other-Matrix-Decompositions-(100100-Matrix)"><span>Other Matrix Decompositions (100×100 Matrix)</span></a></li><li><a class="tocitem" href="#Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)"><span>Schur Complement Bounds (Oishi 2023 / Rump-Oishi 2024)</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../svd/">SVD</a></li><li><a class="tocitem" href="../eigenvalues/">Eigenvalues</a></li><li><a class="tocitem" href="../pseudospectra/">Pseudospectra</a></li><li><a class="tocitem" href="../linearsystems/">Linear Systems</a></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../API/">Overview</a></li><li><a class="tocitem" href="../api/core/">Core Types</a></li><li><a class="tocitem" href="../api/linearsystems/">Linear Systems</a></li><li><a class="tocitem" href="../api/eigenvalues/">Eigenvalues &amp; SVD</a></li><li><a class="tocitem" href="../api/certifscripts/">CertifScripts</a></li><li><a class="tocitem" href="../api/numericaltest/">NumericalTest</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Matrix Decompositions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Matrix Decompositions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaBallArithmetic/BallArithmetic.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaBallArithmetic/BallArithmetic.jl/blob/main/docs/src/decompositions.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Certified-Matrix-Decompositions"><a class="docs-heading-anchor" href="#Certified-Matrix-Decompositions">Certified Matrix Decompositions</a><a id="Certified-Matrix-Decompositions-1"></a><a class="docs-heading-anchor-permalink" href="#Certified-Matrix-Decompositions" title="Permalink"></a></h1><p>BallArithmetic.jl provides rigorous certification for several matrix decompositions. Each method computes both a numerical approximation and a <strong>rigorous error bound</strong>.</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><table><tr><th style="text-align: right">Decomposition</th><th style="text-align: right">Function</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right">SVD</td><td style="text-align: right"><code>ogita_svd_refine</code></td><td style="text-align: right">Singular value decomposition</td></tr><tr><td style="text-align: right">SVD Cascade</td><td style="text-align: right"><code>ogita_svd_cascade</code></td><td style="text-align: right">Multi-precision SVD cascade</td></tr><tr><td style="text-align: right">SVD (GLA)</td><td style="text-align: right"><code>ogita_svd_cascade_gla</code></td><td style="text-align: right">Native BigFloat SVD</td></tr><tr><td style="text-align: right">Schur</td><td style="text-align: right"><code>iterative_schur_refinement</code></td><td style="text-align: right">Schur form</td></tr><tr><td style="text-align: right">LU</td><td style="text-align: right"><code>verified_lu</code></td><td style="text-align: right">LU factorization</td></tr><tr><td style="text-align: right">Cholesky</td><td style="text-align: right"><code>verified_cholesky</code></td><td style="text-align: right">Cholesky factorization</td></tr><tr><td style="text-align: right">QR</td><td style="text-align: right"><code>verified_qr</code></td><td style="text-align: right">QR factorization</td></tr><tr><td style="text-align: right">Polar</td><td style="text-align: right"><code>verified_polar</code></td><td style="text-align: right">Polar decomposition</td></tr><tr><td style="text-align: right">Takagi</td><td style="text-align: right"><code>verified_takagi</code></td><td style="text-align: right">Takagi factorization</td></tr></table><h2 id="Recommended-Extensions"><a class="docs-heading-anchor" href="#Recommended-Extensions">Recommended Extensions</a><a id="Recommended-Extensions-1"></a><a class="docs-heading-anchor-permalink" href="#Recommended-Extensions" title="Permalink"></a></h2><p>BallArithmetic supports several extension packages that provide different performance characteristics:</p><table><tr><th style="text-align: right">Extension</th><th style="text-align: right">Package</th><th style="text-align: right">Use Case</th></tr><tr><td style="text-align: right"><strong>GenericLinearAlgebra</strong></td><td style="text-align: right"><code>GenericLinearAlgebra.jl</code></td><td style="text-align: right"><strong>Recommended</strong> - Native BigFloat SVD, fastest and most accurate</td></tr><tr><td style="text-align: right"><strong>MultiFloats</strong></td><td style="text-align: right"><code>MultiFloats.jl</code></td><td style="text-align: right">SIMD-accelerated multi-precision (Float64x2, Float64x4)</td></tr><tr><td style="text-align: right"><strong>DoubleFloats</strong></td><td style="text-align: right"><code>DoubleFloats.jl</code></td><td style="text-align: right">Fast Double64 arithmetic (~106 bits)</td></tr></table><h2 id="SVD-Certification-Methods"><a class="docs-heading-anchor" href="#SVD-Certification-Methods">SVD Certification Methods</a><a id="SVD-Certification-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#SVD-Certification-Methods" title="Permalink"></a></h2><p>The SVD is fundamental for resolvent norm certification and condition number estimation. We provide multiple methods with different speed/accuracy trade-offs.</p><h3 id="Method-Comparison"><a class="docs-heading-anchor" href="#Method-Comparison">Method Comparison</a><a id="Method-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Method-Comparison" title="Permalink"></a></h3><p>All benchmarks performed on:</p><ul><li><strong>CPU:</strong> AMD Ryzen 5 5600 6-Core Processor</li><li><strong>RAM:</strong> 128 GB</li><li><strong>Julia:</strong> 1.11+</li><li><strong>BigFloat precision:</strong> 256 bits</li></ul><h4 id="Small-Matrix-(100100)"><a class="docs-heading-anchor" href="#Small-Matrix-(100100)">Small Matrix (100×100)</a><a id="Small-Matrix-(100100)-1"></a><a class="docs-heading-anchor-permalink" href="#Small-Matrix-(100100)" title="Permalink"></a></h4><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Time</th><th style="text-align: right">Non-rigorous Residual</th><th style="text-align: right">Rigorous σ_min Bound</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right"><strong>GLA (no refine)</strong></td><td style="text-align: right"><strong>4.2s</strong></td><td style="text-align: right"><strong>4×10⁻⁷⁴</strong></td><td style="text-align: right">✓</td><td style="text-align: right"><strong>6.6×</strong></td></tr><tr><td style="text-align: right">D64 cascade (F64→D64→BF)</td><td style="text-align: right">11.7s</td><td style="text-align: right">1×10⁻¹²</td><td style="text-align: right">✓</td><td style="text-align: right">2.4×</td></tr><tr><td style="text-align: right">Minimal cascade (F64→MF3→BF)</td><td style="text-align: right">12.2s</td><td style="text-align: right">1×10⁻¹²</td><td style="text-align: right">✓</td><td style="text-align: right">2.3×</td></tr><tr><td style="text-align: right">Full cascade (F64→D64→MF3→MF4→BF)</td><td style="text-align: right">15.0s</td><td style="text-align: right">1×10⁻¹³</td><td style="text-align: right">✓</td><td style="text-align: right">1.8×</td></tr><tr><td style="text-align: right">Pure Ogita (F64→BF×5)</td><td style="text-align: right">27.7s</td><td style="text-align: right">1×10⁻¹²</td><td style="text-align: right">✓</td><td style="text-align: right">1.0×</td></tr></table><p><strong>Key observations:</strong></p><ul><li>GLA achieves <strong>60+ orders of magnitude</strong> better residual than cascade methods</li><li>GLA is <strong>6.6× faster</strong> than pure Ogita refinement</li><li>All methods produce valid rigorous bounds for σ_min</li><li>Simpler cascades (D64 only) outperform complex multi-level cascades</li></ul><h4 id="Medium-Matrix-(200200)"><a class="docs-heading-anchor" href="#Medium-Matrix-(200200)">Medium Matrix (200×200)</a><a id="Medium-Matrix-(200200)-1"></a><a class="docs-heading-anchor-permalink" href="#Medium-Matrix-(200200)" title="Permalink"></a></h4><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Time</th><th style="text-align: right">Non-rigorous Residual</th><th style="text-align: right">Rigorous Bound</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right">Cascade (F64→D64→MF3→MF4→BF×2)</td><td style="text-align: right">196s</td><td style="text-align: right">3.3×10⁻¹²</td><td style="text-align: right">✓</td><td style="text-align: right">2.1×</td></tr><tr><td style="text-align: right">Pure Ogita (F64→BF×5)</td><td style="text-align: right">407s</td><td style="text-align: right">5.0×10⁻¹²</td><td style="text-align: right">✓</td><td style="text-align: right">1.0×</td></tr></table><h4 id="Large-Matrix-(500500)"><a class="docs-heading-anchor" href="#Large-Matrix-(500500)">Large Matrix (500×500)</a><a id="Large-Matrix-(500500)-1"></a><a class="docs-heading-anchor-permalink" href="#Large-Matrix-(500500)" title="Permalink"></a></h4><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Time</th><th style="text-align: right">Non-rigorous Residual</th><th style="text-align: right">Rigorous Bound</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right">Cascade (F64→D64→MF3→MF4→BF×2)</td><td style="text-align: right">3234s</td><td style="text-align: right">1.4×10⁻¹¹</td><td style="text-align: right">✓</td><td style="text-align: right">1.9×</td></tr><tr><td style="text-align: right">Pure Ogita (F64→BF×5)</td><td style="text-align: right">6279s</td><td style="text-align: right">1.6×10⁻¹¹</td><td style="text-align: right">✓</td><td style="text-align: right">1.0×</td></tr></table><h3 id="Recommendations"><a class="docs-heading-anchor" href="#Recommendations">Recommendations</a><a id="Recommendations-1"></a><a class="docs-heading-anchor-permalink" href="#Recommendations" title="Permalink"></a></h3><ol><li><p><strong>Use GenericLinearAlgebra</strong> when available:</p><pre><code class="language-julia hljs">using BallArithmetic, GenericLinearAlgebra

T_bf = Complex{BigFloat}.(T)
z_bf = Complex{BigFloat}(z)
result = ogita_svd_cascade_gla(T_bf, z_bf)

# result.σ_min is a rigorous lower bound
# result.residual_norm is the non-rigorous residual</code></pre></li><li><p><strong>Without GLA</strong>, use the simple D64 cascade:</p><pre><code class="language-julia hljs">using BallArithmetic, MultiFloats, DoubleFloats

result = ogita_svd_cascade(T_bf, z_bf;
    f64_iters=1, d64_iters=1, mf3_iters=0, mf4_iters=0, bf_iters=2)</code></pre></li><li><p><strong>For pure BigFloat</strong> (no extensions):</p><pre><code class="language-julia hljs">using BallArithmetic

result = ogita_svd_refine(A, U, Σ, V; max_iterations=5)</code></pre></li></ol><h2 id="Rigorous-vs-Non-Rigorous-Results"><a class="docs-heading-anchor" href="#Rigorous-vs-Non-Rigorous-Results">Rigorous vs Non-Rigorous Results</a><a id="Rigorous-vs-Non-Rigorous-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Rigorous-vs-Non-Rigorous-Results" title="Permalink"></a></h2><p>Each decomposition method returns:</p><ul><li><strong>Non-rigorous residual:</strong> The computed <code>‖A - UΣVᴴ‖_F</code> using standard floating-point</li><li><strong>Rigorous bound:</strong> A mathematically guaranteed upper bound on the true error</li></ul><p>The rigorous bound accounts for:</p><ul><li>Rounding errors in all computations</li><li>Potential instabilities in the algorithm</li><li>Accumulated error from multiple operations</li></ul><p>For certification purposes, <strong>always use the rigorous bound</strong>.</p><h2 id="Other-Matrix-Decompositions-(100100-Matrix)"><a class="docs-heading-anchor" href="#Other-Matrix-Decompositions-(100100-Matrix)">Other Matrix Decompositions (100×100 Matrix)</a><a id="Other-Matrix-Decompositions-(100100-Matrix)-1"></a><a class="docs-heading-anchor-permalink" href="#Other-Matrix-Decompositions-(100100-Matrix)" title="Permalink"></a></h2><p>Beyond SVD, BallArithmetic provides verified versions of standard matrix decompositions.</p><h3 id="Standard-(Float64-BigFloat)"><a class="docs-heading-anchor" href="#Standard-(Float64-BigFloat)">Standard (Float64 → BigFloat)</a><a id="Standard-(Float64-BigFloat)-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-(Float64-BigFloat)" title="Permalink"></a></h3><p>These use Float64 computation with BigFloat certification:</p><table><tr><th style="text-align: right">Decomposition</th><th style="text-align: right">Time</th><th style="text-align: right">Residual Norm</th><th style="text-align: right">Rigorous Bound</th></tr><tr><td style="text-align: right">Cholesky (SPD)</td><td style="text-align: right">1.7s</td><td style="text-align: right">2.7×10⁻¹⁶</td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right">QR</td><td style="text-align: right">2.1s</td><td style="text-align: right">3.1×10⁻¹⁵</td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right">Polar</td><td style="text-align: right">3.3s</td><td style="text-align: right">4.8×10⁻¹⁶</td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right">LU</td><td style="text-align: right">5.6s</td><td style="text-align: right">1.3×10⁻¹⁴</td><td style="text-align: right">✓</td></tr><tr><td style="text-align: right">Takagi</td><td style="text-align: right">10.3s</td><td style="text-align: right">1.7×10⁻¹⁵</td><td style="text-align: right">✓</td></tr></table><h3 id="GLA-Based-(Native-BigFloat)"><a class="docs-heading-anchor" href="#GLA-Based-(Native-BigFloat)">GLA-Based (Native BigFloat)</a><a id="GLA-Based-(Native-BigFloat)-1"></a><a class="docs-heading-anchor-permalink" href="#GLA-Based-(Native-BigFloat)" title="Permalink"></a></h3><p>With GenericLinearAlgebra, we achieve <strong>60+ orders of magnitude better residuals</strong>:</p><table><tr><th style="text-align: right">Decomposition</th><th style="text-align: right">Time</th><th style="text-align: right">Residual Norm</th><th style="text-align: right">Improvement</th></tr><tr><td style="text-align: right"><strong>Cholesky (GLA)</strong></td><td style="text-align: right"><strong>0.55s</strong></td><td style="text-align: right"><strong>5.2×10⁻⁷⁴</strong></td><td style="text-align: right">10⁵⁸× better</td></tr><tr><td style="text-align: right"><strong>LU (GLA)</strong></td><td style="text-align: right"><strong>0.91s</strong></td><td style="text-align: right"><strong>5.9×10⁻⁷⁵</strong></td><td style="text-align: right">10⁶¹× better</td></tr><tr><td style="text-align: right"><strong>QR (GLA)</strong></td><td style="text-align: right"><strong>0.91s</strong></td><td style="text-align: right"><strong>5.4×10⁻⁷⁵</strong></td><td style="text-align: right">10⁶⁰× better</td></tr><tr><td style="text-align: right"><strong>SVD (GLA)</strong></td><td style="text-align: right">5.15s</td><td style="text-align: right">4.5×10⁻⁷⁴</td><td style="text-align: right">10⁶⁰× better</td></tr></table><p><strong>GLA functions:</strong></p><pre><code class="language-julia hljs">using BallArithmetic, GenericLinearAlgebra

result_lu = verified_lu_gla(A)        # ~10⁻⁷⁵ residual
result_qr = verified_qr_gla(A)        # ~10⁻⁷⁵ residual
result_chol = verified_cholesky_gla(A_spd)  # ~10⁻⁷⁴ residual
(U, S, V, res) = verified_svd_gla(A)  # ~10⁻⁷⁴ residual</code></pre><p><strong>Usage examples:</strong></p><pre><code class="language-julia hljs">using BallArithmetic
using LinearAlgebra

A = randn(100, 100) + 5I

# LU decomposition
result_lu = verified_lu(A)
# result_lu.L, result_lu.U are BallMatrix enclosures
# result_lu.residual_norm is the rigorous error bound

# QR decomposition
result_qr = verified_qr(A)
# result_qr.Q, result_qr.R are BallMatrix enclosures
# result_qr.orthogonality_defect bounds ‖QᴴQ - I‖

# Cholesky (for symmetric positive definite)
A_spd = A&#39;A + 100I
result_chol = verified_cholesky(A_spd)
# result_chol.L is the lower Cholesky factor

# Polar decomposition A = UH
result_polar = verified_polar(A)
# result_polar.U (unitary), result_polar.H (Hermitian positive semidefinite)

# Takagi factorization (for complex symmetric)
A_symm = A + transpose(A)
result_takagi = verified_takagi(A_symm)
# A = U Σ Uᵀ (not Uᴴ!)</code></pre><h3 id="Iterative-Refinement-Methods"><a class="docs-heading-anchor" href="#Iterative-Refinement-Methods">Iterative Refinement Methods</a><a id="Iterative-Refinement-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Iterative-Refinement-Methods" title="Permalink"></a></h3><p>For decompositions not supported by GLA, we provide iterative refinement using extended precision arithmetic.</p><h4 id="Float64-Iterative-Refinement-(5-iterations)"><a class="docs-heading-anchor" href="#Float64-Iterative-Refinement-(5-iterations)">Float64 Iterative Refinement (5 iterations)</a><a id="Float64-Iterative-Refinement-(5-iterations)-1"></a><a class="docs-heading-anchor-permalink" href="#Float64-Iterative-Refinement-(5-iterations)" title="Permalink"></a></h4><table><tr><th style="text-align: right">Decomposition</th><th style="text-align: right">Time</th><th style="text-align: right">Residual</th><th style="text-align: right">Orthogonality Defect</th></tr><tr><td style="text-align: right">Cholesky</td><td style="text-align: right">0.97s</td><td style="text-align: right">8.9×10⁻¹⁷</td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right">QR (CholQR2)</td><td style="text-align: right">0.12s</td><td style="text-align: right">6.8×10⁻¹⁶</td><td style="text-align: right">2.8×10⁻¹⁵</td></tr><tr><td style="text-align: right">LU</td><td style="text-align: right">0.96s</td><td style="text-align: right">1.5×10⁻¹⁵</td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right">Polar (Newton-Schulz)</td><td style="text-align: right">0.22s</td><td style="text-align: right">1.4×10⁻¹⁵</td><td style="text-align: right">2.1×10⁻¹⁵</td></tr></table><h4 id="Double64-Iterative-Refinement-(5-iterations)"><a class="docs-heading-anchor" href="#Double64-Iterative-Refinement-(5-iterations)">Double64 Iterative Refinement (5 iterations)</a><a id="Double64-Iterative-Refinement-(5-iterations)-1"></a><a class="docs-heading-anchor-permalink" href="#Double64-Iterative-Refinement-(5-iterations)" title="Permalink"></a></h4><p>Double64 provides ~106 bits of precision, dramatically improving orthogonality:</p><table><tr><th style="text-align: right">Decomposition</th><th style="text-align: right">Time</th><th style="text-align: right">Residual</th><th style="text-align: right">Orthogonality Defect</th></tr><tr><td style="text-align: right">Cholesky</td><td style="text-align: right">0.90s</td><td style="text-align: right">7.2×10⁻¹⁸</td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right">QR (CholQR2)</td><td style="text-align: right">1.69s</td><td style="text-align: right">7.1×10⁻¹⁶</td><td style="text-align: right"><strong>2.1×10⁻³¹</strong></td></tr><tr><td style="text-align: right">LU</td><td style="text-align: right">4.53s</td><td style="text-align: right">1.2×10⁻¹⁵</td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right">Polar (Newton-Schulz)</td><td style="text-align: right">2.76s</td><td style="text-align: right">1.3×10⁻¹⁵</td><td style="text-align: right"><strong>2.0×10⁻³¹</strong></td></tr></table><p><strong>Key observation:</strong> Double64 achieves <strong>16 orders of magnitude better orthogonality</strong> for QR and Polar decompositions, while residuals remain similar (limited by Float64 input precision).</p><p><strong>Usage:</strong></p><pre><code class="language-julia hljs">using BallArithmetic, DoubleFloats, LinearAlgebra

A = randn(100, 100) + 5I
F_qr = qr(A)

# Float64 refinement
result_f64 = refine_qr_cholqr2(A, Matrix(F_qr.Q), Matrix(F_qr.R); max_iterations=5)

# Double64 refinement (better orthogonality)
result_d64 = refine_qr_double64(A, Matrix(F_qr.Q), Matrix(F_qr.R);
    method=:cholqr2, max_iterations=5)

# Polar refinement
F_svd = svd(A)
Q0 = F_svd.U * F_svd.Vt
result_polar = refine_polar_double64(A, Q0; method=:newton_schulz, max_iterations=10)</code></pre><h2 id="Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)"><a class="docs-heading-anchor" href="#Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)">Schur Complement Bounds (Oishi 2023 / Rump-Oishi 2024)</a><a id="Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)-1"></a><a class="docs-heading-anchor-permalink" href="#Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)" title="Permalink"></a></h2><p>For block-structured matrices, the Schur complement method provides efficient σ_min bounds:</p><pre><code class="language-julia hljs">result = rump_oishi_2024_sigma_min_bound(G; block_size=m)</code></pre><p>This implements:</p><ul><li><strong>Oishi 2023:</strong> Base Schur complement algorithm</li><li><strong>Rump-Oishi 2024:</strong> Improved ψ(N) formula that works for ‖N‖ ≥ 1</li></ul><p>Key advantages:</p><ul><li>Works on matrices too large for full SVD</li><li>Exploits block diagonal dominance structure</li><li>Automatic optimal block size selection</li></ul><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>Ogita, T. &amp; Aishima, K. (2020), &quot;Iterative refinement for singular value decomposition based on matrix multiplication&quot;</li><li>Rump, S.M. &amp; Ogita, S. (2024), &quot;A Note on Oishi&#39;s Lower Bound for the Smallest Singular Value of Linearized Galerkin Equations&quot;</li><li>Oishi, S. (2023), &quot;Lower bounds for the smallest singular values of generalized asymptotic diagonal dominant matrices&quot;</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../svd/">SVD »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Saturday 14 February 2026 14:04">Saturday 14 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
