var documenterSearchIndex = {"docs":
[{"location":"api/certifscripts/#API-CertifScripts","page":"CertifScripts","title":"API - CertifScripts","text":"Pseudospectra certification module.","category":"section"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.CertificationCircle","page":"CertifScripts","title":"BallArithmetic.CertifScripts.CertificationCircle","text":"CertificationCircle(center, radius; samples = 256)\n\nDiscretisation of a circle with centre center, radius radius, and samples equally spaced points used for certification runs.\n\n\n\n\n\n","category":"type"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._bf_ogita_cache_stats-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._bf_ogita_cache_stats","text":"_bf_ogita_cache_stats()\n\nReturn statistics about the BigFloat Ogita cache usage.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._clear_bf_ogita_cache!-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._clear_bf_ogita_cache!","text":"_clear_bf_ogita_cache!()\n\nClear the worker-local BigFloat SVD cache used for Ogita optimization.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._clear_ogita_cache!-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._clear_ogita_cache!","text":"_clear_ogita_cache!()\n\nClear the worker-local SVD cache used for Ogita optimization.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._clear_parametric_cache!-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._clear_parametric_cache!","text":"_clear_parametric_cache!()\n\nClear the worker-local parametric certifier cache.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._compute_schur_and_error_bigfloat-Tuple{BallMatrix{BigFloat}}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._compute_schur_and_error_bigfloat","text":"_compute_schur_and_error_bigfloat(A; polynomial = nothing)\n\nBigFloat version of computeschurand_error.  Uses GenericSchur.jl's native BigFloat Schur decomposition for full-precision results.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._compute_schur_bigfloat_direct-Tuple{BallMatrix{BigFloat}}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._compute_schur_bigfloat_direct","text":"_compute_schur_bigfloat_direct(A; polynomial = nothing)\n\nCompute BigFloat Schur decomposition directly via GenericSchur.jl (no Float64 seed).  Works for matrices whose eigenvalues span many orders of magnitude.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._compute_schur_bigfloat_refined-Tuple{BallMatrix{BigFloat}}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._compute_schur_bigfloat_refined","text":"_compute_schur_bigfloat_refined(A; polynomial = nothing)\n\nCompute BigFloat Schur decomposition by refining a Float64 seed. Seeds from Float64 Schur, then refines iteratively in BigFloat. May fail for matrices with eigenvalues below ~10⁻¹⁶.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._evaluate_sample_ogita_bigfloat-Union{Tuple{ET}, Tuple{BallMatrix{ET}, Number, Int64}} where ET","page":"CertifScripts","title":"BallArithmetic.CertifScripts._evaluate_sample_ogita_bigfloat","text":"_evaluate_sample_ogita_bigfloat(T_matrix::BallMatrix, z::Number, idx::Int;\n                                 max_iterations::Int=4,\n                                 target_precision::Int=256,\n                                 distance_threshold::Real=1e-4,\n                                 use_cache::Bool=true)\n\nEvaluate the smallest singular value at z using Ogita refinement with caching.\n\nThis function uses a worker-local cache to store the last refined BigFloat SVD. For nearby points (distance < distance_threshold), it uses the cached SVD as a starting point for Ogita refinement, which requires fewer iterations than starting from Float64.\n\nCache Strategy\n\nIf cache hit: use cached BigFloat SVD → 1-2 Ogita iterations\nIf cache miss: use Float64 SVD → 3-4 Ogita iterations\n\nArguments\n\nT_matrix: The Schur matrix T (BallMatrix)\nz: Sample point on the circle\nidx: Sample index for logging\nmax_iterations: Number of Ogita iterations for cache miss (3-4 for 256-bit)\ntarget_precision: Target precision in bits\ndistance_threshold: Maximum distance for cache reuse\nuse_cache: Whether to use caching (default: true)\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._evaluate_sample_parametric-Union{Tuple{ET}, Tuple{BallMatrix{ET}, Number, Int64}} where ET","page":"CertifScripts","title":"BallArithmetic.CertifScripts._evaluate_sample_parametric","text":"_evaluate_sample_parametric(T, z, idx; use_warm_start=true, distance_threshold=1e-4)\n\nEvaluate sample using the parametric Sylvester-based certifier.\n\nReturns a result compatible with the standard certification format.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._evaluate_sample_with_ogita_cache-Union{Tuple{ET}, Tuple{BallMatrix{ET}, Number, Int64}} where ET","page":"CertifScripts","title":"BallArithmetic.CertifScripts._evaluate_sample_with_ogita_cache","text":"_evaluate_sample_with_ogita_cache(T, z, idx; ogita_distance_threshold, ogita_quality_threshold)\n\nEvaluate sample with Ogita optimization: try to refine from cached SVD if available.\n\nIf the cached SVD is from a nearby point (distance < ogitadistancethreshold), attempt Ogita refinement. If the refined SVD has acceptable quality (residual < ogitaqualitythreshold), use it; otherwise fall back to full SVD.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._ogita_cache_stats-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._ogita_cache_stats","text":"_ogita_cache_stats()\n\nReturn statistics about the Ogita cache usage.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._parametric_cache_stats-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._parametric_cache_stats","text":"_parametric_cache_stats()\n\nReturn statistics about the parametric cache usage.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts._set_center_svd_cache!-NTuple{4, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts._set_center_svd_cache!","text":"_set_center_svd_cache!(U, S, V, z)\n\nSet the center SVD cache. This should be called once at the start of certification with the SVD computed at the circle center.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.adaptive_arcs!-Tuple{Vector{Tuple{ComplexF64, ComplexF64}}, Dict{ComplexF64, Any}, Any, Float64}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.adaptive_arcs!","text":"adaptive_arcs!(arcs, cache, pending, η; kwargs...)\n\nDrive the adaptive refinement routine.  When job channels are provided the refinement uses asynchronous workers; otherwise the evaluation is carried out serially using the supplied evaluator.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.bound_res_original-NTuple{7, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.bound_res_original","text":"bound_res_original(l2pseudo, η, norm_Z, norm_Z_inv, errF, errT, N; Cbound=1.0)\n\nReturn an upper bound on the ℓ₁ resolvent norm of the original matrix given the bounds obtained from the Schur form.\n\nThin wrapper that calls bound_resolvent_schur and schur_to_original_resolvent.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.bound_resolvent_schur-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.bound_resolvent_schur","text":"bound_resolvent_schur(l2pseudo, η)\n\nAdjust the raw Schur pseudospectral resolvent for the trapezoid rule discretization error η. Returns a rigorous upper bound on the Schur resolvent.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.choose_snapshot_to_load-Tuple{String}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.choose_snapshot_to_load","text":"choose_snapshot_to_load(basepath)\n\nReturn the most recent valid snapshot stored at basepath.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.compute_schur_and_error-Union{Tuple{BallMatrix{T}}, Tuple{T}} where T","page":"CertifScripts","title":"BallArithmetic.CertifScripts.compute_schur_and_error","text":"compute_schur_and_error(A; polynomial = nothing)\n\nCompute the Schur decomposition of A and certified bounds for the orthogonality defect, the reconstruction error, and the norms of Z and Z⁻¹.  When polynomial is provided (as coefficients in ascending order), additional bounds are computed for p(A) and p(T).\n\nSupports both Float64 and BigFloat precision based on the element type of A. For BigFloat, the Schur decomposition is computed in Float64 and then refined to higher precision using iterative refinement.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.configure_certification!-Tuple{}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.configure_certification!","text":"configure_certification!(; job_channel, result_channel, certification_log, snapshot, io)\n\nCache common resources used by the certification helpers.  The stored values are used as defaults by adaptive_arcs! and save_snapshot!. Any keyword may be omitted to keep its previous value.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.dowork-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.dowork","text":"dowork(jobs, results)\n\nProcess tasks received on jobs, computing the SVD certification routine for T - zI.  The Schur factor must have been registered in advance with set_schur_matrix!.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.dowork_ogita-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.dowork_ogita","text":"dowork_ogita(jobs, results; ogita_distance_threshold=1e-4, ogita_quality_threshold=1e-10)\n\nProcess tasks with Ogita optimization enabled. Similar to dowork but tries to use cached SVD from previous evaluations to speed up nearby points.\n\nThe worker maintains a cache of the last computed SVD. When a new point z arrives, if it's within ogita_distance_threshold of the cached point, Ogita refinement is attempted. If the refined SVD has acceptable quality (relative residual < ogita_quality_threshold), it's used; otherwise a full SVD is computed.\n\nThis is beneficial when the adaptive bisection sends consecutive jobs for nearby points, which happens naturally as arcs get smaller during refinement.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.dowork_ogita_bigfloat-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.dowork_ogita_bigfloat","text":"dowork_ogita_bigfloat(jobs, results; target_precision=256, max_ogita_iterations=3,\n                      distance_threshold=1e-4)\n\nProcess tasks with BigFloat precision using Ogita SVD refinement with caching.\n\nFor each job (id, z), this worker:\n\nChecks if a cached BigFloat SVD exists from a nearby point\nIf cache hit: refines from cached SVD (1-2 iterations)\nIf cache miss: computes Float64 SVD and refines to BigFloat (3-4 iterations)\nCertifies with Miyajima bounds\nCaches the result for future reuse\n\nThis is the distributed equivalent of run_certification_ogita for parallel execution. The Schur matrix must be a BigFloat BallMatrix registered with set_schur_matrix!.\n\nPerformance\n\nCache miss: Ogita from Float64 requires ~4 iterations (10^-16 → 10^-64)\nCache hit: Ogita from BigFloat requires ~1-2 iterations (already at high precision)\nFor adaptive bisection with nearby points, expect 50-90% cache hit rate\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.dowork_parametric-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.dowork_parametric","text":"dowork_parametric(jobs, results; distance_threshold=1e-4)\n\nProcess tasks using the parametric Sylvester-based certifier.\n\nThe Schur factor and parametric config must have been registered in advance with set_schur_matrix! and set_parametric_config!.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.points_on-Tuple{CertificationCircle}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.points_on","text":"points_on(circle)\n\nReturn the discretisation of circle used for certification.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.poly_from_roots-Tuple{AbstractVector}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.poly_from_roots","text":"poly_from_roots(roots::AbstractVector)\n\nGiven a list of roots r₁, r₂, …, rₙ, returns the coefficients [a₀, a₁, …, aₙ] of the monic polynomial     p(x) = (x - r₁)(x - r₂)…(x - rₙ) so that p(x) = a₀ + a₁x + a₂x² + … + aₙ*xⁿ.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.run_certification-Tuple{BallMatrix, CertificationCircle}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.run_certification","text":"run_certification(A, circle; schur_data = nothing, polynomial = nothing, kwargs...)\n\nRun the adaptive certification routine on circle using a serial evaluator.\n\nArguments\n\nA: matrix to certify.  Converted to BallMatrix when required.\ncircle: CertificationCircle describing the contour used for the adaptive refinement.\n\nKeyword Arguments\n\nschur_data = nothing: pre-computed Schur data as the 5-tuple (S, errF, errT, norm_Z, norm_Z_inv) returned by compute_schur_and_error. When provided, the expensive Schur computation is skipped entirely. This is useful for reusing the same Schur decomposition across multiple circles or when the default Float64-seeded refinement fails (e.g., matrices with eigenvalues below ~10⁻¹⁶).\npolynomial = nothing: optional coefficients (ascending order) describing a polynomial p.  When provided the certification is carried out on p(T) and the returned error corresponds to the reconstruction error of p(A).\nη = 0.5: admissible threshold for the adaptive refinement.  Must lie in the open unit interval.\ncheck_interval = 100: number of processed arcs between progress reports and consistency checks.\nlog_io = stdout: destination IO for log messages.\nCbound = 1.0: constant used by bound_res_original when lifting resolvent bounds back to the original matrix.\n\nThe return value is a named tuple containing the computed Schur form, the accumulated certification log, and the resolvent bounds for both the Schur factor and the original matrix.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.run_certification_ogita-Union{Tuple{T}, Tuple{BallMatrix{T}, CertificationCircle}} where T","page":"CertifScripts","title":"BallArithmetic.CertifScripts.run_certification_ogita","text":"run_certification_ogita(A, circle; target_precision=256, kwargs...)\n\nOptimized BigFloat certification using Ogita SVD refinement.\n\nThis function is specifically designed for BigFloat precision certification where computing fresh BigFloat SVDs at each sample point is expensive. Instead, it:\n\nComputes Schur decomposition with BigFloat refinement\nAt each sample point z, computes Float64 SVD of (T - zI)\nRefines the Float64 SVD to BigFloat using Ogita's algorithm (3-4 iterations)\n\nDue to quadratic convergence, 4 Ogita iterations from Float64 (~10^-16 error) achieve ~10^-64 error, saturating 256-bit precision.\n\nPerformance\n\nTypically 10-100x faster than computing fresh BigFloat SVDs at each point.\n\nArguments\n\nA: matrix to certify (will be converted to BigFloat BallMatrix)\ncircle: CertificationCircle describing the contour\ntarget_precision::Int=256: precision in bits for BigFloat\nmax_ogita_iterations::Int=3: Ogita iterations (3 is optimal for 256-bit precision)\nOther kwargs passed to standard certification\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.run_certification_parametric-Union{Tuple{T}, Tuple{BallMatrix{T}, CertificationCircle}} where T","page":"CertifScripts","title":"BallArithmetic.CertifScripts.run_certification_parametric","text":"run_certification_parametric(A, circle; k=nothing, config=config_v2(), kwargs...)\n\nRun the adaptive certification routine using the parametric Sylvester-based certifier.\n\nThis method uses block-diagonalization via Sylvester equation to certify the resolvent norm, which can be more efficient than full SVD for large matrices.\n\nArguments\n\nA: matrix to certify. Converted to BallMatrix when required.\ncircle: CertificationCircle describing the contour.\n\nKeyword Arguments\n\nk::Union{Nothing, Int}=nothing: Split index for the Schur block decomposition. If nothing, automatically selects k ≈ n/4.\nconfig::ResolventBoundConfig=config_v2(): Configuration specifying estimators. Options: config_v1(), config_v2(), config_v2p5(), config_v3().\npolynomial = nothing: optional coefficients for polynomial certification.\nη = 0.5: admissible threshold for adaptive refinement.\ncheck_interval = 100: number of arcs between progress reports.\nlog_io = stdout: destination for log messages.\nCbound = 1.0: constant for resolvent bound lifting.\n\nExample\n\nusing BallArithmetic\nA = randn(ComplexF64, 50, 50)\ncircle = CertificationCircle(0.0, 1.5; samples=64)\n\n# Use V2 configuration (default)\nresult = run_certification_parametric(A, circle)\n\n# Use V3 configuration with Neumann bounds\nresult = run_certification_parametric(A, circle; config=config_v3())\n\n# Specify custom split\nresult = run_certification_parametric(A, circle; k=10)\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.save_snapshot!-Tuple{Any, Any, Any, Any, String, Bool}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.save_snapshot!","text":"save_snapshot!(arcs, cache, log, pending, basepath, toggle)\n\nPersist the current certification state to disk using alternating files.\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.schur_to_original_resolvent-Tuple{Any, Any}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.schur_to_original_resolvent","text":"schur_to_original_resolvent(resolvent_schur, ϵ; Cbound=1.0)\n\nTransform a Schur resolvent bound to the original matrix using the Schur perturbation theorem. Returns Inf when the bound is not computable (ε·resolvent too large for the perturbation estimate).\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.set_parametric_config!-Tuple{SylvesterResolventResult, AbstractMatrix, ResolventBoundConfig}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.set_parametric_config!","text":"set_parametric_config!(precomp, R, config; k=0)\n\nSet the parametric certifier configuration.\n\nArguments\n\nprecomp: Precomputed Sylvester quantities from sylvester_resolvent_precompute\nR: Sylvester residual matrix\nconfig: ResolventBoundConfig specifying estimators\nk: Split index (for reference)\n\n\n\n\n\n","category":"method"},{"location":"api/certifscripts/#BallArithmetic.CertifScripts.set_schur_matrix!-Tuple{BallMatrix}","page":"CertifScripts","title":"BallArithmetic.CertifScripts.set_schur_matrix!","text":"set_schur_matrix!(T)\n\nStore the Schur factor T used by dowork.\n\n\n\n\n\n","category":"method"},{"location":"references/#References","page":"References","title":"References","text":"S. M. Rump. Fast and Parallel Interval Arithmetic. BIT Numerical Mathematics 39, 534–554 (1999).\n\n\n\nN. Revol and P. Théveny. Parallel Implementation of Interval Matrix Multiplication. Reliable Computing 19, 91 (2013).\n\n\n\nS. Miyajima. Fast enclosure for solutions of Sylvester equations. Linear Algebra and its Applications 439, 856–878 (2013).\n\n\n\nS. M. Rump and S. Oishi. Fast enclosure of matrix eigenvalues and singular values via rounding mode controlled computation. Linear Algebra and its Applications 324, 133–146 (2001).\n\n\n\nS. Miyajima. Fast verified matrix multiplication. Journal of Computational and Applied Mathematics 233, 2994–3004 (2010).\n\n\n\nT. Ogita and K. Aishima. Iterative refinement for singular value decomposition based on matrix multiplication. Journal of Computational and Applied Mathematics 369, 112512 (2020).\n\n\n\nS. Miyajima. Numerical enclosure for each eigenvalue in generalized eigenvalue problem. Journal of Computational and Applied Mathematics 236, 2545–2552 (2012).\n\n\n\nS. Miyajima. Verified computation of invariant subspaces. SIAM Journal on Matrix Analysis and Applications 35, 1205–1225 (2014).\n\n\n\nS. M. Rump. Verified bounds for singular values, in particular for the spectral norm of a matrix and its inverse. BIT Numerical Mathematics 51, 367–384 (2011).\n\n\n\nS. Miyajima. Verified bounds for all the singular values of matrix. Japan Journal of Industrial and Applied Mathematics 31, 513–539 (2014).\n\n\n\nZ. Bujanović, D. Kressner and C. Schröder. Iterative refinement of Schur decompositions. Numerical Algorithms 95, 247–267 (2024). Preprint: arXiv:2203.10879v1, 2022.\n\n\n\nS. M. Rump. Verification methods: Rigorous results using floating-point arithmetic. Acta Numerica 19, 287–449 (2010).\n\n\n\nL. Qi. Some simple estimates for singular values of a matrix. Linear Algebra and its Applications 56, 105–119 (1984).\n\n\n\n\n\nN. J. Higham. Accuracy and Stability of Numerical Algorithms: Second Edition (Philadelphia, PA: SIAM, 1996).\n\n\n\nS. Oishi. Lower bounds for the smallest singular values of generalized asymptotic diagonal dominant matrices. Japan Journal of Industrial and Applied Mathematics 40, 1569–1585 (2023).\n\n\n\nS. M. Rump and S. Oishi. A note on Oishi's lower bound for the smallest singular value of linearized Galerkin equations. Japan Journal of Industrial and Applied Mathematics 41, 1097–1104 (2024).\n\n\n\nT. Ogita and K. Aishima. Iterative refinement for symmetric eigenvalue decomposition. Japan Journal of Industrial and Applied Mathematics 35, 1007–1035 (2018). Algorithm 1: RefSyEv.\n\n\n\nN. J. Higham. Computing the Polar Decomposition—with Applications. SIAM Journal on Scientific and Statistical Computing 7, 1160–1174 (1986).\n\n\n\nN. J. Higham. Functions of Matrices: Theory and Computation (Philadelphia, PA: SIAM, 2008). Chapter 8 covers the polar decomposition.\n\n\n\nY. Nakatsukasa, Z. Bai and F. Gygi. Optimizing Halley's Iteration for Computing the Matrix Polar Decomposition. SIAM Journal on Scientific Computing 32, 2700–2720 (2010). QDWH algorithm for polar decomposition.\n\n\n\nJ. H. Wilkinson. Rounding Errors in Algebraic Processes (Prentice-Hall, 1963). Classic text on rounding error analysis.\n\n\n\nR. S. Martin, G. Peters and J. H. Wilkinson. Iterative Refinement of the Solution of a Positive Definite System of Equations. Numerische Mathematik 8, 203–216 (1971). Cholesky factor refinement.\n\n\n\nY. Yamamoto, Y. Nakatsukasa, Y. Yanagisawa and T. Fukaya. Roundoff error analysis of the CholeskyQR2 algorithm. Numerische Mathematik 131, 297–322 (2015). CholeskyQR2 for QR reorthogonalization.\n\n\n\nT. Fukaya, R. Kannan, G. Ballard and J. Dongarra. LU-Cholesky QR Algorithms for Thin QR Decomposition. SIAM Journal on Scientific Computing 42, A1401–A1423 (2020).\n\n\n\nE. Carson and N. J. Higham. A New Analysis of Iterative Refinement and its Application to Accurate Solution of Ill-Conditioned Sparse Linear Systems. SIAM Journal on Scientific Computing 39, A2834–A2856 (2017). Mixed precision iterative refinement.\n\n\n\nS. M. Rump and T. Ogita. Error-free transformations and verified matrix decompositions. Numerical Algorithms (2024). Verified LU, Cholesky, QR, polar decompositions.\n\n\n\n","category":"section"},{"location":"api/linearsystems/#API-Linear-Systems","page":"Linear Systems","title":"API - Linear Systems","text":"Verified linear system solvers and related functions.","category":"section"},{"location":"api/linearsystems/#Gaussian-Elimination","page":"Linear Systems","title":"Gaussian Elimination","text":"","category":"section"},{"location":"api/linearsystems/#Iterative-Methods","page":"Linear Systems","title":"Iterative Methods","text":"","category":"section"},{"location":"api/linearsystems/#HBR-Method","page":"Linear Systems","title":"HBR Method","text":"","category":"section"},{"location":"api/linearsystems/#Shaving","page":"Linear Systems","title":"Shaving","text":"","category":"section"},{"location":"api/linearsystems/#Preconditioning","page":"Linear Systems","title":"Preconditioning","text":"","category":"section"},{"location":"api/linearsystems/#Overdetermined-Systems","page":"Linear Systems","title":"Overdetermined Systems","text":"","category":"section"},{"location":"api/linearsystems/#H-Matrix-Systems","page":"Linear Systems","title":"H-Matrix Systems","text":"","category":"section"},{"location":"api/linearsystems/#Sylvester-Equations","page":"Linear Systems","title":"Sylvester Equations","text":"","category":"section"},{"location":"api/linearsystems/#Matrix-Regularity","page":"Linear Systems","title":"Matrix Regularity","text":"","category":"section"},{"location":"api/linearsystems/#Determinant-Bounds","page":"Linear Systems","title":"Determinant Bounds","text":"","category":"section"},{"location":"api/linearsystems/#BallArithmetic.GaussianEliminationResult","page":"Linear Systems","title":"BallArithmetic.GaussianEliminationResult","text":"GaussianEliminationResult{T, VT}\n\nResult from interval Gaussian elimination.\n\nFields\n\nsolution::VT: Solution enclosure (or empty if singular)\nsuccess::Bool: Whether elimination succeeded\nsingular::Bool: Whether matrix is provably singular\nL::Matrix: Lower triangular factor (if computed)\nU::BallMatrix: Upper triangular factor\np::Vector{Int}: Permutation vector (pivoting)\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.interval_gaussian_elimination","page":"Linear Systems","title":"BallArithmetic.interval_gaussian_elimination","text":"interval_gaussian_elimination(A::BallMatrix{T}, b::BallVector{T};\n                              pivoting::Symbol=:partial,\n                              store_factors::Bool=false) where {T}\n\nSolve Ax = b using interval Gaussian elimination with partial pivoting.\n\nAlgorithm\n\nForward elimination with partial pivoting:\nFor each column k, find pivot with maximum magnitude\nSwap rows if needed\nEliminate entries below pivot\nCheck for singular matrix (zero on diagonal)\nBackward substitution:\nSolve Ux = y from bottom to top\nxi = (yi - Σ{j>i} u{ij}xj) / u{ii}\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\npivoting: Pivoting strategy (:partial or :none)\nstore_factors: Whether to store L and U factors\n\nReturns\n\nGaussianEliminationResult with solution and factorization information.\n\nExample\n\nA = BallMatrix([2.0 1.0 1.0; 4.0 3.0 3.0; 8.0 7.0 9.0], fill(1e-10, 3, 3))\nb = BallVector([4.0, 10.0, 24.0], fill(1e-10, 3))\n\nresult = interval_gaussian_elimination(A, b)\n\nif result.success\n    println(\"Solution: \", result.solution)\nelseif result.singular\n    println(\"Matrix is singular\")\nend\n\nNotes\n\nO(n³) complexity\nDetects singularity during elimination\nPartial pivoting improves numerical stability\nCan suffer from overestimation (wrapping effect)\nPreconditioning recommended for better accuracy\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.interval_gaussian_elimination_det","page":"Linear Systems","title":"BallArithmetic.interval_gaussian_elimination_det","text":"interval_gaussian_elimination_det(A::BallMatrix{T}) where {T}\n\nCompute determinant enclosure using Gaussian elimination.\n\nAlgorithm\n\nThe determinant is the product of diagonal elements after elimination:     det(PA) = ∏{i=1}^n u{ii} × sign(permutation)\n\nArguments\n\nA: Square ball matrix (n×n)\n\nReturns\n\nBall enclosure of the determinant.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0], fill(1e-10, 2, 2))\ndet_enclosure = interval_gaussian_elimination_det(A)\nprintln(\"det(A) ∈ \", det_enclosure)\n\nNotes\n\nO(n³) complexity\nCan suffer from overestimation\nZero in result indicates possible singularity\nUseful for singularity detection\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_regular_gaussian_elimination","page":"Linear Systems","title":"BallArithmetic.is_regular_gaussian_elimination","text":"is_regular_gaussian_elimination(A::BallMatrix{T}) where {T}\n\nTest if matrix [A] contains only regular (nonsingular) matrices using Gaussian elimination.\n\nAlgorithm\n\nPerform Gaussian elimination and check if zero appears on diagonal. If zero does NOT appear, matrix is proven regular.\n\nArguments\n\nA: Square ball matrix (n×n)\n\nReturns\n\ntrue if matrix is proven regular\nfalse if test is inconclusive\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(1e-10, 2, 2))\n\nif is_regular_gaussian_elimination(A)\n    println(\"Matrix is regular\")\nelse\n    println(\"Cannot determine regularity\")\nend\n\nNotes\n\nSufficient but not necessary test\nO(n³) complexity\nIf returns true, regularity is guaranteed\nIf returns false, matrix may still be regular\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.IterativeResult","page":"Linear Systems","title":"BallArithmetic.IterativeResult","text":"IterativeResult{T, VT}\n\nResult from iterative interval linear system solver.\n\nFields\n\nsolution::VT: Enclosure of the solution set\nconverged::Bool: Whether the iteration converged\niterations::Int: Number of iterations performed\nfinal_width::T: Maximum width of final solution components\nconvergence_rate::T: Observed convergence rate (ratio of successive widths)\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.interval_gauss_seidel","page":"Linear Systems","title":"BallArithmetic.interval_gauss_seidel","text":"interval_gauss_seidel(A::BallMatrix{T}, b::BallVector{T};\n                      x0::Union{Nothing, BallVector{T}}=nothing,\n                      max_iterations::Int=100,\n                      tol::T=T(1e-10),\n                      use_epsilon_inflation::Bool=true,\n                      ϵ::T=T(1e-15),\n                      r::T=T(0.001)) where {T}\n\nSolve Ax = b using interval Gauss-Seidel iteration.\n\nAlgorithm\n\nThe Gauss-Seidel method updates each component x_i using:\n\nx_i^(k+1) = (b_i - Σ_{j<i} a_{ij}x_j^(k+1) - Σ_{j>i} a_{ij}x_j^(k)) / a_{ii}\n\nwhere updated components x_j^(k+1) for j < i are used immediately.\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\nx0: Initial enclosure (computed if not provided)\nmax_iterations: Maximum number of iterations\ntol: Convergence tolerance (maximum component width)\nuse_epsilon_inflation: Apply ε-inflation before intersection\nϵ: Absolute inflation factor\nr: Relative inflation factor\n\nReturns\n\nIterativeResult with solution enclosure and convergence information.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(1e-10, 2, 2))\nb = BallVector([5.0, 4.0], fill(1e-10, 2))\n\nresult = interval_gauss_seidel(A, b)\n\nif result.converged\n    println(\"Solution: \", result.solution)\n    println(\"Iterations: \", result.iterations)\nend\n\nNotes\n\nGenerally converges faster than Jacobi method\nConverges for strictly diagonally dominant matrices\nUses most recent updates immediately (sequential updates)\nε-inflation helps ensure non-empty intersection\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.interval_jacobi","page":"Linear Systems","title":"BallArithmetic.interval_jacobi","text":"interval_jacobi(A::BallMatrix{T}, b::BallVector{T};\n                x0::Union{Nothing, BallVector{T}}=nothing,\n                max_iterations::Int=100,\n                tol::T=T(1e-10),\n                use_epsilon_inflation::Bool=true,\n                ϵ::T=T(1e-15),\n                r::T=T(0.001)) where {T}\n\nSolve Ax = b using interval Jacobi iteration.\n\nAlgorithm\n\nThe Jacobi method updates all components simultaneously:\n\nx_i^(k+1) = (b_i - Σ_{j≠i} a_{ij}x_j^(k)) / a_{ii}\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\nx0: Initial enclosure (computed if not provided)\nmax_iterations: Maximum number of iterations\ntol: Convergence tolerance (maximum component width)\nuse_epsilon_inflation: Apply ε-inflation before intersection\nϵ: Absolute inflation factor\nr: Relative inflation factor\n\nReturns\n\nIterativeResult with solution enclosure and convergence information.\n\nExample\n\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(1e-10, 2, 2))\nb = BallVector([7.0, 6.0], fill(1e-10, 2))\n\nresult = interval_jacobi(A, b)\n\nif result.converged\n    println(\"Solution: \", result.solution)\n    println(\"Convergence rate: \", result.convergence_rate)\nend\n\nNotes\n\nEasily parallelizable (all updates independent)\nConverges for strictly diagonally dominant matrices\nGenerally slower than Gauss-Seidel but more parallelizable\nAll components updated simultaneously (parallel updates)\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.HBRResult","page":"Linear Systems","title":"BallArithmetic.HBRResult","text":"HBRResult{T, VT}\n\nResult from Hansen-Bliek-Rohn method.\n\nFields\n\nsolution::VT: Tight solution enclosure\nsuccess::Bool: Whether all systems solved successfully\nnum_systems_solved::Int: Number of real systems solved (≤ 2n)\nmax_residual::T: Maximum residual from solved systems\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.hbr_method","page":"Linear Systems","title":"BallArithmetic.hbr_method","text":"hbr_method(A::BallMatrix{T}, b::BallVector{T};\n           preconditioner::Union{Nothing, Matrix{T}}=nothing,\n           check_residuals::Bool=true,\n           residual_tol::T=T(1e-8)) where {T}\n\nCompute tight enclosure of Ax = b using Hansen-Bliek-Rohn method.\n\nAlgorithm\n\nThe HBR method computes the hull of the solution set by solving 2n real systems:\n\nFor each component i = 1, ..., n:\n\nCompute lower bound: Solve Aσ^i x = bc where σ^i selects extremal matrix\nCompute upper bound: Solve Aτ^i x = bc where τ^i selects opposite extremal matrix\n\nThe extremal matrices are chosen to minimize/maximize the i-th component.\n\nMathematical Details\n\nFor minimizing x_i:\n\nChoose Aσ entries: aij = inf(Aij) if sgn(Ĉji) ≥ 0, else sup(A_ij) where Ĉ = C^(-1) is the inverse preconditioner\n\nFor maximizing x_i:\n\nFlip the selection rule\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\npreconditioner: Approximate inverse C ≈ A^(-1) (computed if not provided)\ncheck_residuals: Verify solutions satisfy Oettli-Prager condition\nresidual_tol: Tolerance for residual checking\n\nReturns\n\nHBRResult with tight solution enclosure.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\nb = BallVector([3.0, 3.0], fill(0.1, 2))\n\nresult = hbr_method(A, b)\n\nif result.success\n    println(\"Tight solution: \", result.solution)\n    println(\"Systems solved: \", result.num_systems_solved)\nend\n\nNotes\n\nO(n⁴) complexity - expensive but provides tightest enclosures\nSolves 2n real linear systems\nMore accurate than Krawczyk or iterative methods\nRecommended when high accuracy is required and n is small (n ≤ 20)\nRequires good preconditioner for optimal vertex selection\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.hbr_method_simple","page":"Linear Systems","title":"BallArithmetic.hbr_method_simple","text":"hbr_method_simple(A::BallMatrix{T}, b::BallVector{T}) where {T}\n\nSimplified HBR method without preconditioner optimization.\n\nUses identity matrix as preconditioner, which may give suboptimal but still valid bounds.\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\n\nReturns\n\nHBRResult with solution enclosure.\n\nExample\n\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(0.05, 2, 2))\nb = BallVector([5.0, 4.0], fill(0.05, 2))\n\nresult = hbr_method_simple(A, b)\nprintln(\"Solution: \", result.solution)\n\nNotes\n\nSimpler but may not give tightest possible bounds\nUses identity matrix for vertex selection\nFaster preconditioner computation\nStill O(n⁴) due to 2n system solves\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.ShavingResult","page":"Linear Systems","title":"BallArithmetic.ShavingResult","text":"ShavingResult{T, VT}\n\nResult from interval shaving method.\n\nFields\n\nsolution::VT: Shaved (refined) solution enclosure\nshaved_amount::T: Total amount shaved from all boundaries\niterations::Int: Number of shaving passes performed\ncomponents_shaved::Int: Number of component boundaries that were improved\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.interval_shaving","page":"Linear Systems","title":"BallArithmetic.interval_shaving","text":"interval_shaving(A::BallMatrix{T}, b::BallVector{T}, x0::BallVector{T};\n                 max_iterations::Int=10,\n                 min_improvement::T=T(1e-6),\n                 R::Union{Nothing, Matrix{T}}=nothing) where {T}\n\nRefine solution enclosure x0 by shaving infeasible boundaries using Sherman-Morrison updates.\n\nAlgorithm\n\nFor each component i and each boundary (lower/upper):\n\nFix x_i at its boundary value\nUpdate inverse using Sherman-Morrison formula\nCompute bounds on x_i from remaining equations\nIf bound excludes fixed value, shrink interval\nRepeat until no significant improvement\n\nMathematical Details\n\nWhen fixing xi = α, the system becomes:     A * x = b  with  xi = α\n\nThis is equivalent to:     (A with i-th column replaced by e_i) * x' = b - α * A[:,i]\n\nThe inverse can be updated efficiently using Sherman-Morrison formula.\n\nArguments\n\nA: Coefficient ball matrix (n×n)\nb: Right-hand side ball vector (n)\nx0: Initial solution enclosure to be refined\nmax_iterations: Maximum number of shaving passes\nmin_improvement: Minimum relative improvement to continue shaving\nR: Preconditioner A^(-1) (computed if not provided)\n\nReturns\n\nShavingResult with refined solution enclosure.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\nb = BallVector([4.0, 3.0], fill(0.1, 2))\n\n# Get initial enclosure (e.g., from Krawczyk)\nresult_krawczyk = krawczyk_linear_system(A, b)\nx0 = result_krawczyk.solution\n\n# Refine with shaving\nresult_shaved = interval_shaving(A, b, x0)\n\nprintln(\"Original width: \", maximum(rad(x0)))\nprintln(\"Shaved width: \", maximum(rad(result_shaved.solution)))\nprintln(\"Improvement: \", result_shaved.shaved_amount)\n\nNotes\n\nO(n²) per boundary test (efficient!)\nTypically applied after Krawczyk or other method\nCan significantly reduce interval widths\nDiminishing returns after few iterations\nSherman-Morrison makes this practical\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.sherman_morrison_inverse_update","page":"Linear Systems","title":"BallArithmetic.sherman_morrison_inverse_update","text":"sherman_morrison_inverse_update(A_inv::Matrix{T}, u::Vector{T}, v::Vector{T}) where {T}\n\nCompute (A + uv^T)^(-1) using Sherman-Morrison formula.\n\nSherman-Morrison Formula\n\n(A + uv^T)^(-1) = A^(-1) - (A^(-1)uv^T A^(-1)) / (1 + v^T A^(-1)u)\n\nThis allows O(n²) update of inverse for rank-1 perturbation instead of O(n³) recomputation.\n\nArguments\n\nA_inv: Inverse of base matrix A (n×n)\nu: First vector of rank-1 update (n)\nv: Second vector of rank-1 update (n)\n\nReturns\n\n(A + uv^T)^(-1)\n\nExample\n\nA = [3.0 1.0; 1.0 2.0]\nA_inv = inv(A)\nu = [1.0, 0.0]\nv = [0.0, 1.0]\n\n# Efficiently compute inv(A + u*v')\nA_updated_inv = sherman_morrison_inverse_update(A_inv, u, v)\n\nNotes\n\nO(n²) complexity vs O(n³) for full inverse\nNumerically stable if |1 + v^T A^(-1)u| is not too small\nCritical for efficient shaving implementation\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.PreconditionerType","page":"Linear Systems","title":"BallArithmetic.PreconditionerType","text":"PreconditionerType\n\nEnumeration of available preconditioning strategies.\n\n:midpoint: C = A_c^(-1) (inverse of midpoint)\n:lu: C from LU factorization of midpoint\n:ldlt: C from LDLT factorization of midpoint (symmetric matrices)\n:identity: C = I (no preconditioning)\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.PreconditionerResult","page":"Linear Systems","title":"BallArithmetic.PreconditionerResult","text":"PreconditionerResult{T}\n\nResult from preconditioner computation.\n\nFields\n\npreconditioner::Matrix{T}: Approximate inverse C\nmethod::PreconditionerType: Method used\ncondition_number::T: Estimated condition number\nsuccess::Bool: Whether computation succeeded\nfactorization::Any: Stored factorization (for LU/LDLT)\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.compute_preconditioner","page":"Linear Systems","title":"BallArithmetic.compute_preconditioner","text":"compute_preconditioner(A::BallMatrix{T};\n                      method::Symbol=:midpoint,\n                      check_conditioning::Bool=true) where {T}\n\nCompute preconditioner C ≈ A^(-1) for interval matrix A.\n\nMethods\n\n:midpoint: Direct inverse of A_c (default, simplest)\n:lu: LU factorization of A_c (more stable)\n:ldlt: LDLT factorization of A_c (for symmetric A)\n:identity: Identity matrix (no preconditioning)\n\nArguments\n\nA: Interval matrix to precondition\nmethod: Preconditioning strategy\ncheck_conditioning: Compute and warn about condition number\n\nReturns\n\nPreconditionerResult with approximate inverse and diagnostic info.\n\nExample\n\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(0.1, 2, 2))\n\n# Midpoint inverse (default)\nprec = compute_preconditioner(A)\nC = prec.preconditioner\n\n# LU factorization (more stable)\nprec_lu = compute_preconditioner(A, method=:lu)\n\nNotes\n\nMidpoint inverse: O(n³), simplest but may be numerically unstable\nLU factorization: O(n³) once, O(n²) per solve, more stable\nLDLT factorization: O(n³/6) once, O(n²) per solve, only for symmetric\nIdentity: O(1), use for well-conditioned or diagonally dominant matrices\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.apply_preconditioner","page":"Linear Systems","title":"BallArithmetic.apply_preconditioner","text":"apply_preconditioner(prec::PreconditionerResult{T}, v::Vector{T}) where {T}\n\nApply preconditioner to vector: compute C * v.\n\nIf factorization is available, uses it for efficiency.\n\nArguments\n\nprec: Preconditioner result from compute_preconditioner\nv: Vector to multiply\n\nReturns\n\nC * v\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\nprec = compute_preconditioner(A, method=:lu)\n\nb = [5.0, 4.0]\nCb = apply_preconditioner(prec, b)\n\n\n\n\n\napply_preconditioner(prec::PreconditionerResult{T}, M::Matrix{T}) where {T}\n\nApply preconditioner to matrix: compute C * M.\n\nArguments\n\nprec: Preconditioner result\nM: Matrix to multiply\n\nReturns\n\nC * M\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_well_preconditioned","page":"Linear Systems","title":"BallArithmetic.is_well_preconditioned","text":"is_well_preconditioned(A::BallMatrix{T}, prec::PreconditionerResult{T};\n                      threshold::T=T(0.5)) where {T}\n\nCheck if preconditioner is effective.\n\nA good preconditioner should make ‖I - CA‖ small (ideally < 0.5).\n\nArguments\n\nA: Original interval matrix\nprec: Preconditioner result\nthreshold: Threshold for ‖I - CA‖ (default 0.5)\n\nReturns\n\ntrue if ‖I - CA‖ < threshold\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\nprec = compute_preconditioner(A)\n\nif is_well_preconditioned(A, prec)\n    println(\"Good preconditioner\")\nend\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.OverdeterminedResult","page":"Linear Systems","title":"BallArithmetic.OverdeterminedResult","text":"OverdeterminedResult{T, VT}\n\nResult from overdetermined interval linear system solver.\n\nFields\n\nsolution::VT: Solution enclosure (or empty if unsolvable)\nsolvable::Bool: Whether system is proven solvable\nmethod::Symbol: Method used\nsubsystems_checked::Int: Number of subsystems examined\nresidual::T: Maximum residual norm\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.subsquares_method","page":"Linear Systems","title":"BallArithmetic.subsquares_method","text":"subsquares_method(A::BallMatrix{T}, b::BallVector{T};\n                 max_subsystems::Int=1000,\n                 solver::Symbol=:gaussian_elimination) where {T}\n\nSolve overdetermined system Ax = b using subsquares approach.\n\nAlgorithm\n\nFor m×n system with m > n:\n\nConsider all (m choose n) square subsystems\nSolve each n×n subsystem\nCheck if solution satisfies all m equations (Oettli-Prager)\nTake hull of all valid solutions\n\nMathematical Background\n\nA solution exists if at least one n×n subsystem has a solution that satisfies all m equations.\n\nArguments\n\nA: Coefficient ball matrix (m×n, m > n)\nb: Right-hand side ball vector (m)\nmax_subsystems: Maximum number of subsystems to check\nsolver: Solver for square subsystems (:gaussian_elimination, :krawczyk)\n\nReturns\n\nOverdeterminedResult with solution enclosure.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0; 3.0 1.0], fill(0.1, 3, 2))\nb = BallVector([3.0, 3.0, 4.0], fill(0.1, 3))\n\nresult = subsquares_method(A, b)\n\nif result.solvable\n    println(\"Solution: \", result.solution)\n    println(\"Checked \", result.subsystems_checked, \" subsystems\")\nend\n\nNotes\n\nCombinatorial complexity: O(C(m,n) × n³)\nOnly practical for small m and n\nGuaranteed to find solution if one exists (complete method)\nMay be very slow for large m or n\nRecommended: m ≤ 20, n ≤ 10\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.multi_jacobi_method","page":"Linear Systems","title":"BallArithmetic.multi_jacobi_method","text":"multi_jacobi_method(A::BallMatrix{T}, b::BallVector{T};\n                   x0::Union{Nothing, BallVector{T}}=nothing,\n                   max_iterations::Int=100,\n                   tol::T=T(1e-10)) where {T}\n\nSolve overdetermined system using Multi-Jacobi iteration.\n\nAlgorithm\n\nFor each variable x_j, compute intersection of bounds from all equations:\n\nx_j^(k+1) = ⋂_{i=1}^m [(b_i - ∑_{l≠j} a_{il}x_l^(k)) / a_{ij}]\n\nwhere the intersection is over all rows i where a_{ij} ≠ 0.\n\nArguments\n\nA: Coefficient ball matrix (m×n, m > n)\nb: Right-hand side ball vector (m)\nx0: Initial enclosure (computed if not provided)\nmax_iterations: Maximum iterations\ntol: Convergence tolerance\n\nReturns\n\nOverdeterminedResult with solution enclosure.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0; 2.0 3.0], fill(0.1, 3, 2))\nb = BallVector([4.0, 3.0, 5.0], fill(0.1, 3))\n\nresult = multi_jacobi_method(A, b)\n\nif result.solvable\n    println(\"Solution: \", result.solution)\n    println(\"Iterations: \", result.subsystems_checked)\nend\n\nNotes\n\nO(mn²) per iteration - faster than subsquares\nMay not converge for all systems\nEmpty intersection indicates unsolvability\nWorks well when system is \"nearly square\" or well-conditioned\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.interval_least_squares","page":"Linear Systems","title":"BallArithmetic.interval_least_squares","text":"interval_least_squares(A::BallMatrix{T}, b::BallVector{T};\n                      method::Symbol=:normal_equations) where {T}\n\nCompute interval least squares solution to overdetermined system.\n\nMinimizes ||Ax - b||² over the interval matrix/vector.\n\nArguments\n\nA: Coefficient ball matrix (m×n, m ≥ n)\nb: Right-hand side ball vector (m)\nmethod: Solution method (:normal_equations or :qr)\n\nReturns\n\nOverdeterminedResult with least squares solution enclosure.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0; 3.0 1.0], fill(0.1, 3, 2))\nb = BallVector([3.1, 2.9, 4.2], fill(0.05, 3))\n\nresult = interval_least_squares(A, b)\nprintln(\"LS solution: \", result.solution)\n\nNotes\n\nSolves normal equations: A^T A x = A^T b\nO(mn² + n³) complexity\nMay not satisfy all equations exactly\nUseful when exact solution doesn't exist\nReturns minimum norm solution in interval sense\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.VerifiedLinearSystemResult","page":"Linear Systems","title":"BallArithmetic.VerifiedLinearSystemResult","text":"VerifiedLinearSystemResult\n\nResult structure for verified linear system solution.\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.verified_linear_solve_hmatrix","page":"Linear Systems","title":"BallArithmetic.verified_linear_solve_hmatrix","text":"verified_linear_solve_hmatrix(A::BallMatrix, b::BallVector;\n                               method=:improved_method_a,\n                               R=nothing,\n                               x_approx=nothing,\n                               max_iterations=1,\n                               compute_perron_vector=true)\n\nCompute verified error bounds for the solution of Ax = b using H-matrix properties.\n\nArguments\n\nA: Coefficient ball matrix\nb: Right-hand side ball vector\nmethod: Verification method to use\n:rump_original - Original Rump (2013) bound (Theorem 3.1)\n:minamihata_2015 - Minamihata et al. (2015) bound (Theorem 3.2, m=1)\n:improved_method_a - Improved bound for Method (a) (Theorem 3.3, default)\n:improved_method_b - Improved bound for Method (b) (Corollary 3.2)\nR: Approximate inverse of A (computed if not provided)\nx_approx: Approximate solution (computed if not provided)\nmax_iterations: Number of refinement iterations for improved bounds\ncompute_perron_vector: Whether to compute Perron vector (more accurate)\n\nReturns\n\nVerifiedLinearSystemResult containing verified error bounds\n\nMethod Comparison\n\nMethod (a): Uses C = [▽(RA), △(RA)] - more expensive but tighter\nMethod (b): Uses C = [▽(RA), ▽(RA) + 2nu|R||A|] - half cost, weaker bounds\n\nThe improved methods (Theorem 3.3 and Corollary 3.2) provide tighter bounds than conventional approaches, especially for ill-conditioned systems.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(1e-10, 2, 2))\nb = BallVector([5.0, 4.0], fill(1e-10, 2))\n\nresult = verified_linear_solve_hmatrix(A, b; method=:improved_method_a)\n\nprintln(\"Verified: \", result.verified)\nprintln(\"Solution: \", result.x_approx)\nprintln(\"Error bound: \", result.error_bound)\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.sylvester_miyajima_enclosure","page":"Linear Systems","title":"BallArithmetic.sylvester_miyajima_enclosure","text":"sylvester_miyajima_enclosure(A, B, C, X̃)\n\nCompute a Miyajima-style verified enclosure for the solution of the Sylvester problem A * X + X * B = C.  The method follows the componentwise certificate from Ref. [3] and returns a BallMatrix whose midpoint is the supplied approximation X̃ and whose radii enclose the exact solution entrywise.\n\nThe routine raises an error when the spectral gaps λ_i(A) + λ_j(B) vanish or when the contraction bound is not satisfied.\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.triangular_sylvester_miyajima_enclosure","page":"Linear Systems","title":"BallArithmetic.triangular_sylvester_miyajima_enclosure","text":"triangular_sylvester_miyajima_enclosure(T, k)\n\nConstruct the Miyajima enclosure for the Sylvester system associated with the upper-triangular matrix T partitioned as\n\nT = [T₁₁  T₁₂;\n     0    T₂₂],\n\nwhere T₁₁ is k × k.  The enclosure is computed for the solution Y₂ of the transformed Sylvester equation T₂₂' * Y₂ - Y₂ * T₁₁' = T₁₂'.  Forming the standard Sylvester data A = T₂₂', B = -T₁₁', and C = T₁₂', the routine solves for an approximate Y₂ and then calls sylvester_miyajima_enclosure to obtain a verified bound.  The returned BallMatrix encloses the exact Y₂ entrywise.\n\nThe matrix T must be square and upper triangular, and the block size k must satisfy 1 ≤ k < size(T, 1).\n\n\n\n\n\ntriangular_sylvester_miyajima_enclosure(T_ball::BallMatrix, k::Integer)\n\nMiyajima enclosure for the Sylvester system when the triangular matrix T is given as a BallMatrix (midpoint + radii).\n\nThe midpoint mid(T_ball) is used to solve the Sylvester equation via the scalar method. The radii of T_ball produce a first-order perturbation bound on the solution Y, which inflates the returned enclosure.\n\nAlgorithm\n\nSolve on midpoint: Y_mid = triangular_sylvester_miyajima_enclosure(mid(T_ball), k)\nCompute separation: sep = min_{i,j} |T₁₁[i,i] - T₂₂[j,j]| (lower-bounded rigorously)\nFirst-order perturbation bound on Y from Tball radii: δY ≤ sep⁻¹ · (‖ΔT₂₂‖·‖Y‖ + ‖ΔT₁₁‖·‖Y‖ + ‖ΔT₁₂‖) where `ΔTij` are the radius sub-blocks\nInflate: BallMatrix(mid(Y_mid), rad(Y_mid) .+ δY)\n\nThe matrix T_ball must be square, and mid(T_ball) must be upper triangular.\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.RegularityResult","page":"Linear Systems","title":"BallArithmetic.RegularityResult","text":"RegularityResult{T}\n\nResult from regularity testing.\n\nFields\n\nis_regular::Bool: True if proven regular, false if inconclusive\nmethod::Symbol: Method used for testing\ncertificate::T: Numerical certificate (e.g., separation value)\nis_definitive::Bool: Whether result is definitive or just sufficient condition\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.is_regular","page":"Linear Systems","title":"BallArithmetic.is_regular","text":"is_regular(A::BallMatrix{T};\n          methods::Vector{Symbol}=[:sufficient_condition, :gershgorin, :diagonal_dominance],\n          verbose::Bool=false) where {T}\n\nTest regularity using multiple methods.\n\nTries several sufficient conditions in order until one succeeds.\n\nArguments\n\nA: Interval matrix (n×n)\nmethods: Vector of methods to try (in order)\nverbose: Print information about each method\n\nAvailable Methods\n\n:sufficient_condition: Eigenvalue-based (Theorem 11.12)\n:gershgorin: Gershgorin circle theorem\n:diagonal_dominance: Strict diagonal dominance\n\nReturns\n\nRegularityResult from first successful method, or last result if all fail.\n\nExample\n\nA = BallMatrix([3.0 0.5; 0.5 2.0], fill(0.1, 2, 2))\n\nresult = is_regular(A, verbose=true)\n\nif result.is_regular\n    println(\"Matrix is regular (proven by \", result.method, \")\")\nelse\n    println(\"Regularity could not be proven\")\nend\n\nNotes\n\nTries multiple sufficient conditions\nReturns true only if regularity is proven\nFalse result is inconclusive (matrix may still be regular)\nOrder methods by speed: diagonaldominance → gershgorin → sufficientcondition\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_regular_sufficient_condition","page":"Linear Systems","title":"BallArithmetic.is_regular_sufficient_condition","text":"is_regular_sufficient_condition(A::BallMatrix{T}) where {T}\n\nTest regularity using sufficient condition from Theorem 11.12 (Horáček, p. 183).\n\nSufficient Condition\n\nMatrix [A] is regular if:     λmax(AΔ^T AΔ) < λmin(Ac^T Ac)\n\nwhere Ac is center and AΔ is radius matrix.\n\nArguments\n\nA: Interval matrix (n×n)\n\nReturns\n\nRegularityResult with test outcome.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(0.05, 2, 2))\n\nresult = is_regular_sufficient_condition(A)\n\nif result.is_regular\n    println(\"Matrix is proven regular\")\n    println(\"Separation: \", result.certificate)\nelse\n    println(\"Test inconclusive\")\nend\n\nNotes\n\nO(n³) complexity (eigenvalue computation)\nSufficient but not necessary\nIf returns true, regularity is guaranteed\nIf returns false, matrix may still be regular\nWorks well for small radius matrices\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_regular_gershgorin","page":"Linear Systems","title":"BallArithmetic.is_regular_gershgorin","text":"is_regular_gershgorin(A::BallMatrix{T}) where {T}\n\nTest regularity using Gershgorin circle theorem.\n\nGershgorin Criterion\n\nMatrix [A] is regular if for all i, 0 is not in the Gershgorin disc:     Di = {z : |z - a{ii}| ≤ ∑{j≠i} |a{ij}|}\n\nArguments\n\nA: Interval matrix (n×n)\n\nReturns\n\nRegularityResult with test outcome.\n\nExample\n\nA = BallMatrix([4.0 1.0 0.5; 0.5 3.0 0.5; 0.5 0.5 2.0], fill(0.1, 3, 3))\n\nresult = is_regular_gershgorin(A)\n\nif result.is_regular\n    println(\"Matrix is proven regular by Gershgorin\")\nend\n\nNotes\n\nO(n²) complexity - very fast\nSufficient but not necessary\nWorks well for diagonally dominant matrices\nConservative for general matrices\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_regular_diagonal_dominance","page":"Linear Systems","title":"BallArithmetic.is_regular_diagonal_dominance","text":"is_regular_diagonal_dominance(A::BallMatrix{T};\n                              strict::Bool=true) where {T}\n\nTest regularity using diagonal dominance.\n\nCriterion\n\nMatrix [A] is regular if it is strictly diagonally dominant:     |a{ii}| > ∑{j≠i} |a_{ij}|  for all i\n\nArguments\n\nA: Interval matrix (n×n)\nstrict: Require strict (>) or weak (≥) diagonal dominance\n\nReturns\n\nRegularityResult with test outcome.\n\nExample\n\nA = BallMatrix([5.0 1.0 1.0; 1.0 4.0 0.5; 0.5 1.0 3.0], fill(0.1, 3, 3))\n\nresult = is_regular_diagonal_dominance(A)\n\nif result.is_regular\n    println(\"Matrix is strictly diagonally dominant\")\nend\n\nNotes\n\nO(n²) complexity\nVery fast test\nSufficient for regularity\nMany practical matrices satisfy this\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.is_singular_sufficient_condition","page":"Linear Systems","title":"BallArithmetic.is_singular_sufficient_condition","text":"is_singular_sufficient_condition(A::BallMatrix{T}) where {T}\n\nTest singularity using sufficient condition from Theorem 11.13 (Horáček, p. 183).\n\nSufficient Condition for Singularity\n\nMatrix [A] contains at least one singular matrix if:     λmin(Ac^T Ac) < λmax(AΔ^T AΔ)\n\nThis is the dual of the regularity condition.\n\nArguments\n\nA: Interval matrix (n×n)\n\nReturns\n\ntrue if proven singular, false if inconclusive.\n\nExample\n\nA = BallMatrix([1.0 1.0; 1.0 1.0], fill(0.05, 2, 2))\n\nif is_singular_sufficient_condition(A)\n    println(\"Matrix contains singular matrices\")\nend\n\nNotes\n\nO(n³) complexity\nSufficient but not necessary\nDual of regularity test\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.DeterminantResult","page":"Linear Systems","title":"BallArithmetic.DeterminantResult","text":"DeterminantResult{T}\n\nResult from interval determinant computation.\n\nFields\n\ndeterminant::Ball{T}: Enclosure of determinant\nmethod::Symbol: Method used\ncomputation_time::T: Time spent (optional)\ntight::Bool: Whether enclosure is known to be tight\n\n\n\n\n\n","category":"type"},{"location":"api/linearsystems/#BallArithmetic.interval_det","page":"Linear Systems","title":"BallArithmetic.interval_det","text":"interval_det(A::BallMatrix{T};\n            method::Symbol=:auto,\n            check_regularity::Bool=true) where {T}\n\nCompute interval determinant enclosure using specified or automatic method.\n\nMethods\n\n:auto: Choose automatically based on matrix size and properties\n:hadamard: Hadamard inequality (fast, conservative)\n:gershgorin: Gershgorin-based bounds (fast, moderate)\n:gaussian_elimination: Gaussian elimination (moderate speed, good accuracy)\n:cramer: Cramer's rule (slow, exact for small n)\n\nArguments\n\nA: Interval matrix (n×n)\nmethod: Computation method\ncheck_regularity: First check if matrix is regular\n\nReturns\n\nDeterminantResult with determinant enclosure.\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\n\n# Automatic method selection\nresult = interval_det(A)\nprintln(\"det(A) ∈ \", result.determinant)\n\n# Specific method\nresult_hadamard = interval_det(A, method=:hadamard)\n\nNotes\n\nAuto mode chooses:\nCramer for n ≤ 3\nGaussian elimination for n ≤ 20\nHadamard for n > 20\nCheck regularity first to avoid wasted computation\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.det_hadamard","page":"Linear Systems","title":"BallArithmetic.det_hadamard","text":"det_hadamard(A::BallMatrix{T}) where {T}\n\nCompute determinant bound using Hadamard's inequality.\n\nHadamard's Inequality\n\nFor any n×n matrix A:     |det(A)| ≤ ∏{i=1}^n ||ai||\n\nwhere a_i is the i-th row of A.\n\nArguments\n\nA: Interval matrix (n×n)\n\nReturns\n\nDeterminantResult with determinant bounds.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0], fill(0.1, 2, 2))\n\nresult = det_hadamard(A)\nprintln(\"det(A) ∈ \", result.determinant)\n\nNotes\n\nO(n²) complexity - very fast\nProvides only upper bound on |det(A)|\nVery conservative for most matrices\nUseful for quick nonsingularity check\nNot tight except for special cases\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.det_gershgorin","page":"Linear Systems","title":"BallArithmetic.det_gershgorin","text":"det_gershgorin(A::BallMatrix{T}) where {T}\n\nCompute determinant bound using Gershgorin circle theorem.\n\nGershgorin Approach\n\nEigenvalues lie in union of Gershgorin discs:     λi ∈ {z : |z - a{ii}| ≤ ∑{j≠i} |a{ij}|}\n\nDeterminant is product of eigenvalues.\n\nArguments\n\nA: Interval matrix (n×n)\n\nReturns\n\nDeterminantResult with determinant bounds.\n\nExample\n\nA = BallMatrix([3.0 0.5; 0.5 2.0], fill(0.1, 2, 2))\n\nresult = det_gershgorin(A)\nprintln(\"det(A) ∈ \", result.determinant)\n\nNotes\n\nO(n²) complexity - fast\nCan provide tighter bounds than Hadamard for diagonally dominant matrices\nConservative for general matrices\nUses product of disc bounds\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.det_cramer","page":"Linear Systems","title":"BallArithmetic.det_cramer","text":"det_cramer(A::BallMatrix{T}) where {T}\n\nCompute determinant using Cramer's rule (cofactor expansion).\n\nWarning\n\nThis method has O(n!) complexity and should only be used for n ≤ 4.\n\nArguments\n\nA: Small interval matrix (n ≤ 4)\n\nReturns\n\nDeterminantResult with exact interval determinant.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 3.0], fill(0.05, 2, 2))\n\nresult = det_cramer(A)\nprintln(\"det(A) ∈ \", result.determinant)  # Exact result\n\nNotes\n\nO(n!) complexity - only for tiny matrices\nProvides exact interval arithmetic result\nTight enclosure (no overestimation from method)\nWrapping effect still present\n\n\n\n\n\n","category":"function"},{"location":"api/linearsystems/#BallArithmetic.contains_zero","page":"Linear Systems","title":"BallArithmetic.contains_zero","text":"contains_zero(det_result::DeterminantResult{T}) where {T}\n\nCheck if determinant enclosure contains zero (possible singularity).\n\nArguments\n\ndet_result: Result from determinant computation\n\nReturns\n\ntrue if 0 ∈ det(A), false otherwise.\n\nExample\n\nA = BallMatrix([1.0 1.0; 1.0 1.0], fill(0.1, 2, 2))\nresult = interval_det(A)\n\nif contains_zero(result)\n    println(\"Matrix may be singular\")\nend\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#API-Eigenvalues-and-SVD","page":"Eigenvalues & SVD","title":"API - Eigenvalues & SVD","text":"Verified eigenvalue and singular value computation.","category":"section"},{"location":"api/eigenvalues/#Standard-Eigenvalues","page":"Eigenvalues & SVD","title":"Standard Eigenvalues","text":"","category":"section"},{"location":"api/eigenvalues/#Rump-2022a-Method","page":"Eigenvalues & SVD","title":"Rump 2022a Method","text":"","category":"section"},{"location":"api/eigenvalues/#Rump-Lange-2023-Method","page":"Eigenvalues & SVD","title":"Rump-Lange 2023 Method","text":"","category":"section"},{"location":"api/eigenvalues/#Generalized-Eigenvalues","page":"Eigenvalues & SVD","title":"Generalized Eigenvalues","text":"","category":"section"},{"location":"api/eigenvalues/#Singular-Value-Decomposition","page":"Eigenvalues & SVD","title":"Singular Value Decomposition","text":"","category":"section"},{"location":"api/eigenvalues/#Miyajima-VBD","page":"Eigenvalues & SVD","title":"Miyajima VBD","text":"","category":"section"},{"location":"api/eigenvalues/#Adaptive-Ogita-SVD","page":"Eigenvalues & SVD","title":"Adaptive Ogita SVD","text":"","category":"section"},{"location":"api/eigenvalues/#SVD-Caching","page":"Eigenvalues & SVD","title":"SVD Caching","text":"","category":"section"},{"location":"api/eigenvalues/#Spectral-Projectors","page":"Eigenvalues & SVD","title":"Spectral Projectors","text":"","category":"section"},{"location":"api/eigenvalues/#Block-Schur-Decomposition","page":"Eigenvalues & SVD","title":"Block Schur Decomposition","text":"","category":"section"},{"location":"api/eigenvalues/#Schur-Spectral-Projectors","page":"Eigenvalues & SVD","title":"Schur Spectral Projectors","text":"","category":"section"},{"location":"api/eigenvalues/#Schur-Refinement","page":"Eigenvalues & SVD","title":"Schur Refinement","text":"","category":"section"},{"location":"api/eigenvalues/#Riesz-Projections","page":"Eigenvalues & SVD","title":"Riesz Projections","text":"","category":"section"},{"location":"api/eigenvalues/#Singular-Value-Intervals","page":"Eigenvalues & SVD","title":"Singular Value Intervals","text":"","category":"section"},{"location":"api/eigenvalues/#BallArithmetic.RigorousEigenvaluesResult","page":"Eigenvalues & SVD","title":"BallArithmetic.RigorousEigenvaluesResult","text":"RigorousEigenvaluesResult\n\nContainer returned by rigorous_eigenvalues bundling the midpoint eigenvector factorisation, the certified eigenvalue enclosures, and the norm bounds underpinning their verification. Besides behaving like the underlying vector of eigenvalue balls, the struct exposes the interval residual, the projected residual used in the Miyajima certification, and the inverse defect (inverse * vectors - I).\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rigorous_eigenvalues","page":"Eigenvalues & SVD","title":"BallArithmetic.rigorous_eigenvalues","text":"rigorous_eigenvalues(A::BallMatrix)\n\nCompute rigorous enclosures for the eigenvalues of A, following Ref. [7].  The returned RigorousEigenvaluesResult exposes both the interval enclosures and the norm bounds used during certification.\n\nTODO: Using Miyajima's algorithm is overkill, may be worth using\n\nReferences\n\n[7] Miyajima, JCAM 246, 9 (2012)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.evbox","page":"Eigenvalues & SVD","title":"BallArithmetic.evbox","text":"evbox(A::BallMatrix{T})\n\nBackward-compatible wrapper returning only the vector of eigenvalue enclosures produced by rigorous_eigenvalues.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.Rump2022aResult","page":"Eigenvalues & SVD","title":"BallArithmetic.Rump2022aResult","text":"Rump2022aResult\n\nContainer for Rump2022a eigenvalue and eigenvector error bounds.\n\nExtends the standard eigenvalue result with:\n\nIndividual eigenvector error bounds\nCondition number estimates\nResidual-based refinements\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rump_2022a_eigenvalue_bounds","page":"Eigenvalues & SVD","title":"BallArithmetic.rump_2022a_eigenvalue_bounds","text":"rump_2022a_eigenvalue_bounds(A::BallMatrix; method=:standard, hermitian=false)\n\nCompute verified error bounds for all eigenvalues and eigenvectors following Rump (2022a).\n\nThis method provides:\n\nIndividual eigenvalue enclosures with guaranteed containment\nEigenvector error bounds for each eigenpair\nCondition number estimates for stability assessment\nResidual-based verification\n\nArguments\n\nA::BallMatrix: Square matrix for eigenvalue problem\nmethod::Symbol: Verification method\n:standard - Standard residual-based bounds (default)\n:refined - Refined bounds using Gershgorin + residuals\n:krawczyk - Krawczyk operator for sharper enclosures\nhermitian::Bool: Whether A is Hermitian (enables tighter bounds)\n\nMethod Description\n\nStandard method:\n\nFor each eigenpair (λᵢ, vᵢ), computes:\n\nResidual: rᵢ = Avᵢ - λᵢvᵢ\nEigenvalue bound: |λ̃ᵢ - λᵢ| ≤ ‖rᵢ‖/(1 - κᵢ*‖rᵢ‖)\nEigenvector bound: ‖ṽᵢ - vᵢ‖ ≤ κᵢ‖rᵢ‖/(1 - κᵢ‖rᵢ‖) where κᵢ is the condition number\n\nRefined method:\n\nCombines Gershgorin discs with residual bounds for tighter enclosures, especially effective when eigenvalues are clustered.\n\nKrawczyk method:\n\nUses interval Newton-Krawczyk operator for quadratic convergence in eigenvector refinement.\n\nReturns\n\nRump2022aResult containing verified bounds.\n\nExample\n\nA = BallMatrix([2.0 1.0; 1.0 2.0])\nresult = rump_2022a_eigenvalue_bounds(A; hermitian=true)\n\n# Access results\nλ = result.eigenvalues  # Eigenvalue balls\nκ = result.condition_numbers  # Condition numbers\nerr = result.eigenvector_errors  # Eigenvector error bounds\n\nReference\n\nRump, S.M. (2022), \"Verified Error Bounds for All Eigenvalues and Eigenvectors of a Matrix\", SIAM J. Matrix Anal. Appl. 43(4):1736–1754. DOI: 10.1137/21M1451440\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.RumpLange2023Result","page":"Eigenvalues & SVD","title":"BallArithmetic.RumpLange2023Result","text":"RumpLange2023Result\n\nContainer for RumpLange2023 eigenvalue cluster bounds.\n\nEmphasizes fast computation with clustering information:\n\nCluster structure identification\nPer-cluster error bounds\nFast bounds optimized for clustered spectra\n\nFields\n\neigenvectors::VT: Approximate eigenvectors (as ball matrix)\neigenvalues::ΛT: Certified eigenvalue enclosures\ncluster_assignments::Vector{Int}: Cluster assignments (cluster index for each eigenvalue)\ncluster_bounds::Vector{Ball{T, T}}: Cluster bounds (interval enclosure for each cluster)\nnum_clusters::Int: Number of clusters identified\ncluster_residuals::Vector{T}: Per-cluster residual norms\ncluster_separations::Vector{T}: Per-cluster separation gaps\ncluster_sizes::Vector{Int}: Cluster sizes\nverified::Bool: Overall verification status\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rump_lange_2023_cluster_bounds","page":"Eigenvalues & SVD","title":"BallArithmetic.rump_lange_2023_cluster_bounds","text":"rump_lange_2023_cluster_bounds(A::BallMatrix; hermitian=false, cluster_tol=1e-6, fast=true)\n\nCompute fast error bounds for eigenvalues with emphasis on cluster structure, following Rump & Lange (2023).\n\nThis method excels when eigenvalues form clusters, providing:\n\nFast identification of eigenvalue clusters\nTight bounds within each cluster\nOptimized computation exploiting cluster structure\nScaling to large matrices via cluster-wise processing\n\nArguments\n\nA::BallMatrix: Square matrix for eigenvalue problem\nhermitian::Bool: Whether A is Hermitian (enables faster algorithms)\ncluster_tol::Real: Tolerance for cluster identification (default: 1e-6)\nfast::Bool: Use fast approximations vs. rigorous bounds (default: true)\n\nMethod Description\n\nCluster identification:\n\nUses Gershgorin discs with connectivity analysis to identify clusters of eigenvalues that are close together. Two eigenvalues belong to the same cluster if their Gershgorin discs overlap.\n\nPer-cluster bounds:\n\nFor each cluster Ck with eigenvalues {λᵢ}ᵢ∈Ck:\n\nCompute cluster interval: [min λᵢ - δᵢ, max λᵢ + δᵢ]\nRefine using projected residuals within cluster\nApply separation bounds between clusters\n\nFast mode:\n\nWhen fast=true, uses:\n\nSingle power iteration for norms (vs. convergence)\nSimplified residual bounds\nCluster-level (vs. individual) error propagation\n\nResults in ~10x speedup with typically <2x looser bounds.\n\nReturns\n\nRumpLange2023Result containing cluster structure and bounds.\n\nExample\n\nExample usage for a matrix with two eigenvalue clusters:\n\nCreate interval matrix with clustered spectrum\nCall rump_lange_2023_cluster_bounds(A; hermitian=true)\nResult contains cluster assignments and per-cluster bounds\n\nPerformance Notes\n\nFor n×n matrix: O(n²) flops in fast mode, O(n³) in rigorous mode\nCluster count << n gives significant speedup\nMost effective when cluster separation >> cluster width\n\nReference\n\nRump, S.M. & Lange, M. (2023), \"Fast Computation of Error Bounds...\", SIAM J. Matrix Anal. Appl., to appear\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.refine_cluster_bounds","page":"Eigenvalues & SVD","title":"BallArithmetic.refine_cluster_bounds","text":"refine_cluster_bounds(result::RumpLange2023Result, A::BallMatrix; iterations=1)\n\nRefine cluster bounds using iterative residual computation.\n\nTakes an existing RumpLange2023Result and performs additional refinement iterations to tighten the bounds, particularly for well-separated clusters.\n\nArguments\n\nresult: Initial cluster bound result\nA: Original ball matrix\niterations: Number of refinement iterations (default: 1)\n\nReturns\n\nNew RumpLange2023Result with refined bounds.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.RigorousGeneralizedEigenvaluesResult","page":"Eigenvalues & SVD","title":"BallArithmetic.RigorousGeneralizedEigenvaluesResult","text":"RigorousGeneralizedEigenvaluesResult\n\nContainer returned by rigorous_generalized_eigenvalues bundling the midpoint eigenvector factorisation, the certified eigenvalue enclosures, and the norm bounds underpinning their verification. Besides behaving like the underlying vector of eigenvalue balls, the struct exposes the interval residual, the projected residual used in the Miyajima certification, and the coupling defect of the left action (left_action * B * right_vectors - I).\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rigorous_generalized_eigenvalues","page":"Eigenvalues & SVD","title":"BallArithmetic.rigorous_generalized_eigenvalues","text":"rigorous_generalized_eigenvalues(A::BallMatrix, B::BallMatrix)\n\nCompute rigorous enclosures for the eigenvalues of the generalised problem A * x = λ * B * x, following Ref. [7].  The returned RigorousGeneralizedEigenvaluesResult exposes both the interval enclosures and the norm bounds used during certification.\n\nReferences\n\n[7] Miyajima, JCAM 246, 9 (2012)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.gevbox","page":"Eigenvalues & SVD","title":"BallArithmetic.gevbox","text":"gevbox(A::BallMatrix{T}, B::BallMatrix{T})\n\nBackward-compatible wrapper returning only the vector of eigenvalue enclosures produced by rigorous_generalized_eigenvalues.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.GEVResult","page":"Eigenvalues & SVD","title":"BallArithmetic.GEVResult","text":"GEVResult\n\nResult structure for verified generalized eigenvalue problem.\n\nAll numeric fields use Float64 precision. This struct is not currently parametric; extension to other numeric types would require making it GEVResult{T}.\n\nFields\n\nsuccess::Bool: Whether verification succeeded\neigenvalue_intervals::Vector{Tuple{Float64, Float64}}: Verified intervals [λ̃ᵢ - ηᵢ, λ̃ᵢ + ηᵢ] for each eigenvalue\neigenvector_centers::Matrix{Float64}: Approximate eigenvectors (centers)\neigenvector_radii::Vector{Float64}: Verified radii ξᵢ for eigenvector balls\nbeta::Float64: Preconditioning factor β ≥ √‖B⁻¹‖₂\nglobal_bound::Float64: Global eigenvalue bound δ̂ (Theorem 4)\nindividual_bounds::Vector{Float64}: Individual eigenvalue bounds ε (Theorem 5)\nseparation_bounds::Vector{Float64}: Separation bounds η (Lemma 2)\nresidual_norm::Float64: Norm of residual matrix ‖Rg‖₂\nmessage::String: Diagnostic message (especially if success = false)\n\nInterpretation\n\nIf success = true: All eigenvalue intervals are guaranteed to contain exactly one true eigenvalue, and all eigenvector balls contain the corresponding normalized eigenvector, rigorously accounting for all matrices in the input intervals [A] and [B].\nIf success = false: Check message for diagnostic information. Common failures:\nApproximate eigenvectors not sufficiently orthogonal (‖I - Gg‖₂ >= 1)\nEigenvalues too clustered to separate\nB not positive definite\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.verify_generalized_eigenpairs","page":"Eigenvalues & SVD","title":"BallArithmetic.verify_generalized_eigenpairs","text":"verify_generalized_eigenpairs(A::BallMatrix, B::BallMatrix, X̃::Matrix, λ̃::Vector) -> GEVResult\n\nVerify all eigenpairs of the generalized eigenvalue problem Ax = λBx.\n\nImplements Algorithm 1 from Miyajima et al. (2010).\n\nNumeric Type Support\n\nCurrently supports Float64 only. All computations and error bounds are performed using Float64 arithmetic with IEEE 754 double precision. The implementation uses Float64-specific rounding error constants for rigorous verification.\n\nExtension to BigFloat would require:\n\nParametric GEVResult{T} struct\nType-dependent unit roundoff (eps(T))\nModified error analysis for arbitrary precision\n\nThe mathematical algorithms (Theorems 4, 5, 7, 10) are precision-independent, but this implementation is optimized for Float64 hardware arithmetic.\n\nArguments\n\nA::BallMatrix: Symmetric interval matrix (n×n, Float64 elements)\nB::BallMatrix: Symmetric positive definite interval matrix (n×n, Float64 elements)\nX̃::Matrix: Approximate eigenvectors (n×n), typically from eigen(A.c, B.c)\nλ̃::Vector: Approximate eigenvalues (n), assumed sorted\n\nReturns\n\nGEVResult with verified eigenvalue intervals and eigenvector balls\n\nAlgorithm (4 steps)\n\nCompute β ≥ √‖B⁻¹‖₂ using Theorem 10\nCompute global bound δ̂ and individual bounds ε using Theorems 4, 5\nDetermine separation bounds η using Lemma 2\nCompute eigenvector bounds ξ using Theorem 7\n\nComplexity\n\nO(12n³) dominated by matrix multiplications with interval arithmetic\n\nVerification Guarantees\n\nWhen success = true:\n\nEach interval [λ̃ᵢ - ηᵢ, λ̃ᵢ + ηᵢ] contains exactly one true eigenvalue\nEach ball B(x̃⁽ⁱ⁾, ξᵢ) contains the normalized true eigenvector\nResults are rigorous for ALL matrices in the intervals [A] and [B]\n\nExample\n\nusing LinearAlgebra\n\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(1e-10, 2, 2))\nB = BallMatrix([2.0 0.5; 0.5 2.0], fill(1e-10, 2, 2))\n\nF = eigen(Symmetric(A.c), Symmetric(B.c))\nresult = verify_generalized_eigenpairs(A, B, F.vectors, F.values)\n\nif result.success\n    println(\"Eigenvalue 1 ∈ \", result.eigenvalue_intervals[1])\n    println(\"Eigenvalue 2 ∈ \", result.eigenvalue_intervals[2])\n    println(\"Eigenvector radii: \", result.eigenvector_radii)\nend\n\nReferences\n\nMiyajima, S., Ogita, T., Rump, S. M., Oishi, S. (2010). \"Fast Verification for All Eigenpairs in Symmetric Positive Definite Generalized Eigenvalue Problems\". Reliable Computing 14, pp. 24-45.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_beta_bound","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_beta_bound","text":"compute_beta_bound(B::BallMatrix) -> Float64\n\nCompute verified upper bound β ≥ √‖B⁻¹‖₂ using Theorem 10.\n\nThis function efficiently computes a bound on the square root of the 2-norm of B⁻¹ using Cholesky factorization and an approximate inverse.\n\nNumeric Type Support\n\nCurrently supports Float64 only. The error analysis uses Float64-specific rounding error constants (eps(Float64)). Extension to BigFloat would require:\n\nType-parametric unit roundoff: eps(T) instead of eps(Float64)\nAppropriate error analysis for higher precision\nParametric GEVResult struct\n\nThe mathematical algorithm itself is not Float64-specific, but the rigorous error bounds in the implementation assume IEEE 754 double precision arithmetic.\n\nArguments\n\nB::BallMatrix: Symmetric positive definite interval matrix (Float64 elements)\n\nReturns\n\nβ::Float64: Upper bound on √‖B⁻¹‖₂\n\nAlgorithm (Theorem 10)\n\nCompute Cholesky factorization B ≈ LL^T\nCompute approximate inverse X_L ≈ L⁻¹\nUse interval arithmetic to bound error\nReturn β = √((α₁α∞)/(1 - α₁α∞αC))\n\nComplexity\n\nO(n³) for Cholesky and inverse\n\nExample\n\nB = BallMatrix([2.0 0.5; 0.5 2.0], fill(1e-10, 2, 2))\nβ = compute_beta_bound(B)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.RigorousSVDResult","page":"Eigenvalues & SVD","title":"BallArithmetic.RigorousSVDResult","text":"RigorousSVDResult\n\nContainer returned by rigorous_svd bundling the midpoint factorisation, the certified singular-value enclosures, and the block-diagonal refinement obtained from miyajima_vbd.  Besides the singular values themselves the struct exposes the residual and orthogonality defect bounds that underpin the certification.\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rigorous_svd","page":"Eigenvalues & SVD","title":"BallArithmetic.rigorous_svd","text":"rigorous_svd(A::BallMatrix; apply_vbd = true)\n\nCompute a rigorous singular value decomposition of the ball matrix A. The midpoint SVD is certified following Theorem 3.1 of Ref. [9]; optionally, the resulting singular-value enclosure can be refined by applying miyajima_vbd to Σ'Σ, yielding a block-diagonal structure with a rigorously bounded remainder.\n\nThe returned RigorousSVDResult exposes both the enclosures and the intermediate norm bounds that justify them. When apply_vbd is set to false, the block_diagonalisation field is nothing.\n\nReferences\n\nMiyajima S. (2014), \"Verified bounds for all the singular values of matrix\", Japan J. Indust. Appl. Math. 31, 513–539.\nRump S.M. (2011), \"Verified bounds for singular values\", BIT 51, 367–384.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.svdbox","page":"Eigenvalues & SVD","title":"BallArithmetic.svdbox","text":"svdbox(A::BallMatrix; method = MiyajimaM1(), apply_vbd = true)\n\nBackward-compatible wrapper returning only the vector of singular-value enclosures produced by rigorous_svd.  New code should prefer rigorous_svd directly to access the additional certification data.  The optional method and apply_vbd flags mirror those in rigorous_svd.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.MiyajimaVBDResult","page":"Eigenvalues & SVD","title":"BallArithmetic.MiyajimaVBDResult","text":"MiyajimaVBDResult\n\nContainer returned by miyajima_vbd encapsulating the data produced by the verified block diagonalisation (VBD) step. The fields contain the basis that block diagonalises the midpoint matrix, the transformed enclosure, its block-diagonal truncation, the rigorous remainder, and the Gershgorin clusters that certify how the spectrum groups together.\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.miyajima_vbd","page":"Eigenvalues & SVD","title":"BallArithmetic.miyajima_vbd","text":"miyajima_vbd(A::BallMatrix; hermitian = false)\n\nPerform Miyajima's verified block diagonalisation (VBD) on the square ball matrix A.  The midpoint matrix is reduced either by an eigenvalue decomposition (when hermitian = true) or by a unitary Schur form (for the general case).  The enclosure is transported to that basis, the Gershgorin discs are clustered, and a block-diagonal truncation together with a rigorous remainder is produced.\n\nOverlapping discs are grouped via their connectivity graph so that each cluster becomes contiguous after a basis permutation.  The remainder bound combines the classical Collatz estimate with a block-separation bound that exploits the verified gaps between clusters.\n\nWhen hermitian = true the routine expects A to be Hermitian and the resulting eigenvalues and intervals are real.  Otherwise the Schur form is used and the clusters are discs in the complex plane.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.refine_svd_bounds_with_vbd","page":"Eigenvalues & SVD","title":"BallArithmetic.refine_svd_bounds_with_vbd","text":"refine_svd_bounds_with_vbd(result::RigorousSVDResult)\n\nAttempt to refine singular value bounds using VBD isolation information.\n\nFor singular values whose squared values fall in isolated Gershgorin clusters, we can potentially tighten the bounds using Miyajima's Theorem 11.\n\nReturns a new RigorousSVDResult with potentially tighter bounds, or the original result if no refinement is possible.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.OgitaSVDRefinementResult","page":"Eigenvalues & SVD","title":"BallArithmetic.OgitaSVDRefinementResult","text":"OgitaSVDRefinementResult\n\nResult from Ogita's iterative SVD refinement.\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.AdaptiveSVDResult","page":"Eigenvalues & SVD","title":"BallArithmetic.AdaptiveSVDResult","text":"AdaptiveSVDResult\n\nResult from adaptive precision SVD computation.\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.ogita_svd_refine","page":"Eigenvalues & SVD","title":"BallArithmetic.ogita_svd_refine","text":"ogita_svd_refine(A::AbstractMatrix{T}, U, Σ, V;\n                 max_iterations=10, precision_bits=256,\n                 check_convergence=false,\n                 use_optimal_iterations=false) where {T<:AbstractFloat}\n\nRefine an approximate SVD using Ogita's iterative method (RefSVD algorithm).\n\nArguments\n\nA: Original matrix (in higher precision if needed)\nU: Initial left singular vectors\nΣ: Initial singular values\nV: Initial right singular vectors\nmax_iterations: Maximum number of iterations to run (default: 10)\nprecision_bits: Working precision in bits (default: 256)\ncheck_convergence: If true, check convergence via spectral norm and stop early.                      If false (default), run fixed number of iterations.\nuse_optimal_iterations: If true, compute optimal iteration count from quadratic                           convergence theory and ignore max_iterations.                           This is the fastest option for known target precision.\n\nIteration count (quadratic convergence from Float64)\n\nBased on theory, starting from Float64 (~53 bits), each iteration doubles precision:\n\n3 iterations: sufficient for 256-bit (~77 decimal digits)\n4 iterations: sufficient for 512-bit (~154 decimal digits)\n5 iterations: sufficient for 1024-bit (~308 decimal digits)\n\nReturns\n\nOgitaSVDRefinementResult containing refined SVD\n\nReferences\n\n[6] Ogita, T. & Aishima, K. (2020), \"Iterative refinement for singular value decomposition based on matrix multiplication\", J. Comput. Appl. Math. 369, 112512.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.adaptive_ogita_svd","page":"Eigenvalues & SVD","title":"BallArithmetic.adaptive_ogita_svd","text":"adaptive_ogita_svd(A::BallMatrix{T};\n                   tolerance=1e-10,\n                   method::SVDMethod=MiyajimaM1(),\n                   apply_vbd=true,\n                   max_precision_bits=1024,\n                   max_refinement_iterations=5) where {T}\n\nCompute rigorous SVD bounds with adaptive precision using Ogita's refinement.\n\nAlgorithm\n\nStart with Float64 precision\nCompute rigorous SVD bounds using rigorous_svd\nCheck if max(rad(σᵢ)) < tolerance\nIf not satisfied, refine using Ogita's method with doubled precision\nRepeat until tolerance met or max precision reached\n\nArguments\n\nA: Input ball matrix\ntolerance: Target tolerance for max(rad(σᵢ))\nmethod: SVD certification method (MiyajimaM1, MiyajimaM4, RumpOriginal)\napply_vbd: Whether to apply verified block diagonalization\nmax_precision_bits: Maximum precision to use (bits)\nmax_refinement_iterations: Maximum number of refinement steps\n\nReturns\n\nAdaptiveSVDResult containing final rigorous result and adaptation history\n\nExample\n\nA = BallMatrix([3.0 1.0; 1.0 2.0], fill(1e-8, 2, 2))\nresult = adaptive_ogita_svd(A; tolerance=1e-12)\n\n# Access final result\nσ = result.rigorous_result.singular_values\nprintln(\"Final precision: \", result.final_precision, \" bits\")\nprintln(\"Max radius: \", maximum(rad.(σ)))\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.clear_svd_cache!","page":"Eigenvalues & SVD","title":"BallArithmetic.clear_svd_cache!","text":"clear_svd_cache!()\n\nClear the BigFloat SVD cache used for warm-starting Ogita refinement.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.svd_cache_stats","page":"Eigenvalues & SVD","title":"BallArithmetic.svd_cache_stats","text":"svd_cache_stats()\n\nReturn statistics about the BigFloat SVD cache usage.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.set_svd_cache!","page":"Eigenvalues & SVD","title":"BallArithmetic.set_svd_cache!","text":"set_svd_cache!(U, S, V, A_hash)\n\nSet the SVD cache with the given factors and matrix hash. Used for warm-starting Ogita refinement on nearby matrices.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.RigorousSpectralProjectorsResult","page":"Eigenvalues & SVD","title":"BallArithmetic.RigorousSpectralProjectorsResult","text":"RigorousSpectralProjectorsResult\n\nContainer returned by miyajima_spectral_projectors encapsulating the rigorously computed spectral projectors for each eigenvalue cluster identified by verified block diagonalization (VBD).\n\nEach projector P_k is a ball matrix satisfying:\n\nP_k^2 ≈ P_k (idempotency)\n∑_k P_k ≈ I (resolution of identity)\nP_i * P_j ≈ 0 for i ≠ j (orthogonality)\nA * P_k ≈ P_k * A * P_k (invariance)\n\nThe projectors are constructed from the basis that block-diagonalizes the matrix, restricted to each spectral cluster.\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.miyajima_spectral_projectors","page":"Eigenvalues & SVD","title":"BallArithmetic.miyajima_spectral_projectors","text":"miyajima_spectral_projectors(A::BallMatrix; hermitian=false, verify_invariance=true)\n\nCompute rigorous enclosures for spectral projectors corresponding to each eigenvalue cluster identified by Miyajima's verified block diagonalization (VBD).\n\nThe method follows the approach from Ref. [8]:\n\nApply VBD to obtain basis V that block-diagonalizes A\nFor each cluster k, extract columns V[:, cluster_k]\nConstruct projector P_k = V[:, cluster_k] * V[:, cluster_k]' as ball matrix\nVerify idempotency, orthogonality, and resolution of identity\n\nWhen hermitian = true, the basis is computed via eigendecomposition and projectors are Hermitian. Otherwise, the Schur basis is used.\n\nWhen verify_invariance = true, additionally verifies that A * P_k ≈ P_k * A * P_k for each projector, confirming that the columns of P_k span an invariant subspace.\n\nArguments\n\nA::BallMatrix: Square ball matrix whose spectral projectors to compute\nhermitian::Bool = false: Whether to assume A is Hermitian\nverify_invariance::Bool = true: Whether to verify invariant subspace property\n\nReturns\n\nRigorousSpectralProjectorsResult containing the projectors and verification data.\n\nExample\n\nusing BallArithmetic, LinearAlgebra\n\n# Create a matrix with clustered eigenvalues\nA = BallMatrix(Diagonal([1.0, 1.1, 5.0, 5.1]))\n\n# Compute projectors\nresult = miyajima_spectral_projectors(A; hermitian=true)\n\n# Access projectors\nP1 = result[1]  # Projector for first cluster (eigenvalues ≈ 1.0, 1.1)\nP2 = result[2]  # Projector for second cluster (eigenvalues ≈ 5.0, 5.1)\n\n# Verify properties\n@assert result.idempotency_defect < 1e-10\n@assert result.orthogonality_defect < 1e-10\n\nReferences\n\n[8] Miyajima, SIAM J. Matrix Anal. Appl. 35, 1205–1225 (2014)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_invariant_subspace_basis","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_invariant_subspace_basis","text":"compute_invariant_subspace_basis(proj_result::RigorousSpectralProjectorsResult, k::Int)\n\nExtract an orthonormal basis for the invariant subspace corresponding to cluster k from the spectral projector result.\n\nReturns a BallMatrix whose columns span the invariant subspace associated with the k-th eigenvalue cluster.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.verify_projector_properties","page":"Eigenvalues & SVD","title":"BallArithmetic.verify_projector_properties","text":"verify_projector_properties(proj_result::RigorousSpectralProjectorsResult; tol=1e-10)\n\nVerify that all projector properties hold within the specified tolerance. Returns true if all properties are satisfied, false otherwise.\n\nChecks:\n\nIdempotency: ‖Pk^2 - Pk‖₂ < tol for all k\nOrthogonality: ‖Pi * Pj‖₂ < tol for all i ≠ j\nResolution: ‖∑k Pk - I‖₂ < tol\nInvariance: ‖APk - PkA*P_k‖₂ < tol for all k (if computed)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.projector_condition_number","page":"Eigenvalues & SVD","title":"BallArithmetic.projector_condition_number","text":"projector_condition_number(proj_result::RigorousSpectralProjectorsResult, k::Int)\n\nEstimate the condition number of the k-th spectral projector based on the gap between eigenvalue clusters.\n\nA small gap indicates potential ill-conditioning of the projector.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.RigorousBlockSchurResult","page":"Eigenvalues & SVD","title":"BallArithmetic.RigorousBlockSchurResult","text":"RigorousBlockSchurResult\n\nContainer returned by rigorous_block_schur encapsulating a verified block Schur decomposition A ≈ Q * T * Q' where:\n\nQ is an approximately orthogonal/unitary transformation (as ball matrix)\nT is in block upper quasi-triangular form\nDiagonal blocks correspond to eigenvalue clusters\nOff-diagonal blocks are rigorously bounded\n\nThe decomposition satisfies:\n\nA ≈ Q * T * Q' with rigorous residual bounds\nQ' * Q ≈ I with rigorous orthogonality defect bounds\nEach diagonal block T[cluster_k, cluster_k] contains eigenvalues from cluster k\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.rigorous_block_schur","page":"Eigenvalues & SVD","title":"BallArithmetic.rigorous_block_schur","text":"rigorous_block_schur(A::BallMatrix; hermitian=false, block_structure=:quasi_triangular)\n\nCompute a rigorous block Schur decomposition A ≈ Q * T * Q' where Q is orthogonal/unitary and T is in block form determined by eigenvalue clustering.\n\nThe method follows Miyajima's VBD framework:\n\nApply verified block diagonalization to identify eigenvalue clusters\nConstruct orthogonal basis Q from the diagonalizing transformation\nTransform matrix to block form T = Q' * A * Q\nVerify orthogonality of Q and residual bounds\n\nArguments\n\nA::BallMatrix: Square ball matrix to decompose\nhermitian::Bool = false: Whether to assume A is Hermitian\nblock_structure::Symbol = :quasi_triangular: Block structure to compute\n:diagonal: Keep only diagonal blocks (same as VBD)\n:quasi_triangular: Keep upper triangular block structure\n:full: Keep all blocks (no truncation)\n\nReturns\n\nRigorousBlockSchurResult containing the decomposition and verification data.\n\nExample\n\nusing BallArithmetic, LinearAlgebra\n\n# Create a matrix with clustered eigenvalues\nA = BallMatrix([2.0 0.1 0.05 0.02;\n                0.1 2.1 0.03 0.01;\n                0.05 0.03 5.0 0.15;\n                0.02 0.01 0.15 5.1])\n\n# Compute block Schur form\nresult = rigorous_block_schur(A; hermitian=true)\n\n# Access components\nQ = result.Q\nT = result.T\n\n# Verify decomposition\n@assert result.residual_norm < 1e-10\n@assert result.orthogonality_defect < 1e-10\n\nReferences\n\n[8] Miyajima, SIAM J. Matrix Anal. Appl. 35, 1205–1225 (2014)\n[10] Miyajima, Japan J. Indust. Appl. Math. 31, 513–539 (2014)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.extract_cluster_block","page":"Eigenvalues & SVD","title":"BallArithmetic.extract_cluster_block","text":"extract_cluster_block(result::RigorousBlockSchurResult, i::Int, j::Int)\n\nExtract the (i,j)-th block from the block Schur form T. Returns a BallMatrix corresponding to T[cluster_i, cluster_j].\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.verify_block_schur_properties","page":"Eigenvalues & SVD","title":"BallArithmetic.verify_block_schur_properties","text":"verify_block_schur_properties(result::RigorousBlockSchurResult; tol=1e-10)\n\nVerify that the block Schur decomposition satisfies all required properties within the specified tolerance.\n\nChecks:\n\nResidual: ‖A - QTQ'‖₂ < tol\nOrthogonality: ‖Q'*Q - I‖₂ < tol\nBlock structure preserved (if applicable)\n\nReturns true if all properties are satisfied, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.estimate_block_separation","page":"Eigenvalues & SVD","title":"BallArithmetic.estimate_block_separation","text":"estimate_block_separation(result::RigorousBlockSchurResult, i::Int, j::Int)\n\nEstimate the spectral separation between clusters i and j. A small separation indicates potential numerical difficulties in separating the corresponding invariant subspaces.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.refine_off_diagonal_block","page":"Eigenvalues & SVD","title":"BallArithmetic.refine_off_diagonal_block","text":"refine_off_diagonal_block(result::RigorousBlockSchurResult, i::Int, j::Int)\n\nRefine the (i,j) off-diagonal block by solving the block Sylvester equation with Miyajima's verified solver.\n\nFor i < j, solves T_ii' * Y - Y * T_jj' = T_ij' to obtain a refined enclosure for the (i,j) off-diagonal block.\n\nReturns a BallMatrix with rigorous enclosure for the refined block.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_block_sylvester_rhs","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_block_sylvester_rhs","text":"compute_block_sylvester_rhs(result::RigorousBlockSchurResult, i::Int, j::Int)\n\nFor clusters i < j, compute the right-hand side for the block Sylvester equation that would refine the (i,j) off-diagonal block.\n\nGiven T_ii * X + X * T_jj = C, returns the matrix C that should equal T[cluster_i, cluster_j] if the block Schur form were exact.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.SchurSpectralProjectorResult","page":"Eigenvalues & SVD","title":"BallArithmetic.SchurSpectralProjectorResult","text":"SchurSpectralProjectorResult{T}\n\nResult of verified spectral projector computation from Schur decomposition.\n\nFields\n\nprojector::BallMatrix{T}: Rigorous enclosure of the spectral projector P\nschur_projector::BallMatrix{T}: Projector in Schur coordinates\ncoupling_matrix::BallMatrix{T}: Solution Y to the Sylvester equation T₁₁Y - YT₂₂ = T₁₂\neigenvalue_separation::T: Lower bound on min|λᵢ - λⱼ| for i ∈ S, j ∉ S\nprojector_norm::T: Upper bound on ‖P‖₂\nidempotency_defect::T: Upper bound on ‖P² - P‖₂\nschur_basis::Matrix{T}: Unitary matrix Q from A = QTQ^†\nschur_form::Matrix{T}: Upper triangular T from A = QTQ^†\ncluster_indices::UnitRange{Int}: Indices in Schur form corresponding to projected eigenvalues\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.compute_spectral_projector_schur","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_spectral_projector_schur","text":"compute_spectral_projector_schur(A::BallMatrix, cluster_indices::UnitRange{Int};\n                                 verify_idempotency::Bool=true)\n\nCompute rigorous enclosure of the spectral projector for eigenvalues at specified Schur form indices using verified Sylvester equation solver.\n\nMathematical Background\n\nGiven a matrix A with Schur decomposition A = QTQ^†, where T is upper triangular, partition T into blocks:\n\nT = [T₁₁  T₁₂]\n    [0    T₂₂]\n\nwhere T₁₁ contains the eigenvalues we want to project onto (diagonal entries at positions given by cluster_indices).\n\nThe spectral projector (Riesz projector) onto the eigenspace corresponding to eigenvalues of T₁₁ is:\n\nP = Q * P_Schur * Q^†\n\nwhere P_Schur is the projector in Schur coordinates:\n\nP_Schur = [I   Y]\n          [0   0]\n\nand Y solves the Sylvester equation:\n\nT₁₁*Y - Y*T₂₂ = T₁₂\n\nThis is solved rigorously using triangular_sylvester_miyajima_enclosure.\n\nAlgorithm\n\nCompute Schur decomposition: A = QTQ^† (using approximate Schur for A.c)\nExtract blocks T₁₁, T₁₂, T₂₂ based on cluster_indices\nSolve Sylvester equation rigorously: T₁₁Y - YT₂₂ = T₁₂\nConstruct P_Schur = [I Y; 0 0] with interval arithmetic\nTransform back: P = Q * P_Schur * Q^† with interval arithmetic\nVerify idempotency: ‖P² - P‖₂ < tol\n\nArguments\n\nA::BallMatrix: Square interval matrix (n × n)\ncluster_indices::UnitRange{Int}: Indices of eigenvalues to project onto (corresponds to positions in Schur form, typically 1:k for first k eigenvalues)\nverify_idempotency::Bool=true: Check that ‖P² - P‖₂ is small\n\nReturns\n\nSchurSpectralProjectorResult containing the verified projector and diagnostics.\n\nExamples\n\nProject onto first two eigenvalues\n\nusing BallArithmetic, LinearAlgebra\n\n# Matrix with small uncertainties\nA = BallMatrix([1.0 2.0 0.0; 0.0 3.0 1.0; 0.0 0.0 5.0], fill(1e-10, 3, 3))\n\n# Compute projector onto eigenvalues 1.0 and 3.0 (first two in Schur form)\nresult = compute_spectral_projector_schur(A, 1:2)\n\nP = result.projector\n@show result.eigenvalue_separation  # Gap to third eigenvalue\n@show result.idempotency_defect     # ‖P² - P‖₂\n\n# Project a vector\nv = BallVector([1.0, 2.0, 3.0])\nv_projected = P * v\n\nFor a clustered matrix\n\n# Upper triangular matrix with eigenvalues [1.0, 1.1, 5.0, 5.1]\nA = BallMatrix(triu(randn(4,4)) .+ Diagonal([1.0, 1.1, 5.0, 5.1]))\n\n# After sorting eigenvalues by Schur decomposition, project onto first cluster\nresult = compute_spectral_projector_schur(A, 1:2)\n\nNotes\n\nRequires non-zero eigenvalue separation: min|λᵢ - λⱼ| for i ∈ cluster, j ∉ cluster\nThe Sylvester equation solver may fail if separation is too small\nComplexity: O(n³) for Schur decomposition + O(k²(n-k)²) for Sylvester solver\nFor hermitian matrices, use compute_spectral_projector_hermitian instead (more efficient)\nThe projector P satisfies: P² ≈ P and PA ≈ AP (modulo idempotency defect)\nCaveat: The Schur decomposition of the midpoint matrix is not itself rigorously enclosed (Q and T carry zero radii). The Sylvester coupling Y is rigorously bounded, but the final projector P = Q·PSchur·Q† does not account for the Schur approximation error. The idempotency and invariance checks verify self-consistency of the result, but do not guarantee that the true spectral projector lies within the computed ball. For a fully rigorous enclosure, use [`miyajimaspectral_projectors`](@ref) instead.\n\nReferences\n\nKato, T. \"Perturbation Theory for Linear Operators\" (1995), Chapter II.4\nStewart, G. W., Sun, J. \"Matrix Perturbation Theory\" (1990), Chapter V\nMiyajima, S. \"Fast enclosure for all eigenvalues in generalized eigenvalue problems\" SIAM J. Matrix Anal. Appl. 35, 1205–1225 (2014)\n\nSee Also\n\ntriangular_sylvester_miyajima_enclosure: Verified Sylvester solver used internally\nproject_vector_spectral: Convenient interface to project vectors using this result\n\n\n\n\n\ncompute_spectral_projector_schur(A::BallMatrix, target_indices::AbstractVector{Int};\n                                 verify_idempotency::Bool=true,\n                                 schur_data=nothing)\n\nCompute rigorous spectral projector for eigenvalues at arbitrary Schur form positions.\n\nUnlike the UnitRange method, this accepts any subset of eigenvalue indices. Internally, the Schur form is reordered (via ordschur) so the target eigenvalues occupy positions 1:k, then the standard Sylvester-based projector pipeline is applied.\n\nArguments\n\nA::BallMatrix: Square interval matrix (n × n)\ntarget_indices::AbstractVector{Int}: Positions of eigenvalues in Schur form to project onto\nverify_idempotency::Bool=true: Check ‖P² - P‖₂\nschur_data=nothing: Optional pre-computed (Q, T) Schur factors to skip internal Schur\n\nReturns\n\nSchurSpectralProjectorResult with the reordered Schur factors and verified projector.\n\nExample\n\nA = BallMatrix(randn(5, 5))\n# Project onto 2nd and 4th eigenvalues (arbitrary positions)\nresult = compute_spectral_projector_schur(A, [2, 4])\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_spectral_projector_hermitian","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_spectral_projector_hermitian","text":"compute_spectral_projector_hermitian(A::BallMatrix, cluster_indices::UnitRange{Int})\n\nCompute spectral projector for Hermitian matrix (simplified, no Sylvester equation needed).\n\nFor Hermitian matrices, eigenvectors are orthogonal, so the spectral projector is simply:\n\nP = V_S * V_S^†\n\nwhere V_S are the eigenvectors corresponding to the selected eigenvalues.\n\nThis is more efficient than the general Schur-based method since no Sylvester equation needs to be solved.\n\nArguments\n\nA::BallMatrix: Hermitian interval matrix\ncluster_indices::UnitRange{Int}: Indices of eigenvalues to project onto (after sorting)\n\nReturns\n\nSchurSpectralProjectorResult with the verified projector.\n\nExample\n\n# Symmetric matrix\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(1e-10, 2, 2))\n\n# Project onto first eigenvalue\nresult = compute_spectral_projector_hermitian(A, 1:1)\nP = result.projector\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.project_vector_spectral","page":"Eigenvalues & SVD","title":"BallArithmetic.project_vector_spectral","text":"project_vector_spectral(v::BallVector, result::SchurSpectralProjectorResult)\n\nProject interval vector onto eigenspace using precomputed spectral projector.\n\nArguments\n\nv::BallVector: Interval vector to project\nresult::SchurSpectralProjectorResult: Precomputed projector from compute_spectral_projector_schur or compute_spectral_projector_hermitian\n\nReturns\n\nBallVector containing P*v with rigorous error bounds.\n\nExample\n\nA = BallMatrix([1.0 2.0; 0.0 3.0], fill(1e-10, 2, 2))\nresult = compute_spectral_projector_schur(A, 1:1)\n\nv = BallVector([1.0, 2.0], [1e-10, 1e-10])\nv_projected = project_vector_spectral(v, result)\n\n\n\n\n\nproject_vector_spectral(v::AbstractVector, result::SchurSpectralProjectorResult)\n\nProject standard vector onto eigenspace (non-verified version).\n\nArguments\n\nv::AbstractVector: Vector to project\nresult::SchurSpectralProjectorResult: Precomputed projector\n\nReturns\n\nProjected vector P*v (center value only, no error bounds).\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.verify_spectral_projector_properties","page":"Eigenvalues & SVD","title":"BallArithmetic.verify_spectral_projector_properties","text":"verify_spectral_projector_properties(result::SchurSpectralProjectorResult, A::BallMatrix;\n                                     tol::Real=1e-10)\n\nVerify that the computed spectral projector satisfies expected mathematical properties.\n\nChecks\n\nIdempotency: ‖P² - P‖₂ < tol\nBounded norm: ‖P‖₂ < ∞ (typically ‖P‖₂ ≤ κ(V) where κ is condition number of eigenvectors)\nCommutation (if A normal): ‖AP - PA‖₂ < tol\nEigenvalue separation: min|λᵢ - λⱼ| > 0 for i ∈ S, j ∉ S\n\nArguments\n\nresult::SchurSpectralProjectorResult: Computed projector\nA::BallMatrix: Original matrix\ntol::Real=1e-10: Tolerance for property verification\n\nReturns\n\ntrue if all properties satisfied, false otherwise\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.SchurRefinementResult","page":"Eigenvalues & SVD","title":"BallArithmetic.SchurRefinementResult","text":"SchurRefinementResult{T, RT}\n\nResult from iterative Schur refinement to higher precision.\n\nFields\n\nQ::Matrix{T}: Refined orthogonal/unitary Schur basis\nT::Matrix{T}: Refined upper triangular Schur form\niterations::Int: Number of refinement iterations performed\nresidual_norm::RT: Final residual ‖stril(Q^H A Q)‖₂ / ‖A‖_F — rigorous upper bound (real type)\northogonality_defect::RT: Final ‖Q^H Q - I‖₂ — rigorous upper bound (real type)\nconverged::Bool: Whether refinement converged to desired tolerance\n\nReferences\n\n[11] Bujanović, Kressner & Schröder, \"Iterative refinement of Schur decompositions\", Numer. Algorithms 95, 247–267 (2024)\n\n\n\n\n\n","category":"type"},{"location":"api/eigenvalues/#BallArithmetic.refine_schur_decomposition","page":"Eigenvalues & SVD","title":"BallArithmetic.refine_schur_decomposition","text":"refine_schur_decomposition(A::AbstractMatrix{T}, Q0::Matrix, T0::Matrix;\n                            target_precision::Int=256,\n                            max_iterations::Int=20,\n                            tol::Real=0.0) where T\n\nRefine an approximate Schur decomposition A ≈ Q₀ T₀ Q₀^H to higher precision.\n\nStarting from an approximate Schur decomposition computed in Float64, this function iteratively refines Q and T to achieve the accuracy of target_precision bits. The algorithm uses Newton-like iterations that converge quadratically.\n\nAlgorithm (from Bujanović et al. 2022, Algorithm 4)\n\nGiven A = Q₀ T₀ Q₀^H + E where E is the initial error:\n\nPre-computation (2 high-precision matrix multiplications):\nCompute AQ = A * Q and Q^HA = Q^H * A in target precision\nIteration (4 high-precision matrix multiplications per step):\nCompute residual R = Q^H * A_Q - T\nExtract diagonal correction: T_new = T + diag(R)\nSolve Sylvester equations for off-diagonal corrections\nApply Newton-Schulz to re-orthogonalize Q\nRepeat until convergence\n\nThe method achieves 10-20× speedup over computing Schur directly in high precision.\n\nArguments\n\nA: Original matrix (will be converted to target precision)\nQ0: Approximate orthogonal/unitary factor from Schur decomposition\nT0: Approximate upper triangular factor from Schur decomposition\ntarget_precision: Target precision in bits (default: 256 for BigFloat)\nmax_iterations: Maximum refinement iterations (default: 20)\ntol: Convergence tolerance (default: machine epsilon of target precision)\n\nReturns\n\nSchurRefinementResult containing refined Q, T and convergence information.\n\nExample\n\nusing BallArithmetic, LinearAlgebra\n\n# Compute Schur in Float64\nA = randn(100, 100)\nF = schur(A)\nQ0, T0 = F.Z, F.T\n\n# Refine to BigFloat precision\nresult = refine_schur_decomposition(A, Q0, T0; target_precision=256)\n\n# Check residual\n@show result.residual_norm      # Should be ≈ 10^-77 for 256-bit precision\n@show result.orthogonality_defect\n\nReferences\n\n[11] Bujanović, Kressner & Schröder, \"Iterative refinement of Schur decompositions\", Numer. Algorithms 95, 247–267 (2024). Algorithm 4: Mixed-precision Schur refinement.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.rigorous_schur_bigfloat","page":"Eigenvalues & SVD","title":"BallArithmetic.rigorous_schur_bigfloat","text":"rigorous_schur_bigfloat(A::BallMatrix{T}; target_precision::Int=256,\n                        max_iterations::Int=20) where T\n\nCompute rigorous Schur decomposition with BigFloat precision using iterative refinement.\n\nThis combines:\n\nFast approximate Schur decomposition in Float64\nIterative refinement to BigFloat precision\nRigorous error certification\n\nArguments\n\nA::BallMatrix: Input ball matrix\ntarget_precision: Target BigFloat precision in bits (default: 256)\nmax_iterations: Maximum refinement iterations (default: 20)\n\nReturns\n\nA tuple (Q_ball, T_ball, result) where:\n\nQ_ball::BallMatrix{BigFloat}: Rigorous enclosure of Schur basis\nT_ball::BallMatrix{BigFloat}: Rigorous enclosure of Schur form\nresult::SchurRefinementResult: Refinement diagnostics\n\nExample\n\nA = BallMatrix(randn(10, 10), fill(1e-10, 10, 10))\nQ, T, result = rigorous_schur_bigfloat(A; target_precision=512)\n@show result.converged\n\nReferences\n\n[11] for the iterative refinement algorithm\n[12] for rigorous error certification\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.newton_schulz_orthogonalize!","page":"Eigenvalues & SVD","title":"BallArithmetic.newton_schulz_orthogonalize!","text":"newton_schulz_orthogonalize!(Q::Matrix{T}; max_iter=10, tol=nothing) where T\n\nApply Newton-Schulz iteration to orthogonalize Q in-place.\n\nThe iteration is:     Q{k+1} = (1/2) Qk (3I - Qk^H Qk)\n\nThis converges quadratically if ‖Q^H Q - I‖₂ < 1.\n\nArguments\n\nQ: Matrix to orthogonalize (modified in place)\nmax_iter: Maximum iterations (default: 10)\ntol: Convergence tolerance (default: machine epsilon of T)\n\nReturns\n\nNumber of iterations performed\nFinal orthogonality defect ‖Q^H Q - I‖_F\n\nReferences\n\n[11] Section 2.2.2 (Newton-Schulz iteration)\n\nNOTE: This is an ORACLE computation - convergence is checked via the defect\n\n(‖Q^H Q - I‖_F < tol), which serves as an A POSTERIORI verification. The\n\nintermediate computations don't need directed rounding because the final\n\ndefect measurement validates the orthogonalization quality.\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.project_onto_eigenspace","page":"Eigenvalues & SVD","title":"BallArithmetic.project_onto_eigenspace","text":"project_onto_eigenspace(v::AbstractVector, V::AbstractMatrix, indices::UnitRange{Int};\n                        hermitian::Bool=false, left_eigenvectors::Union{Nothing, AbstractMatrix}=nothing)\n\nProject vector v onto the eigenspace spanned by eigenvectors at the specified indices.\n\nMathematical Background\n\nFor a diagonalizable matrix A = VΛV⁻¹, the Riesz projection onto the eigenspace corresponding to eigenvalues λ_k (k ∈ indices) is:\n\nHermitian/Normal case (hermitian=true or V orthogonal):\n\nP_S v = V_S (V_S^† V_S)⁻¹ V_S^† v = V_S V_S^† v\n\nwhere V_S = V[:, indices] and V^† is the conjugate transpose.\n\nNon-normal case (requires left eigenvectors):\n\nP_S v = V_S W_S^† v\n\nwhere W_S contains the corresponding left eigenvectors (rows of V⁻¹).\n\nArguments\n\nv::AbstractVector: Vector to project (length n)\nV::AbstractMatrix: Matrix of right eigenvectors (n × n)\nindices::UnitRange{Int}: Column indices of eigenvectors to project onto\nhermitian::Bool=false: If true, assumes V is orthogonal (V^† V = I)\nleft_eigenvectors::Union{Nothing, AbstractMatrix}=nothing: Left eigenvectors W = V⁻¹ (required for non-normal matrices when hermitian=false)\n\nReturns\n\nProjected vector P_S v of length n.\n\nExamples\n\nSymmetric/Hermitian case\n\nusing LinearAlgebra, BallArithmetic\n\n# Symmetric matrix with clustered eigenvalues\nA = [4.0 1.0 0.0; 1.0 4.0 0.0; 0.0 0.0 10.0]\nF = eigen(Symmetric(A))\n\n# Project onto first two eigenvectors (eigenvalues ≈ 3, 5)\nv = [1.0, 2.0, 3.0]\nv_proj = project_onto_eigenspace(v, F.vectors, 1:2; hermitian=true)\n\nNon-normal case (requires left eigenvectors)\n\n# Non-normal matrix\nA = [1.0 1.0; 0.0 2.0]  # Upper triangular, non-symmetric\nF = eigen(A)\n\n# Compute left eigenvectors\nV_inv = inv(F.vectors)  # Rows are left eigenvectors\n\n# Project onto first eigenspace\nv = [1.0, 1.0]\nv_proj = project_onto_eigenspace(v, F.vectors, 1:1;\n                                  hermitian=false, left_eigenvectors=V_inv)\n\nNotes\n\nFor hermitian=true, uses the simple formula P = VS VS^†\nFor hermitian=false without left eigenvectors, attempts V⁻¹ computation (may fail)\nFor non-normal matrices, providing left_eigenvectors avoids computing V⁻¹\nThe projection is exact in exact arithmetic but subject to rounding errors\nFor verified computation, use verified_project_onto_eigenspace with BallMatrix\n\nReferences\n\nKato, T. \"Perturbation theory for linear operators\" (1995), Chapter II\nStewart, G. W., Sun, J. \"Matrix Perturbation Theory\" (1990), Section V.3\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.project_onto_schur_subspace","page":"Eigenvalues & SVD","title":"BallArithmetic.project_onto_schur_subspace","text":"project_onto_schur_subspace(v::AbstractVector, Q::AbstractMatrix, indices::UnitRange{Int})\n\nProject vector v onto the invariant subspace spanned by Schur vectors at specified indices.\n\nMathematical Background\n\nFor a Schur decomposition A = QTQ^†, the Schur vectors (columns of Q) span nested invariant subspaces. The projection onto the subspace spanned by Q[:, indices] is:\n\nP_S v = Q_S Q_S^† v\n\nwhere Q_S = Q[:, indices]. Since Q is unitary (Q^† Q = I), this is always well-defined.\n\nArguments\n\nv::AbstractVector: Vector to project (length n)\nQ::AbstractMatrix: Unitary Schur matrix (n × n, with Q^† Q = I)\nindices::UnitRange{Int}: Column indices of Schur vectors to project onto\n\nReturns\n\nProjected vector P_S v of length n.\n\nExample\n\nusing LinearAlgebra, BallArithmetic\n\n# Matrix with complex eigenvalues\nA = [0.0 1.0; -1.0 0.0]  # Rotation matrix\nF = schur(A)\n\n# Project onto first Schur vector\nv = [1.0, 1.0]\nv_proj = project_onto_schur_subspace(v, F.Z, 1:1)\n\nNotes\n\nSchur vectors are always orthonormal, so projection is straightforward\nThe subspace spanned by Q[:, 1:k] is an invariant subspace of A\nFor real Schur form, complex eigenvalue pairs share a 2D invariant subspace\nThis is simpler than eigenspace projection for non-normal matrices\n\nReferences\n\nGolub, G. H., Van Loan, C. F. \"Matrix Computations\" (2013), Section 7.6\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.verified_project_onto_eigenspace","page":"Eigenvalues & SVD","title":"BallArithmetic.verified_project_onto_eigenspace","text":"verified_project_onto_eigenspace(v::BallVector, V::BallMatrix, indices::UnitRange{Int};\n                                 hermitian::Bool=false)\n\nRigorously verified projection of interval vector onto eigenspace with error bounds.\n\nSimilar to project_onto_eigenspace but uses interval arithmetic to provide rigorous bounds on the projection result accounting for uncertainties in both the vector and eigenvector matrix.\n\nArguments\n\nv::BallVector: Interval vector to project\nV::BallMatrix: Interval matrix of eigenvectors\nindices::UnitRange{Int}: Column indices of eigenvectors\nhermitian::Bool=false: If true, assumes V is orthogonal\n\nReturns\n\nBallVector containing the projected vector with rigorous error bounds.\n\nExample\n\nusing BallArithmetic, LinearAlgebra\n\n# Matrix with small uncertainties\nA = BallMatrix([4.0 1.0; 1.0 3.0], fill(1e-10, 2, 2))\nF = eigen(Symmetric(A.c))\n\n# Vector with uncertainties\nv = BallVector([1.0, 2.0], [1e-10, 1e-10])\n\n# Verified projection\nV_ball = BallMatrix(F.vectors)\nv_proj = verified_project_onto_eigenspace(v, V_ball, 1:1; hermitian=true)\n\nNotes\n\nUses interval arithmetic throughout for rigorous error bounds\nThe Gram system G·c = V_S†·v is solved rigorously via krawczyk_linear_system; if Krawczyk does not verify, a Neumann-series residual bound is used as fallback\nResult contains all possible projections for vectors/eigenvectors in input intervals\nMore expensive than non-verified version due to interval arithmetic overhead\nCurrently only supports hermitian case (non-normal requires Sylvester solver)\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_eigenspace_projector","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_eigenspace_projector","text":"compute_eigenspace_projector(V::AbstractMatrix, indices::UnitRange{Int};\n                            hermitian::Bool=false,\n                            left_eigenvectors::Union{Nothing, AbstractMatrix}=nothing)\n\nCompute the projection matrix P_S onto the eigenspace spanned by specified eigenvectors.\n\nReturns the n × n projection matrix PS such that PS v projects any vector v onto the specified eigenspace.\n\nArguments\n\nV::AbstractMatrix: Matrix of right eigenvectors (n × n)\nindices::UnitRange{Int}: Column indices of eigenvectors defining the subspace\nhermitian::Bool=false: If true, assumes V is orthogonal\nleft_eigenvectors::Union{Nothing, AbstractMatrix}=nothing: Left eigenvectors W = V⁻¹\n\nReturns\n\nn × n projection matrix PS with PS² = P_S.\n\nExample\n\nF = eigen(A)\nP = compute_eigenspace_projector(F.vectors, 1:2; hermitian=true)\n\n# Now can project multiple vectors\nv1_proj = P * v1\nv2_proj = P * v2\n\nSee Also\n\nproject_onto_eigenspace: Project single vector without forming matrix\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.compute_schur_projector","page":"Eigenvalues & SVD","title":"BallArithmetic.compute_schur_projector","text":"compute_schur_projector(Q::AbstractMatrix, indices::UnitRange{Int})\n\nCompute the projection matrix onto the invariant subspace spanned by Schur vectors.\n\nReturns the n × n projection matrix PS = QS QS^† where QS = Q[:, indices].\n\nArguments\n\nQ::AbstractMatrix: Unitary Schur matrix (n × n)\nindices::UnitRange{Int}: Column indices of Schur vectors\n\nReturns\n\nn × n projection matrix PS with PS² = P_S.\n\nExample\n\nF = schur(A)\nP = compute_schur_projector(F.Z, 1:3)  # Project onto first 3-dimensional invariant subspace\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.qi_intervals","page":"Eigenvalues & SVD","title":"BallArithmetic.qi_intervals","text":"qi_intervals(A::BallMatrix)\n\nQi (1984, Theorem 2) intervals for singular values. Returns the intervals Bᵢ as a Vector{Ball}. See Ref. [13].\n\n\n\n\n\n","category":"function"},{"location":"api/eigenvalues/#BallArithmetic.qi_sqrt_intervals","page":"Eigenvalues & SVD","title":"BallArithmetic.qi_sqrt_intervals","text":"qi_sqrt_intervals(A::BallMatrix)\n\nSharper square-root intervals for the singular values (Qi 1984, Theorem 3). See Ref. [13].\n\n\n\n\n\n","category":"function"},{"location":"linearsystems/#Linear-Systems","page":"Linear Systems","title":"Linear Systems","text":"This page documents verified linear system solvers.","category":"section"},{"location":"linearsystems/#Overview","page":"Linear Systems","title":"Overview","text":"Verified linear system solvers provide rigorous enclosures for solutions of Ax = b with guaranteed error bounds. Multiple methods are available depending on the matrix properties and desired tightness of bounds.","category":"section"},{"location":"linearsystems/#Krawczyk-Method","page":"Linear Systems","title":"Krawczyk Method","text":"The Krawczyk method uses interval Newton iteration to verify and refine solutions. See src/linear_system/Krawczyk.jl for the basic implementation.","category":"section"},{"location":"linearsystems/#HBR-Method","page":"Linear Systems","title":"HBR Method","text":"The Hansen-Bliek-Rohn enclosure method provides componentwise bounds.\n\nhbr_method - Main HBR solver\nhbr_method_simple - Simplified variant\nHBRResult - Result type","category":"section"},{"location":"linearsystems/#Gaussian-Elimination","page":"Linear Systems","title":"Gaussian Elimination","text":"Verified Gaussian elimination with interval pivoting.\n\ninterval_gaussian_elimination - Verified Gaussian elimination\ninterval_gaussian_elimination_det - With determinant computation\nis_regular_gaussian_elimination - Regularity test via GE\nGaussianEliminationResult - Result type","category":"section"},{"location":"linearsystems/#Iterative-Methods","page":"Linear Systems","title":"Iterative Methods","text":"Interval iterative methods for large sparse systems.\n\ninterval_gauss_seidel - Interval Gauss-Seidel iteration\ninterval_jacobi - Interval Jacobi iteration\nIterativeResult - Result type","category":"section"},{"location":"linearsystems/#Preconditioning","page":"Linear Systems","title":"Preconditioning","text":"Preconditioning strategies for improving convergence.\n\ncompute_preconditioner - Compute preconditioner\napply_preconditioner - Apply preconditioner to system\nis_well_preconditioned - Check preconditioning quality\nPreconditionerResult - Result type\n\nPreconditioner types (see PreconditionerType):\n\nMidpointInverse - Inverse of midpoint matrix\nLUFactorization - LU-based preconditioner\nLDLTFactorization - LDLT-based preconditioner (symmetric)\nIdentityPreconditioner - No preconditioning","category":"section"},{"location":"linearsystems/#Overdetermined-Systems","page":"Linear Systems","title":"Overdetermined Systems","text":"Least squares solutions for overdetermined systems.\n\nsubsquares_method - Subsquares method\nmulti_jacobi_method - Multi-Jacobi method\ninterval_least_squares - Interval least squares\nOverdeterminedResult - Result type","category":"section"},{"location":"linearsystems/#Shaving","page":"Linear Systems","title":"Shaving","text":"Interval shaving for tightening bounds.\n\ninterval_shaving - Iterative shaving\nsherman_morrison_inverse_update - Efficient inverse updates\nShavingResult - Result type","category":"section"},{"location":"linearsystems/#H-Matrix-Systems","page":"Linear Systems","title":"H-Matrix Systems","text":"Verified solvers for H-matrices (hierarchical matrices).\n\nverified_linear_solve_hmatrix - H-matrix linear solver\nVerifiedLinearSystemResult - Result type","category":"section"},{"location":"linearsystems/#Matrix-Regularity","page":"Linear Systems","title":"Matrix Regularity","text":"Functions to verify matrix regularity (invertibility).\n\nis_regular - Main regularity test\nis_regular_sufficient_condition - Sufficient condition check\nis_regular_gershgorin - Gershgorin-based check\nis_regular_diagonal_dominance - Diagonal dominance check\nis_singular_sufficient_condition - Singularity test\nRegularityResult - Result type","category":"section"},{"location":"linearsystems/#Determinant-Bounds","page":"Linear Systems","title":"Determinant Bounds","text":"Rigorous bounds on matrix determinants.\n\ninterval_det - Interval determinant\ndet_hadamard - Hadamard bound\ndet_gershgorin - Gershgorin bound\ndet_cramer - Cramer-based bound\ncontains_zero - Check if determinant contains zero\nDeterminantResult - Result type","category":"section"},{"location":"svd/#Singular-Value-Decomposition","page":"SVD","title":"Singular Value Decomposition","text":"This page documents verified SVD computation and related tools.","category":"section"},{"location":"svd/#Rigorous-SVD","page":"SVD","title":"Rigorous SVD","text":"The rigorous_svd function computes verified singular value decomposition with guaranteed error bounds on the singular values and vectors. It returns a RigorousSVDResult containing the factors and bounds.","category":"section"},{"location":"svd/#Adaptive-Ogita-SVD","page":"SVD","title":"Adaptive Ogita SVD","text":"The adaptive_ogita_svd function uses iterative refinement to achieve tighter singular value bounds. This is particularly useful when high precision is needed. The refinement algorithm is based on Ref. [6].\n\nRelated functions:\n\nogita_svd_refine - Single refinement step\nOgitaSVDRefinementResult - Result type for refinement\nAdaptiveSVDResult - Result type for adaptive SVD","category":"section"},{"location":"svd/#Miyajima-VBD-(Verified-Block-Diagonalization)","page":"SVD","title":"Miyajima VBD (Verified Block Diagonalization)","text":"The miyajima_vbd function performs block diagonalization for eigenvalue clustering and spectral separation analysis. Returns a MiyajimaVBDResult.","category":"section"},{"location":"svd/#Singular-Value-Bounds","page":"SVD","title":"Singular Value Bounds","text":"Low-level functions for computing rigorous bounds on singular values:\n\nsvdbox - Box enclosure for singular values\ncollatz_upper_bound_L2_opnorm - Collatz bound for L2 operator norm\nupper_bound_L2_opnorm - Upper bound on L2 operator norm\nqi_intervals - Qi's singular value intervals\nqi_sqrt_intervals - Qi's intervals with square root bounds","category":"section"},{"location":"eigenvalues/#Eigenvalues,-Sylvester-Equations,-and-Projectors","page":"Eigenvalues","title":"Eigenvalues, Sylvester Equations, and Projectors","text":"This page documents verified eigenvalue computation, Sylvester equation solvers, and spectral projectors.","category":"section"},{"location":"eigenvalues/#Overview","page":"Eigenvalues","title":"Overview","text":"We implement several algorithms to compute rigorous enclosures of eigenvalues, following Ref. [7]. The interested reader may refer to the treatment in Eigenvalues in Arb for a deeper discussion on the topic.","category":"section"},{"location":"eigenvalues/#Standard-Eigenvalue-Problems","page":"Eigenvalues","title":"Standard Eigenvalue Problems","text":"","category":"section"},{"location":"eigenvalues/#Main-Functions","page":"Eigenvalues","title":"Main Functions","text":"rigorous_eigenvalues - General eigenvalue verification\nrump_2022a_eigenvalue_bounds - Individual eigenvector error bounds (Rump 2022a method)\nrump_lange_2023_cluster_bounds - Schur-based cluster bounds\nrefine_cluster_bounds - Iterative refinement of cluster bounds","category":"section"},{"location":"eigenvalues/#Result-Types","page":"Eigenvalues","title":"Result Types","text":"RigorousEigenvaluesResult - Result from rigorous eigenvalue computation\nRump2022aResult - Result with individual eigenvector bounds\nRumpLange2023Result - Schur-based result","category":"section"},{"location":"eigenvalues/#Generalized-Eigenvalue-Problems","page":"Eigenvalues","title":"Generalized Eigenvalue Problems","text":"For the generalized eigenvalue problem Ax = lambda Bx:\n\nverify_generalized_eigenpairs - Verify all eigenpairs\nrigorous_generalized_eigenvalues - Full rigorous computation\ncompute_beta_bound - Compute β bound for B matrix","category":"section"},{"location":"eigenvalues/#Result-Types-2","page":"Eigenvalues","title":"Result Types","text":"GEVResult - Generalized eigenvalue result\nRigorousGeneralizedEigenvaluesResult - Full result with bounds","category":"section"},{"location":"eigenvalues/#Sylvester-Equations","page":"Eigenvalues","title":"Sylvester Equations","text":"Fast verified computation for solutions of Sylvester equations AX + XB = C, following Ref. [3].\n\nsylvester_miyajima_enclosure - General Sylvester solver\ntriangular_sylvester_miyajima_enclosure - Triangular variant","category":"section"},{"location":"eigenvalues/#Spectral-Projectors","page":"Eigenvalues","title":"Spectral Projectors","text":"Computation of spectral projectors for eigenvalue clustering, following Ref. [8].\n\nmiyajima_spectral_projectors - Main spectral projector computation\ncompute_spectral_projector_schur - Schur-based projector\ncompute_spectral_projector_hermitian - Hermitian case","category":"section"},{"location":"eigenvalues/#Eigenspace-Projection","page":"Eigenvalues","title":"Eigenspace Projection","text":"project_onto_eigenspace - Project vector onto eigenspace\nproject_onto_schur_subspace - Project onto Schur subspace\ncompute_eigenspace_projector - Compute eigenspace projection matrix\ncompute_schur_projector - Compute Schur subspace projector","category":"section"},{"location":"eigenvalues/#Result-Types-3","page":"Eigenvalues","title":"Result Types","text":"RigorousSpectralProjectorsResult - Spectral projector result\nSchurSpectralProjectorResult - Schur-based result","category":"section"},{"location":"eigenvalues/#Block-Schur-Decomposition","page":"Eigenvalues","title":"Block Schur Decomposition","text":"Rigorous block Schur decomposition for eigenvalue clustering.\n\nrigorous_block_schur - Block Schur decomposition\nextract_cluster_block - Extract diagonal block for cluster\nrefine_schur_decomposition - Newton-based iterative refinement\nrigorous_schur_bigfloat - BigFloat precision variant","category":"section"},{"location":"eigenvalues/#Auxiliary-Functions","page":"Eigenvalues","title":"Auxiliary Functions","text":"newton_schulz_orthogonalize! - Newton-Schulz orthogonalization","category":"section"},{"location":"eigenvalues/#Result-Types-4","page":"Eigenvalues","title":"Result Types","text":"RigorousBlockSchurResult - Block Schur result\nSchurRefinementResult - Refinement result","category":"section"},{"location":"api/core/#API-Core-Types","page":"Core Types","title":"API - Core Types","text":"Core ball arithmetic types and basic operations.","category":"section"},{"location":"api/core/#Ball-Type","page":"Core Types","title":"Ball Type","text":"","category":"section"},{"location":"api/core/#Array-Types","page":"Core Types","title":"Array Types","text":"","category":"section"},{"location":"api/core/#Norm-Bounds","page":"Core Types","title":"Norm Bounds","text":"","category":"section"},{"location":"api/core/#L2-Operator-Norm:-Method-Comparison","page":"Core Types","title":"L2 Operator Norm: Method Comparison","text":"The package provides several methods for computing rigorous upper bounds on ‖A‖₂:\n\nMethod Complexity Accuracy Description\nsvd_bound_L2_opnorm O(n³) Exact (~0%) Computes rigorous SVD, returns largest σ\ncollatz_upper_bound_L2_opnorm O(k·n²) 0-500%* Iterative power method on |A|ᵀ|A|\nsqrt(‖·‖₁·‖·‖∞) O(n²) 87-564% Uses ‖A‖₂ ≤ √(‖A‖₁·‖A‖∞)\nupper_bound_L2_opnorm O(k·n²) min of above Takes minimum of Collatz and sqrt\n\n*Collatz accuracy depends heavily on matrix structure:\n\nTridiagonal/banded: ~0% overestimation (essentially exact)\nHilbert-like matrices: ~0% overestimation\nDiagonally dominant: ~26% overestimation\nRandom dense matrices: 200-500% overestimation","category":"section"},{"location":"api/core/#Benchmark-Results-(nn-matrices)","page":"Core Types","title":"Benchmark Results (n×n matrices)","text":"Matrix type               Collatz   sqrt(‖·‖₁·‖·‖∞)   SVD bound\n─────────────────────────────────────────────────────────────────\nRandom (n=50)             186%      249%              0%\nDiagonally dominant       26%       36%               0%\nTridiagonal               0.1%      0.1%              0%\nSymmetric positive def.   140%      230%              0%\nLow rank + noise          54%       143%              0%\nHilbert-like              0%        117%              0%","category":"section"},{"location":"api/core/#Recommendations","page":"Core Types","title":"Recommendations","text":"General use: upper_bound_L2_opnorm (fast, takes best of cheap bounds)\nAccuracy critical: svd_bound_L2_opnorm (exact but O(n³))\nStructured matrices: collatz_upper_bound_L2_opnorm often gives near-exact results","category":"section"},{"location":"api/core/#Oishi-2023-Schur-Complement-Bounds","page":"Core Types","title":"Oishi 2023 Schur Complement Bounds","text":"Lower bounds on minimum singular values using the Schur complement method from Oishi (2023), \"Lower bounds for the smallest singular values of generalized asymptotic diagonal dominant matrices\".","category":"section"},{"location":"api/core/#Rump-Oishi-2024-Improved-Schur-Complement-Bounds","page":"Core Types","title":"Rump-Oishi 2024 Improved Schur Complement Bounds","text":"Improved bounds from Rump & Oishi (2024), \"A Note on Oishi's Lower Bound for the Smallest Singular Value of Linearized Galerkin Equations\".","category":"section"},{"location":"api/core/#Key-Improvements-over-Oishi-2023","page":"Core Types","title":"Key Improvements over Oishi 2023","text":"Removes conditions 1 & 2: No longer requires ‖A⁻¹B‖ < 1 and ‖CA⁻¹‖ < 1. Only condition 3 (‖Dd⁻¹(Df - CA⁻¹B)‖ < 1) is needed.\nUses exact ψ(N) formula: Instead of 1/(1-‖N‖), uses ψ(μ) = √(1 + 2αμ√(1-α²) + α²μ²) which is tighter and works for any μ ≥ 0.\nFast γ bound (optional): Uses π(N) = √(‖N‖₁·‖N‖∞) to quickly check if the method will succeed, avoiding expensive matrix products and reducing complexity from O((n-m)²m) to O((n-m)m²).","category":"section"},{"location":"api/core/#Example","page":"Core Types","title":"Example","text":"using BallArithmetic, LinearAlgebra\n\n# Create a diagonally dominant matrix (Example 3 from paper)\nk, n = 0.9, 50\nG_mid = [i == j ? Float64(i) : k^abs(i-j) for i in 1:n, j in 1:n]\nG = BallMatrix(G_mid, zeros(n, n))\n\n# Compute bounds with optimal block size\nbest_m, result = rump_oishi_2024_optimal_block_size(G; max_m=30)\n\nif result.verified\n    println(\"σ_min(G) ≥ \", result.sigma_min_lower)\n    println(\"‖G⁻¹‖ ≤ \", result.G_inv_upper)\n    println(\"Optimal block size: m = \", best_m)\n    println(\"Used fast γ bound: \", result.used_fast_gamma)\nend","category":"section"},{"location":"api/core/#API-Reference","page":"Core Types","title":"API Reference","text":"","category":"section"},{"location":"api/core/#BallArithmetic.Ball","page":"Core Types","title":"BallArithmetic.Ball","text":"Ball{T, CT}\n\nClosed floating-point ball with midpoint type CT and radius type T. Each value represents the set { c + δ : |δ| ≤ r } where c::CT is the stored midpoint and r::T ≥ 0 is the radius. Both real and complex midpoints are supported as long as the radius is expressed in the underlying real field. The type behaves as a number and participates in arithmetic with rigorous outward rounding.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.BallF64","page":"Core Types","title":"BallArithmetic.BallF64","text":"Ball{T, CT}\n\nClosed floating-point ball with midpoint type CT and radius type T. Each value represents the set { c + δ : |δ| ≤ r } where c::CT is the stored midpoint and r::T ≥ 0 is the radius. Both real and complex midpoints are supported as long as the radius is expressed in the underlying real field. The type behaves as a number and participates in arithmetic with rigorous outward rounding.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.BallComplexF64","page":"Core Types","title":"BallArithmetic.BallComplexF64","text":"Ball{T, CT}\n\nClosed floating-point ball with midpoint type CT and radius type T. Each value represents the set { c + δ : |δ| ≤ r } where c::CT is the stored midpoint and r::T ≥ 0 is the radius. Both real and complex midpoints are supported as long as the radius is expressed in the underlying real field. The type behaves as a number and participates in arithmetic with rigorous outward rounding.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.mid","page":"Core Types","title":"BallArithmetic.mid","text":"mid(x)\n\nReturn the midpoint of x. For plain numbers the midpoint is the value itself, while for balls the stored center is returned.\n\n\n\n\n\nmid(v::AbstractVector{<:Ball})\n\nReturn a vector of midpoints for a collection of balls.\n\n\n\n\n\nmid(M::AbstractMatrix{<:Ball})\n\nReturn a matrix of midpoints for a collection of balls.\n\n\n\n\n\nmid(A::AbstractArray)\n\nFallback definition that treats ordinary arrays as their own midpoint representation. Specialisations for BallArray overload this method to return the stored midpoint data.\n\n\n\n\n\nmid(A::BallArray)\n\nReturn the stored midpoint array.\n\n\n\n\n\nmid(A::AbstractMatrix)\n\nReturn the midpoint matrix associated with A. For plain matrices the midpoint equals the matrix itself; for BallMatrix values this method is extended elsewhere to extract the stored midpoint data.\n\n\n\n\n\nmid(v::AbstractVector)\n\nTreat ordinary vectors as their own midpoints.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.rad","page":"Core Types","title":"BallArithmetic.rad","text":"rad(x)\n\nReturn the radius associated with x. Numbers default to a zero radius, and balls return their stored uncertainty.\n\n\n\n\n\nrad(v::AbstractVector{<:Ball})\n\nReturn a vector of radii for a collection of balls.\n\n\n\n\n\nrad(M::AbstractMatrix{<:Ball})\n\nReturn a matrix of radii for a collection of balls.\n\n\n\n\n\nrad(A::AbstractArray)\n\nReturn a zero array of matching size that serves as the default radius for non-ball arrays.\n\n\n\n\n\nrad(A::BallArray)\n\nReturn the stored radius array.\n\n\n\n\n\nrad(A::AbstractMatrix{T})\n\nReturn a matrix of radii matching the size of A. For non-ball matrices this defaults to a zero matrix, while for BallMatrix values the method is overloaded to provide the stored uncertainty information.\n\n\n\n\n\nrad(A::AbstractMatrix{Complex{T}})\n\nReturn a matrix of real radii matching the size of the complex matrix A. Even for complex entries the radius is measured over the underlying real field, hence the resulting matrix has element type T.\n\n\n\n\n\nrad(v::AbstractVector)\n\nDefault radius for non-ball vectors: a zero vector of the appropriate floating-point type.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.midtype","page":"Core Types","title":"BallArithmetic.midtype","text":"midtype(::Ball)\n\nReturn the type used to store the midpoint component of a Ball. This is useful for allocating arrays that mirror the internal layout of a ball or a collection of balls.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.radtype","page":"Core Types","title":"BallArithmetic.radtype","text":"radtype(x)\n\nReturn the floating-point type used to store radii for x. The helper accepts either a ball instance or the associated type, mirroring the behaviour of midtype.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.inf","page":"Core Types","title":"BallArithmetic.inf","text":"inf(x::Ball)\n\nReturn the infimum (lower endpoint) of the set represented by x by evaluating mid(x) - rad(x) with downward rounding.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.sup","page":"Core Types","title":"BallArithmetic.sup","text":"sup(x::Ball)\n\nReturn the supremum (upper endpoint) of the set represented by x by evaluating mid(x) + rad(x) with outward rounding.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.ball_hull","page":"Core Types","title":"BallArithmetic.ball_hull","text":"ball_hull(a::Ball, b::Ball)\n\nReturn the smallest ball that contains both a and b. For real centres the function encloses the convex hull on the real line. When the midpoints are complex the result encloses both discs while keeping the centre as close as possible to one of the inputs so that subsequent operations remain stable.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.intersect_ball","page":"Core Types","title":"BallArithmetic.intersect_ball","text":"intersect_ball(a::Ball, b::Ball)\n\nReturn the intersection of the real balls a and b. When the balls do not overlap the function returns nothing to indicate that the intersection is empty.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.BallArray","page":"Core Types","title":"BallArithmetic.BallArray","text":"BallArray{T, N, NT, BT, CA, RA}\n\nMulti-dimensional array whose entries are Ball values. The type stores midpoint data c::CA and radius data r::RA separately while presenting an AbstractArray{BT, N} interface that behaves like an array of balls. The parameters mirror the element type and storage layout and are inferred automatically from the provided midpoint and radius containers.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.BallMatrix","page":"Core Types","title":"BallArithmetic.BallMatrix","text":"BallMatrix{T, NT, BT, CM, RM}\n\nAlias for the two-dimensional BallArray used to represent matrices with rigorous error control. The type parameters mirror those of BallArray and describe the base floating-point type T, the element type NT, the Ball container BT, and the concrete matrix types used for the midpoints (CM) and radii (RM).\n\nUsers typically construct instances through the BallMatrix constructors below rather than specifying these parameters explicitly.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.BallVector","page":"Core Types","title":"BallArithmetic.BallVector","text":"BallVector{T, NT, BT, CM, RM}\n\nAlias for the one-dimensional BallArray, representing vectors of balls.\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.upper_bound_norm","page":"Core Types","title":"BallArithmetic.upper_bound_norm","text":"upper_bound_norm(A::BallMatrix, p::Real = 2)\n\nCompute a rigorous upper bound for the p-norm of a BallMatrix by computing the norm of the midpoint and radius arrays with upward rounding. The default p = 2 corresponds to the Frobenius norm.\n\n\n\n\n\nupper_bound_norm(v::BallVector, p::Real = 2)\n\nCompute a rigorous upper bound for the p-norm of a BallVector.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.upper_bound_L1_opnorm","page":"Core Types","title":"BallArithmetic.upper_bound_L1_opnorm","text":"upper_bound_L1_opnorm(A::BallMatrix{T})\n\nReturns a rigorous upper bound on the ℓ¹-norm of the ball matrix A\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.upper_bound_L2_opnorm","page":"Core Types","title":"BallArithmetic.upper_bound_L2_opnorm","text":"upper_bound_L_inf_opnorm(A::BallMatrix{T})\n\nReturns a rigorous upper bound on the ℓ²-norm of the ball matrix A using the best between the Collatz bound and the interpolation bound\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.upper_bound_L_inf_opnorm","page":"Core Types","title":"BallArithmetic.upper_bound_L_inf_opnorm","text":"upper_bound_L_inf_opnorm(A::BallMatrix{T})\n\nReturns a rigorous upper bound on the ℓ-∞-norm of the ball matrix A\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.collatz_upper_bound_L2_opnorm","page":"Core Types","title":"BallArithmetic.collatz_upper_bound_L2_opnorm","text":"collatz_upper_bound_L2_opnorm(A::BallMatrix; iterates=10)\n\nGive a rigorous upper bound on the ℓ² norm of the matrix A by using the Collatz theorem.\n\nWe use Perron theory here: if for two matrices with B positive |A| < B we have ρ(A)<=ρ(B) by Wielandt's theorem Wielandt's theorem\n\nThe keyword argument iterates is used to establish how many times we are iterating the vector of ones before we use Collatz's estimate.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.svd_bound_L2_opnorm","page":"Core Types","title":"BallArithmetic.svd_bound_L2_opnorm","text":"svd_bound_L2_opnorm(A::BallMatrix{T})\n\nReturns a rigorous upper bound on the ℓ²-norm (spectral norm) of the ball matrix A using the rigorous SVD enclosure from rigorous_svd.\n\nThis method computes the largest certified singular value, providing the tightest possible upper bound on ‖A‖₂. The bound is essentially exact (typically <0.01% overestimation), but requires O(n³) computation for the SVD.\n\nComparison with other L2 norm methods\n\nMethod Speed Accuracy Best use case\nsvd_bound_L2_opnorm O(n³) ~0% overest. When accuracy is critical\ncollatz_upper_bound_L2_opnorm Fast 0-500% overest.* Structured matrices\nupper_bound_L2_opnorm Fast min of above General use\n\n*Collatz performs well on structured matrices (tridiagonal: ~0%, Hilbert: ~0%, diagonally dominant: ~26%) but poorly on random matrices (~200-500%).\n\nExample\n\nA = BallMatrix(randn(50, 50))\nbound = svd_bound_L2_opnorm(A)  # Tight bound, slower\nfast_bound = upper_bound_L2_opnorm(A)  # Looser bound, faster\n\nSee also: upper_bound_L2_opnorm, collatz_upper_bound_L2_opnorm, rigorous_svd\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.rump_oishi_2024_triangular_bound","page":"Core Types","title":"BallArithmetic.rump_oishi_2024_triangular_bound","text":"rump_oishi_2024_triangular_bound(T::BallMatrix, k::Int; method=:hybrid)\n\nCompute rigorous upper bound on ‖T[1:k,:]⁻¹‖₂ for upper triangular T.\n\nImplements the bounds from RumpOishi2024 with improved handling of the Collatz spectral radius estimate for triangular matrices.\n\nArguments\n\nT::BallMatrix: Upper triangular ball matrix\nk::Int: Block size (compute bound for first k rows/columns)\nmethod::Symbol: Method to use\n:psi - ψ-bound method (original RumpOishi2024)\n:backward - Backward substitution method\n:hybrid - Use best of both methods (default)\n\nMethod Details\n\nΨ-bound method:\n\nFor block structure T = [A B; 0 D] where A is k×k:\n\nCompute E = A⁻¹B via backward substitution\nCompute F = D_d⁻¹ D_f where D = D_d + D_f (diagonal + off-diagonal)\nEstimate using ψ bounds: ‖T⁻¹‖ ≤ max(α, β) · ψ(E) where α = ‖A⁻¹‖, β = ‖D_d⁻¹‖/(1-‖F‖)\n\nBackward substitution method:\n\nRecursively compute bounds for singular values using: σᵢ = (1/|dᵢᵢ|) · √(1 + ‖bᵢ‖² · σᵢ₊₁²) where bᵢ is the i-th row tail and dᵢᵢ is the i-th diagonal.\n\nReturns\n\nRigorous upper bound on ‖T[1:k,:]⁻¹‖₂ as a floating-point number.\n\nReference\n\nRump & Oishi (2024), \"A Note on Oishi's Lower Bound...\", SIAM J. Matrix Anal. Appl.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.backward_singular_value_bound","page":"Core Types","title":"BallArithmetic.backward_singular_value_bound","text":"backward_singular_value_bound(A::BallMatrix)\n\nCompute rigorous upper bounds for singular values of upper triangular matrix using backward recursion.\n\nFor upper triangular A, computes bounds σᵢ such that σᵢ(A) ≤ σᵢ for i=1,...,n using the recursion:\n\nσᵢ = (1/|aᵢᵢ|) · √(1 + ‖row_tail_i‖² · σᵢ₊₁²)\n\nstarting from σₙ₊₁ = 0.\n\nReference\n\nRumpOishi2024, Theorem 3.2\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.Oishi2023Result","page":"Core Types","title":"BallArithmetic.Oishi2023Result","text":"Oishi2023Result{T}\n\nResult from the Oishi 2023 Schur complement bound computation.\n\nFields\n\nsigma_min_lower: Rigorous lower bound on the minimum singular value\nG_inv_upper: Upper bound on ‖G⁻¹‖₂ (= 1/σ_min)\nA_inv_norm: Upper bound on ‖A⁻¹‖₂\nA_inv_B_norm: Upper bound on ‖A⁻¹B‖₂\nC_A_inv_norm: Upper bound on ‖CA⁻¹‖₂\nschur_contraction: Upper bound on ‖Dd⁻¹(Df - CA⁻¹B)‖₂\nverified: Whether all conditions of Theorem 1 are satisfied\nblock_size: The block size m used\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.oishi_2023_sigma_min_bound","page":"Core Types","title":"BallArithmetic.oishi_2023_sigma_min_bound","text":"oishi_2023_sigma_min_bound(G::BallMatrix{T}, m::Int) where {T}\n\nCompute a rigorous lower bound on the minimum singular value of G using the Schur complement method from Oishi (2023).\n\nArguments\n\nG::BallMatrix: The matrix to analyze\nm::Int: Block size for the partition (A is m×m)\n\nMethod (Theorem 1 from Oishi 2023)\n\nPartition G as:\n\nG = [A  B]\n    [C  D]\n\nwhere A ∈ Mm, B ∈ M{m,n-m}, C ∈ M{n-m,m}, D ∈ M{n-m,n-m}.\n\nLet Dd and Df be the diagonal and off-diagonal parts of D.\n\nIf the following conditions hold:\n\n‖A⁻¹B‖₂ < 1\n‖CA⁻¹‖₂ < 1\n‖Dd⁻¹(Df - CA⁻¹B)‖₂ < 1\n\nThen G is invertible and:\n\n‖G⁻¹‖₂ ≤ max{‖A⁻¹‖₂, ‖D_d⁻¹‖₂/(1 - ‖D_d⁻¹(D_f - CA⁻¹B)‖₂)}\n         / ((1 - ‖A⁻¹B‖₂)(1 - ‖CA⁻¹‖₂))\n\nSince σmin(G) = 1/‖G⁻¹‖₂, this gives a lower bound on σmin.\n\nReturns\n\nOishi2023Result containing the bounds and verification status.\n\nReference\n\nOishi, S. (2023), Japan J. Indust. Appl. Math. 40:1569-1585\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.oishi_2023_optimal_block_size","page":"Core Types","title":"BallArithmetic.oishi_2023_optimal_block_size","text":"oishi_2023_optimal_block_size(G::BallMatrix{T}; max_m::Int=100) where {T}\n\nFind the optimal block size m that gives the tightest bound on σ_min.\n\nReturns a tuple (bestm, bestresult).\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.RumpOishi2024Result","page":"Core Types","title":"BallArithmetic.RumpOishi2024Result","text":"RumpOishi2024Result{T}\n\nResult from the Rump-Oishi 2024 improved Schur complement bound computation.\n\nThis improves upon Oishi 2023 by:\n\nRemoving the conditions ‖A⁻¹B‖ < 1 and ‖CA⁻¹‖ < 1\nUsing the exact ψ(N) formula instead of 1/(1-‖N‖)\nOptionally using a fast γ bound to avoid expensive matrix products\n\nFields\n\nsigma_min_lower: Rigorous lower bound on the minimum singular value\nG_inv_upper: Upper bound on ‖G⁻¹‖₂ (= 1/σ_min)\nA_inv_norm: Upper bound on ‖A⁻¹‖₂\npsi_A_inv_B: ψ(‖A⁻¹B‖₂) factor\npsi_C_A_inv: ψ(‖CA⁻¹‖₂) factor\nschur_contraction: Upper bound on ‖Dd⁻¹(Df - CA⁻¹B)‖₂\nused_fast_gamma: Whether the fast γ bound was used\nverified: Whether the method succeeded (only requires schur_contraction < 1)\nblock_size: The block size m used\n\nReference\n\nRump, S.M. & Oishi, S. (2024), \"A Note on Oishi's Lower Bound for the Smallest Singular Value of Linearized Galerkin Equations\"\n\n\n\n\n\n","category":"type"},{"location":"api/core/#BallArithmetic.rump_oishi_2024_sigma_min_bound","page":"Core Types","title":"BallArithmetic.rump_oishi_2024_sigma_min_bound","text":"rump_oishi_2024_sigma_min_bound(G::BallMatrix{T}, m::Int;\n                                 try_fast_gamma::Bool=true) where {T}\n\nCompute a rigorous lower bound on the minimum singular value of G using the improved Schur complement method from Rump-Oishi (2024).\n\nArguments\n\nG::BallMatrix: The matrix to analyze\nm::Int: Block size for the partition (A is m×m)\ntry_fast_gamma::Bool=true: Whether to try the fast γ bound first\n\nImprovements over Oishi 2023\n\nRemoves conditions 1 & 2: No longer requires ‖A⁻¹B‖ < 1 and ‖CA⁻¹‖ < 1. Only condition 3 (‖Dd⁻¹(Df - CA⁻¹B)‖ < 1) is needed.\nUses exact ψ(N) formula: Instead of 1/(1-‖N‖), uses ψ(μ) = √(1 + 2αμ√(1-α²) + α²μ²) which is tighter and works for any μ ≥ 0.\nFast γ bound (optional): Uses π(N) = √(‖N‖₁·‖N‖∞) to quickly check if the method will succeed, avoiding expensive matrix products.\n\nMethod (Theorem 1.3 from Rump-Oishi 2024)\n\nPartition G as:\n\nG = [A  B]\n    [C  D]\n\nIf ‖Dd⁻¹(Df - CA⁻¹B)‖ < 1, then:\n\n‖G⁻¹‖ ≤ max{‖A⁻¹‖, ‖Dd⁻¹‖/(1 - ‖Dd⁻¹(Df - CA⁻¹B)‖)} · ψ(‖A⁻¹B‖) · ψ(‖CA⁻¹‖)\n\nReturns\n\nRumpOishi2024Result containing the bounds and verification status.\n\nReference\n\nRump, S.M. & Oishi, S. (2024), \"A Note on Oishi's Lower Bound for the Smallest Singular Value of Linearized Galerkin Equations\"\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.rump_oishi_2024_optimal_block_size","page":"Core Types","title":"BallArithmetic.rump_oishi_2024_optimal_block_size","text":"rump_oishi_2024_optimal_block_size(G::BallMatrix{T}; max_m::Int=100,\n                                    try_fast_gamma::Bool=true) where {T}\n\nFind the optimal block size m that gives the tightest bound on σ_min using the Rump-Oishi 2024 method.\n\nReturns a tuple (bestm, bestresult).\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.psi_schur_factor","page":"Core Types","title":"BallArithmetic.psi_schur_factor","text":"psi_schur_factor(μ::T) where {T}\n\nCompute ψ(μ) from Lemma 1.2 of Rump-Oishi 2024.\n\nFor a block triangular matrix H = [I, -N; 0, I] with ‖N‖ = μ, this computes the exact value of ‖H‖ = ‖H⁻¹‖.\n\nThe formula is:     α = √(½(1 + 1/√(1 + 4/μ²)))     ψ(μ) = √(1 + 2αμ√(1-α²) + α²μ²)\n\nThis replaces the weaker bound 1/(1-μ) used in Oishi 2023, and works for any μ ≥ 0 (no restriction μ < 1).\n\nReturns\n\nψ(μ) as an upper bound (computed with directed rounding).\n\n\n\n\n\n","category":"function"},{"location":"api/core/#BallArithmetic.pi_norm","page":"Core Types","title":"BallArithmetic.pi_norm","text":"pi_norm(M::BallMatrix{T}) where {T}\n\nCompute π(M) = √(‖M‖₁ · ‖M‖∞), an upper bound on ‖M‖₂.\n\nThis is a cheap bound useful for the fast γ estimate in Rump-Oishi 2024.\n\n\n\n\n\n","category":"function"},{"location":"literate/warmstart_investigation/#Warm-Start-Investigation-for-Circle-Certification","page":"Warm-Start Investigation for Circle Certification","title":"Warm-Start Investigation for Circle Certification","text":"","category":"section"},{"location":"literate/warmstart_investigation/#Executive-Summary","page":"Warm-Start Investigation for Circle Certification","title":"Executive Summary","text":"Goal: Accelerate resolvent certification at multiple points around a circle.\n\nKey findings:\n\nDirect warm-start of Ogita refinement fails - fresh Float64 SVD is more accurate than reusing previous point's SVD\nWarm-start of the Float64 SVD computation provides modest speedup (1.1-1.2x)\nAll extended precision methods (Double64, BigFloat) give identical certified bounds\nDouble64 is 10-20x faster than BigFloat for the refinement phase\nSub-machine-precision circles work - BigFloat center + Ogita refinement can certify circles with radius ≤ 1e-16\n\nRecommended algorithm (normal radius r > 1e-14):\n\nCompute Float64 SVD (cold or warm-started via power iteration)\nRefine with Double64 (~106 bits) for 2 iterations\nFinal certification with BigFloat (256+ bits)\n\nAlgorithm for sub-ε radius (r ≤ 1e-16):\n\nRepresent center and radius in BigFloat (256+ bits)\nCompute Float64 SVD at center (same for all points)\nFor each point: Ogita refinement in BigFloat starting from center's SVD\nDistinct σ_min values achieved despite identical Float64 representations\n\nPrecision cascade investigation:\n\nWe tested adaptive cascades: Float64 → Double64 → Float64x3 → Float64x4 → BigFloat.\n\nFindings:\n\nLAPACK's Float64 SVD is already near-optimal (residual ~1e-14)\nFirst Ogita iteration at Float64 can increase residual (rounding effects)\nPure BigFloat (5 iterations) achieves ~1e-76 residual via quadratic convergence\nCascade achieves ~1e-14 residual in similar time - no speedup for small matrices\n\nGenericLinearAlgebra discovery:\n\nGenericLinearAlgebra.jl provides a native BigFloat SVD that is both faster and more accurate than all cascade methods. It computes SVD directly at full precision without needing refinement.\n\nFinal benchmark (100×100 matrix, 256-bit BigFloat):\n\nMethod Time Residual Speedup\nGLA (no refine) 4.2s 4e-74 6.6x\nD64 only: F64→D64→BF 11.7s 1e-12 2.4x\nMinimal: F64→MF3→BF 12.2s 1e-12 2.3x\nFull cascade 15.0s 1e-13 1.8x\nPure Ogita: F64→BF(5) 27.7s 1e-12 1.0x\n\nKey insights:\n\nGLA is 6.6x faster than pure Ogita and 2.8x faster than the best cascade\nGLA achieves 60+ orders of magnitude better residual (1e-74 vs 1e-12)\nRefinement iterations are unnecessary for GLA (and slightly degrade accuracy)\nSimpler cascades (D64 only) outperform complex ones (full cascade)\n\nTiming comparison (n=200 matrix, single point): | Method | Time | Residual | Speedup | |––––|–––|–––––|––––-| | Cascade (1×F64→1×D64→1×MF3→1×MF4→2×BF) | 196s | 3.3e-12 | 2.08x | | Pure BigFloat (5 iter) | 407s | 5.0e-12 | 1.0x |\n\nTiming comparison (n=500 matrix, single point): | Method | Time | Residual | Speedup | |––––|–––|–––––|––––-| | Cascade (1×F64→1×D64→1×MF3→1×MF4→2×BF) | 3234s | 1.4e-11 | 1.94x | | Pure BigFloat (5 iter) | 6279s | 1.6e-11 | 1.0x |\n\nRecommended methods:\n\n# Best overall (requires GenericLinearAlgebra):\nusing BallArithmetic, GenericLinearAlgebra\nresult = ogita_svd_cascade_gla(T_bf, z_bf)  # 6.6x faster, 1e-74 residual\n\n# Without GenericLinearAlgebra (use simplest cascade):\nusing BallArithmetic, MultiFloats\nresult = ogita_svd_cascade(T_bf, z_bf;\n    f64_iters=1, d64_iters=1, mf3_iters=0, mf4_iters=0, bf_iters=2)\n\nConclusion:\n\nUse GLA (ogita_svd_cascade_gla) when possible - fastest and most accurate\nFor matrices without GLA, use D64 only cascade (F64→D64→BF)\nThe full cascade with MF3/MF4 adds overhead without significant benefit","category":"section"},{"location":"literate/warmstart_investigation/#Terminology","page":"Warm-Start Investigation for Circle Certification","title":"Terminology","text":"Cold-start SVD: Compute full SVD from scratch using LAPACK (svd(A))\nWarm-start SVD: Use previous point's U, V as initial guess, refine via power/subspace iteration\nOgita refinement: Iterative algorithm that refines an approximate SVD to high precision (quadratic convergence)\nDouble64: Extended precision type (~106 bits) from DoubleFloats.jl - used in ogita_svd_refine_fast\nBigFloat: Arbitrary precision floating point - used for final rigorous certification\nMiyajima method: Ball arithmetic SVD certification (rigorous but slower)","category":"section"},{"location":"literate/warmstart_investigation/#Problem-Setup","page":"Warm-Start Investigation for Circle Certification","title":"Problem Setup","text":"When certifying the resolvent norm ||(zI - A)^{-1}|| at multiple points z around a circle, adjacent points have similar shifted matrices:\n\nA - z₁I and A - z₂I differ only by (z₂ - z₁)I\nFor a circle with n points, adjacent distance is |Δz| ≈ 2πr/n\n\nQuestion: Can we use the SVD from point z₁ to accelerate certification at z₂?","category":"section"},{"location":"literate/warmstart_investigation/#Key-Findings","page":"Warm-Start Investigation for Circle Certification","title":"Key Findings","text":"","category":"section"},{"location":"literate/warmstart_investigation/#1.-Singular-Vector-Rotation","page":"Warm-Start Investigation for Circle Certification","title":"1. Singular Vector Rotation","text":"Even for small |Δz|, singular vectors can rotate significantly:\n\n| |Δz| | Min Overlap | Warm-Start | |–––|––––––-|––––––| | 0.115 | 0.79 | Fails | | 0.058 | 0.94 | Works | | 0.029 | 0.99 | Works | | 0.015 | 0.996 | Works |\n\nThreshold: Warm-start works when min_overlap > 0.94, requiring |Δz| < 0.06.","category":"section"},{"location":"literate/warmstart_investigation/#2.-Singular-Value-Crossings","page":"Warm-Start Investigation for Circle Certification","title":"2. Singular Value Crossings","text":"The singular vectors rotate because singular values reorder as z changes:\n\nAt different z, the minimum gap moves between different singular value pairs\nThis causes the corresponding singular vectors to \"exchange roles\"\nEven without coalescence, vectors rotate within near-degenerate subspaces\n\nExample from our test matrix:\n\nθ=0.0:  min gap at σ[14]-σ[15]\nθ=0.79: min gap at σ[29]-σ[30]\nθ=1.18: min gap at σ[29]-σ[30]","category":"section"},{"location":"literate/warmstart_investigation/#3.-Ogita-Refinement-Requires-Accurate-Initial-Guess","page":"Warm-Start Investigation for Circle Certification","title":"3. Ogita Refinement Requires Accurate Initial Guess","text":"Comparing cold-start (fresh SVD) vs warm-start (previous point's SVD):\n\nIter Cold Residual Warm Residual\n1 2e-26 1.3e-04\n2 1e-43 5.6e-07\n3 2e-57 3e-08\n5 4e-85 9e-11\n\nKey insight: Fresh Float64 SVD has O(ε_machine) ≈ 1e-16 error, while warm-start from adjacent point has O(|Δz|) ≈ 1e-3 error. Cold-start wins!","category":"section"},{"location":"literate/warmstart_investigation/#4.-Why-Warm-Start-Fails-for-Ogita-Refinement","page":"Warm-Start Investigation for Circle Certification","title":"4. Why Warm-Start Fails for Ogita Refinement","text":"Ogita's RefSVD algorithm assumes the initial SVD approximation has error O(ε_machine). With quadratic convergence:\n\nFrom 1e-16 error: 2 iterations reach 1e-32, 3 iterations reach 1e-64\nFrom 1e-3 error: 2 iterations reach 1e-6, 5 iterations reach 1e-48\n\nThe O(|Δz|) error from warm-start is too large for efficient refinement.","category":"section"},{"location":"literate/warmstart_investigation/#5.-Near-Eigenvalue-Certification-Needs-BigFloat","page":"Warm-Start Investigation for Circle Certification","title":"5. Near-Eigenvalue Certification Needs BigFloat","text":"Testing with decreasing radius around center λ = 1.0:\n\nRadius σ_min Status\n0.050 3.4e-03 Float64 OK\n0.030 5.4e-04 Float64 OK\n0.022 7.9e-05 Float64 OK\n0.020 0 SINGULAR (on eigenvalue)\n0.018 7.2e-05 Float64 OK\n0.005 2.6e-04 Float64 OK\n\nAt radius = 0.02, the circle passes exactly through an eigenvalue. BigFloat is essential for certifying near eigenvalues where σ_min is tiny.","category":"section"},{"location":"literate/warmstart_investigation/#Precision-Comparison-(Cold-Start)","page":"Warm-Start Investigation for Circle Certification","title":"Precision Comparison (Cold-Start)","text":"All methods give identical certified bounds when they succeed:\n\nMethod Time (8 pts) Accuracy\nDouble64 0.32s 1.00x\nBigFloat 3.21s 1.00x\nMultiFloat 1.46s 1.00x\nFloat64 (Miyajima) 6.86s 1.00x\n\nRecommendation: Use Double64 for best speed/accuracy tradeoff.","category":"section"},{"location":"literate/warmstart_investigation/#Warm-Start-Float64-SVD:-Implementation-and-Results","page":"Warm-Start Investigation for Circle Certification","title":"Warm-Start Float64 SVD: Implementation and Results","text":"Since Ogita refinement benefits from accurate Float64 SVD, we implemented warm-starting the SVD computation itself using subspace iteration.","category":"section"},{"location":"literate/warmstart_investigation/#Algorithm","page":"Warm-Start Investigation for Circle Certification","title":"Algorithm","text":"function warm_svd(A, U_init, V_init; max_iter=2)\n    V = copy(V_init)\n    for iter in 1:max_iter\n        U = A * V;  U, _ = qr(U)  # Power iteration\n        V = A' * U; V, _ = qr(V)\n    end\n    U = A * V; U, _ = qr(U)\n    S = diag(U' * A * V)\n    return U, S, V\nend","category":"section"},{"location":"literate/warmstart_investigation/#Quality-of-Warm-SVD-Approximation","page":"Warm-Start Investigation for Circle Certification","title":"Quality of Warm SVD Approximation","text":"| Power Iter | Residual ||A - USV'|| | σ_min error | |––––––|––––––––––––|––––––-| | 0 (direct) | 9.8e-04 | 4.2e-02 | | 1 | 5.67 | 8.6e-13 | | 2 | 5.67 | 4.2e-13 | | Cold SVD | 1.4e-14 | 0 |\n\nThe large residual after power iteration is due to subspace basis differences, but singular VALUES are accurate (σ_min error ~1e-13).","category":"section"},{"location":"literate/warmstart_investigation/#Full-Chain-Results-(32-points,-radius0.005)","page":"Warm-Start Investigation for Circle Certification","title":"Full Chain Results (32 points, radius=0.005)","text":"Method Time Success Bound Agreement\nCold SVD + Ogita 13.11s 32/32 reference\nWarm SVD + Ogita 13.38s 32/32 mean 5.6e-12\nSpeedup 0.98x  ","category":"section"},{"location":"literate/warmstart_investigation/#Speedup-vs-Matrix-Size","page":"Warm-Start Investigation for Circle Certification","title":"Speedup vs Matrix Size","text":"Testing warm SVD speedup at different matrix sizes:\n\nn Cold Time Warm Time Speedup\n30 9.84s 8.24s 1.20x\n50 29.97s 29.48s 1.02x\n100 300.89s 279.36s 1.08x\n\nConclusion: Warm SVD provides modest speedup (1.08-1.20x) that varies with matrix size. The benefit is real but limited because:\n\nPower iterations cost O(n²) per iteration vs O(n³) for full SVD\nWith 2 power iterations, cost is ~O(n²) vs O(n³) - should help more for larger n\nBut BigFloat refinement cost (O(n³)) dominates the overall time","category":"section"},{"location":"literate/warmstart_investigation/#Summary","page":"Warm-Start Investigation for Circle Certification","title":"Summary","text":"Approach Works? Speedup Notes\nWarm Ogita (from prev z) No - Initial error O(\nWarm Ogita (small Δz ) Yes\nWarm Float64 SVD Yes 1.08-1.20x Modest speedup, varies with n\n\nBest approach: Use Double64 cold-start (10-20x faster than BigFloat). Warm SVD provides additional 1.1-1.2x speedup on top of that.","category":"section"},{"location":"literate/warmstart_investigation/#Implementation-Notes","page":"Warm-Start Investigation for Circle Certification","title":"Implementation Notes","text":"The benchmark code is in docs/src/literate/benchmark_warmstart_circle.jl.\n\nKey functions:\n\ncertify_circle_cold() - BigFloat refinement, fresh SVD each point\ncertify_circle_cold_d64() - Double64 refinement\ncertify_circle_cold_mf() - MultiFloat refinement\ncertify_circle_float64() - Miyajima (ball arithmetic) certification","category":"section"},{"location":"literate/warmstart_investigation/#Floating-Point-Boundary-Case-(radius-ε_machine)","page":"Warm-Start Investigation for Circle Certification","title":"Floating-Point Boundary Case (radius ≤ ε_machine)","text":"","category":"section"},{"location":"literate/warmstart_investigation/#The-Problem","page":"Warm-Start Investigation for Circle Certification","title":"The Problem","text":"When the circle radius is at or below machine precision (r ≤ 1e-16):\n\nAll points z = center + r·e^{iθ} round to the same Float64 value as the center\nFloat64 SVD gives the same result for all points\nWe lose the ability to distinguish points on the circle","category":"section"},{"location":"literate/warmstart_investigation/#Proposed-Solution:-BigFloat-Center","page":"Warm-Start Investigation for Circle Certification","title":"Proposed Solution: BigFloat Center","text":"If the center is represented in BigFloat with sufficient precision:\n\ncenter_bf = BigFloat(\"1.0\")  # Exact\nradius = BigFloat(\"1e-20\")   # Sub-machine-precision radius\nz_bf = center_bf + radius * exp(im * θ)  # Distinct in BigFloat\n\nAlgorithm for sub-ε circles:\n\nRepresent center and radius in BigFloat\nCompute A - z*I in BigFloat precision\nFor initial SVD approximation:\nOption A: Compute SVD at nearest Float64 point, then refine\nOption B: Use BigFloat SVD directly (slower but more robust)\nApply Ogita refinement in BigFloat\nCertify with ball arithmetic","category":"section"},{"location":"literate/warmstart_investigation/#Key-Insight","page":"Warm-Start Investigation for Circle Certification","title":"Key Insight","text":"At Float64 boundary, the initial SVD approximation comes from the center point:\n\nA - z_bf*I ≈ A - center*I in Float64\nThe Float64 SVD of A - center*I serves as initial guess for ALL points\nOgita refinement corrects the O(r) perturbation\n\nThis is similar to warm-start but forced by precision limits - all points share the same Float64 approximation, refined individually in BigFloat.","category":"section"},{"location":"literate/warmstart_investigation/#Experimental-Verification","page":"Warm-Start Investigation for Circle Certification","title":"Experimental Verification","text":"We tested certification at radius = 1e-16 (machine precision) near the eigenvalue cluster.\n\nTest setup:\n\nCenter: z = 1.02 (just outside eigenvalue cluster at 1.0 ± 0.02)\nRadius: 1e-16 (machine precision)\n8 points on the circle\nFloat64 SVD at center gives σ_min ≈ 2.9e-16 (essentially meaningless)\n\nResults: BigFloat Ogita refinement successfully distinguishes all 8 points:\n\nPoint σ_min (BigFloat)\n1 3.089e-18\n2 3.318e-18\n3 3.815e-18\n4 4.254e-18\n5 4.424e-18\n6 4.254e-18\n7 3.815e-18\n8 3.318e-18\n\nKey metrics:\n\nσ_min variation: 1.33e-18 (Max - Min)\nRelative variation: 43% across the circle\nResiduals: ~1e-75 (converged to full BigFloat precision)","category":"section"},{"location":"literate/warmstart_investigation/#Sub-Machine-Precision-Differences","page":"Warm-Start Investigation for Circle Certification","title":"Sub-Machine-Precision Differences","text":"Testing whether Ogita can distinguish points that differ by 1e-20:\n\nz1 = 1.02 + 0i\nz2 = 1.02 + 1e-20 + 0i\nSame Float64? YES (both round to 1.02)\n\nResults:\n\nz1: σ_min = 6.6725e-19\nz2: σ_min = 6.6688e-19\nDifference: 0.06% (distinguishable!)","category":"section"},{"location":"literate/warmstart_investigation/#Precision-Requirements","page":"Warm-Start Investigation for Circle Certification","title":"Precision Requirements","text":"Testing what BigFloat precision is needed to resolve 1e-18 differences:\n\n| Precision | max|A₁ - A₂| | |–––––-|––––––––| | 64 bits | 9.76e-19 | | 128 bits | 1.00e-18 | | 256 bits | 1.00e-18 | | 512 bits | 1.00e-18 |\n\nConclusion: 64 bits (~19 decimal digits) is sufficient to represent 1e-18 differences. Standard 256-bit BigFloat provides ample headroom.","category":"section"},{"location":"literate/warmstart_investigation/#Float64-Collapse-Threshold","page":"Warm-Start Investigation for Circle Certification","title":"Float64 Collapse Threshold","text":"Testing when Float64 representations become identical (pure real points):\n\nRadius Distinct Float64 values\n1e-14 5/8\n1e-15 5/8\n1e-16 1/8\n1e-17 1/8\n1e-18 1/8\n\nAt radius ≤ 1e-16, all real-axis points collapse to the same Float64 value. Complex points may remain distinct due to imaginary part encoding.","category":"section"},{"location":"literate/warmstart_investigation/#Validated-Algorithm","page":"Warm-Start Investigation for Circle Certification","title":"Validated Algorithm","text":"For sub-ε circles, the following algorithm is proven to work:\n\n# 1. Setup in BigFloat\nsetprecision(BigFloat, 256)\ncenter_bf = Complex{BigFloat}(BigFloat(\"1.02\"), BigFloat(\"0.0\"))\nradius_bf = BigFloat(\"1e-16\")\n\n# 2. Generate points in BigFloat\nθs = [BigFloat(2π * k / n) for k in 0:n-1]\nzs_bf = [center_bf + radius_bf * exp(im * θ) for θ in θs]\n\n# 3. Get initial SVD from center (Float64)\nA_center = Complex{Float64}.(T) - Float64.(center_bf) * I\nU_init, S_init, V_init = svd(A_center)\n\n# 4. Certify each point with BigFloat Ogita\nfor z in zs_bf\n    A_bf = T_bf - z * I\n    U_bf = convert.(Complex{BigFloat}, U_init)\n    S_bf = convert.(BigFloat, S_init)\n    V_bf = convert.(Complex{BigFloat}, V_init)\n\n    result = ogita_svd_refine(A_bf, U_bf, S_bf, V_bf;\n                              max_iterations=5, precision_bits=256)\n    # Each point gets distinct, accurate σ_min\nend","category":"section"},{"location":"literate/warmstart_investigation/#When-to-Use-Double64-vs-BigFloat","page":"Warm-Start Investigation for Circle Certification","title":"When to Use Double64 vs BigFloat","text":"Condition Use Double64? Use BigFloat?\nσ_min > 1e-10 ✓ (10-30x faster) Optional\n1e-14 < σ_min < 1e-10 ✓ (works) Safer\nσ_min < 1e-14 ✗ (residual too large) Required\nSub-ε radius, far from spectrum ✓ (works) Optional\nSub-ε radius, near spectrum ✗ (fails) Required\n\nKey insight: The limiting factor is not representing sub-ε differences (Double64 can handle 1e-32), but achieving small enough residual. Double64 residual ≈ 1e-13, BigFloat ≈ 1e-77.\n\nPractical guideline:\n\nIf Float64 σ_min at center > 1e-12: Double64 is safe\nIf Float64 σ_min at center < 1e-12: Use BigFloat\nWhen in doubt: Use BigFloat (correct but slower)","category":"section"},{"location":"literate/warmstart_investigation/#Resolved-Questions","page":"Warm-Start Investigation for Circle Certification","title":"Resolved Questions","text":"Optimal precision cascade: Float64 → Double64 → BigFloat, or skip Double64?\nAnswer: Depends on σmin. For σmin > 1e-10, Double64 provides 10-20x speedup.\nFor σ_min < 1e-14 (near eigenvalues), skip Double64 and use BigFloat directly.\nWarm-start at BigFloat level: Does reusing BigFloat SVD between adjacent points help?\nAnswer: No. The O(|Δz|) error from warm-start defeats Ogita's quadratic convergence.\nAdaptive radius: Automatically detect when radius < ε and switch to BigFloat workflow?\nAnswer: Yes, this is needed. When radius < 1e-16 * |center|, switch to BigFloat center.","category":"section"},{"location":"literate/warmstart_investigation/#Open-Questions","page":"Warm-Start Investigation for Circle Certification","title":"Open Questions","text":"Integration with adaptive circle splitting: How does sub-ε certification interact with the adaptive refinement in CertifScripts? Should we add a minimum radius threshold?\nPerformance at sub-ε: Is there a faster algorithm when all points share the same Float64 approximation? (Currently we compute the same center SVD n times.)","category":"section"},{"location":"literate/warmstart_investigation/#References","page":"Warm-Start Investigation for Circle Certification","title":"References","text":"Ogita & Aishima (2020): \"Iterative refinement for singular value decomposition\"\nBini, Gemignani et al.: Work on tracking eigenvalues through crossings\nRump & Ogita (2024): Verified SVD computation","category":"section"},{"location":"pseudospectra/#Pseudospectra-Certification","page":"Pseudospectra","title":"Pseudospectra Certification","text":"This page documents the CertifScripts module for rigorous pseudospectrum computation.","category":"section"},{"location":"pseudospectra/#Overview","page":"Pseudospectra","title":"Overview","text":"The pseudospectrum certification tools compute rigorous resolvent bounds along contours in the complex plane. This is useful for:\n\nVerifying spectral gaps\nComputing pseudospectral radii\nStability analysis of matrices\n\nThe certification uses adaptive arc refinement to efficiently sample the contour, with several execution modes optimized for different scenarios.","category":"section"},{"location":"pseudospectra/#Basic-Usage","page":"Pseudospectra","title":"Basic Usage","text":"The main entry point is run_certification, which takes a matrix and a CertificationCircle defining the contour.\n\nUse compute_schur_and_error to precompute the Schur decomposition and backward error, which is then passed to the certification routine.","category":"section"},{"location":"pseudospectra/#Execution-Modes","page":"Pseudospectra","title":"Execution Modes","text":"","category":"section"},{"location":"pseudospectra/#Serial-Mode-(Float64)","page":"Pseudospectra","title":"Serial Mode (Float64)","text":"The basic serial mode computes SVD at each sample point in Float64 precision. Suitable for moderate-sized problems and contours not too close to the spectrum.","category":"section"},{"location":"pseudospectra/#Parallel-Mode-(Distributed.jl)","page":"Pseudospectra","title":"Parallel Mode (Distributed.jl)","text":"For large problems, certification can be parallelized across multiple Julia workers. Load the Distributed extension:\n\nusing BallArithmetic, Distributed\nusing BallArithmetic.CertifScripts\n\naddprocs(4)  # Add 4 workers\nresult = run_certification(A, circle, workers())\n\nThe parallel extension provides:\n\nAutomatic worker management via dowork\nJob distribution via channels\nCheckpoint/snapshot support via save_snapshot! and choose_snapshot_to_load","category":"section"},{"location":"pseudospectra/#Cached-Ogita-Mode","page":"Pseudospectra","title":"Cached Ogita Mode","text":"When consecutive sample points are close together (which happens naturally during adaptive bisection), we can reuse SVD information via Ogita's iterative refinement. This provides approximately 2x speedup for adaptive certification.\n\nUse run_certification_ogita for this mode.\n\nThe caching system tracks SVD results at sample points and reuses them for nearby points. This is particularly effective during adaptive arc refinement via adaptive_arcs!.\n\nWorker functions for distributed Ogita mode:\n\ndowork_ogita - Float64 precision worker\ndowork_ogita_bigfloat - BigFloat precision worker","category":"section"},{"location":"pseudospectra/#BigFloat-Precision-Mode","page":"Pseudospectra","title":"BigFloat Precision Mode","text":"For contours very close to the spectrum (resolvent bounds > 10^15), Float64 precision is insufficient. The BigFloat mode uses:\n\nCompute Float64 SVD as initial approximation\nRefine to BigFloat precision using Ogita's algorithm\nDue to quadratic convergence, 4 iterations from Float64 saturate 256-bit precision\n\nThis mode is essential when verifying tight spectral gaps or computing pseudospectral radii near eigenvalues.","category":"section"},{"location":"pseudospectra/#When-to-Use-Each-Mode","page":"Pseudospectra","title":"When to Use Each Mode","text":"Scenario Recommended Mode\nModerate resolvent (< 10^8) Serial Float64\nLarge matrix, moderate resolvent Parallel Float64\nTight contour, resolvent 10^8 - 10^15 Cached Ogita\nVery tight contour, resolvent > 10^15 BigFloat Ogita","category":"section"},{"location":"pseudospectra/#Helper-Functions","page":"Pseudospectra","title":"Helper Functions","text":"Additional utility functions:\n\npoints_on - Generate sample points on circle\nset_schur_matrix! - Configure Schur matrix\nconfigure_certification! - Set up certification parameters\nbound_res_original - Compute resolvent bound\npoly_from_roots - Construct polynomial from roots","category":"section"},{"location":"API/#API-Reference","page":"Overview","title":"API Reference","text":"This section contains the complete API reference for BallArithmetic.jl, organized by functionality.","category":"section"},{"location":"API/#Pages","page":"Overview","title":"Pages","text":"Core Types - Ball, BallArray, BallMatrix, BallVector, and norm bounds\nLinear Systems - Verified linear system solvers\nEigenvalues & SVD - Eigenvalue and singular value computation\nCertifScripts - Pseudospectra certification\nNumericalTest - Testing utilities\n\n","category":"section"},{"location":"api/numericaltest/#API-NumericalTest","page":"NumericalTest","title":"API - NumericalTest","text":"Testing utilities for verifying floating-point rounding behavior.","category":"section"},{"location":"api/numericaltest/#BallArithmetic.NumericalTest.rounding_test","page":"NumericalTest","title":"BallArithmetic.NumericalTest.rounding_test","text":"rounding_test(n, k)\n\nLet u=fill(2^(-53), k-1) and let A be the matrix [I u; 0 2^(-53)]\n\nThis test checks the result of A*A' in different rounding modes, running BLAS on n threads\n\n\n\n\n\n","category":"function"},{"location":"decompositions/#Certified-Matrix-Decompositions","page":"Matrix Decompositions","title":"Certified Matrix Decompositions","text":"BallArithmetic.jl provides rigorous certification for several matrix decompositions. Each method computes both a numerical approximation and a rigorous error bound.","category":"section"},{"location":"decompositions/#Overview","page":"Matrix Decompositions","title":"Overview","text":"Decomposition Function Description\nSVD ogita_svd_refine Singular value decomposition\nSVD Cascade ogita_svd_cascade Multi-precision SVD cascade\nSVD (GLA) ogita_svd_cascade_gla Native BigFloat SVD\nSchur iterative_schur_refinement Schur form\nLU verified_lu LU factorization\nCholesky verified_cholesky Cholesky factorization\nQR verified_qr QR factorization\nPolar verified_polar Polar decomposition\nTakagi verified_takagi Takagi factorization","category":"section"},{"location":"decompositions/#Recommended-Extensions","page":"Matrix Decompositions","title":"Recommended Extensions","text":"BallArithmetic supports several extension packages that provide different performance characteristics:\n\nExtension Package Use Case\nGenericLinearAlgebra GenericLinearAlgebra.jl Recommended - Native BigFloat SVD, fastest and most accurate\nMultiFloats MultiFloats.jl SIMD-accelerated multi-precision (Float64x2, Float64x4)\nDoubleFloats DoubleFloats.jl Fast Double64 arithmetic (~106 bits)","category":"section"},{"location":"decompositions/#SVD-Certification-Methods","page":"Matrix Decompositions","title":"SVD Certification Methods","text":"The SVD is fundamental for resolvent norm certification and condition number estimation. We provide multiple methods with different speed/accuracy trade-offs.","category":"section"},{"location":"decompositions/#Method-Comparison","page":"Matrix Decompositions","title":"Method Comparison","text":"All benchmarks performed on:\n\nCPU: AMD Ryzen 5 5600 6-Core Processor\nRAM: 128 GB\nJulia: 1.11+\nBigFloat precision: 256 bits","category":"section"},{"location":"decompositions/#Small-Matrix-(100100)","page":"Matrix Decompositions","title":"Small Matrix (100×100)","text":"Method Time Non-rigorous Residual Rigorous σ_min Bound Speedup\nGLA (no refine) 4.2s 4×10⁻⁷⁴ ✓ 6.6×\nD64 cascade (F64→D64→BF) 11.7s 1×10⁻¹² ✓ 2.4×\nMinimal cascade (F64→MF3→BF) 12.2s 1×10⁻¹² ✓ 2.3×\nFull cascade (F64→D64→MF3→MF4→BF) 15.0s 1×10⁻¹³ ✓ 1.8×\nPure Ogita (F64→BF×5) 27.7s 1×10⁻¹² ✓ 1.0×\n\nKey observations:\n\nGLA achieves 60+ orders of magnitude better residual than cascade methods\nGLA is 6.6× faster than pure Ogita refinement\nAll methods produce valid rigorous bounds for σ_min\nSimpler cascades (D64 only) outperform complex multi-level cascades","category":"section"},{"location":"decompositions/#Medium-Matrix-(200200)","page":"Matrix Decompositions","title":"Medium Matrix (200×200)","text":"Method Time Non-rigorous Residual Rigorous Bound Speedup\nCascade (F64→D64→MF3→MF4→BF×2) 196s 3.3×10⁻¹² ✓ 2.1×\nPure Ogita (F64→BF×5) 407s 5.0×10⁻¹² ✓ 1.0×","category":"section"},{"location":"decompositions/#Large-Matrix-(500500)","page":"Matrix Decompositions","title":"Large Matrix (500×500)","text":"Method Time Non-rigorous Residual Rigorous Bound Speedup\nCascade (F64→D64→MF3→MF4→BF×2) 3234s 1.4×10⁻¹¹ ✓ 1.9×\nPure Ogita (F64→BF×5) 6279s 1.6×10⁻¹¹ ✓ 1.0×","category":"section"},{"location":"decompositions/#Recommendations","page":"Matrix Decompositions","title":"Recommendations","text":"Use GenericLinearAlgebra when available:\nusing BallArithmetic, GenericLinearAlgebra\n\nT_bf = Complex{BigFloat}.(T)\nz_bf = Complex{BigFloat}(z)\nresult = ogita_svd_cascade_gla(T_bf, z_bf)\n\n# result.σ_min is a rigorous lower bound\n# result.residual_norm is the non-rigorous residual\nWithout GLA, use the simple D64 cascade:\nusing BallArithmetic, MultiFloats, DoubleFloats\n\nresult = ogita_svd_cascade(T_bf, z_bf;\n    f64_iters=1, d64_iters=1, mf3_iters=0, mf4_iters=0, bf_iters=2)\nFor pure BigFloat (no extensions):\nusing BallArithmetic\n\nresult = ogita_svd_refine(A, U, Σ, V; max_iterations=5)","category":"section"},{"location":"decompositions/#Rigorous-vs-Non-Rigorous-Results","page":"Matrix Decompositions","title":"Rigorous vs Non-Rigorous Results","text":"Each decomposition method returns:\n\nNon-rigorous residual: The computed ‖A - UΣVᴴ‖_F using standard floating-point\nRigorous bound: A mathematically guaranteed upper bound on the true error\n\nThe rigorous bound accounts for:\n\nRounding errors in all computations\nPotential instabilities in the algorithm\nAccumulated error from multiple operations\n\nFor certification purposes, always use the rigorous bound.","category":"section"},{"location":"decompositions/#Other-Matrix-Decompositions-(100100-Matrix)","page":"Matrix Decompositions","title":"Other Matrix Decompositions (100×100 Matrix)","text":"Beyond SVD, BallArithmetic provides verified versions of standard matrix decompositions.","category":"section"},{"location":"decompositions/#Standard-(Float64-BigFloat)","page":"Matrix Decompositions","title":"Standard (Float64 → BigFloat)","text":"These use Float64 computation with BigFloat certification:\n\nDecomposition Time Residual Norm Rigorous Bound\nCholesky (SPD) 1.7s 2.7×10⁻¹⁶ ✓\nQR 2.1s 3.1×10⁻¹⁵ ✓\nPolar 3.3s 4.8×10⁻¹⁶ ✓\nLU 5.6s 1.3×10⁻¹⁴ ✓\nTakagi 10.3s 1.7×10⁻¹⁵ ✓","category":"section"},{"location":"decompositions/#GLA-Based-(Native-BigFloat)","page":"Matrix Decompositions","title":"GLA-Based (Native BigFloat)","text":"With GenericLinearAlgebra, we achieve 60+ orders of magnitude better residuals:\n\nDecomposition Time Residual Norm Improvement\nCholesky (GLA) 0.55s 5.2×10⁻⁷⁴ 10⁵⁸× better\nLU (GLA) 0.91s 5.9×10⁻⁷⁵ 10⁶¹× better\nQR (GLA) 0.91s 5.4×10⁻⁷⁵ 10⁶⁰× better\nSVD (GLA) 5.15s 4.5×10⁻⁷⁴ 10⁶⁰× better\n\nGLA functions:\n\nusing BallArithmetic, GenericLinearAlgebra\n\nresult_lu = verified_lu_gla(A)        # ~10⁻⁷⁵ residual\nresult_qr = verified_qr_gla(A)        # ~10⁻⁷⁵ residual\nresult_chol = verified_cholesky_gla(A_spd)  # ~10⁻⁷⁴ residual\n(U, S, V, res) = verified_svd_gla(A)  # ~10⁻⁷⁴ residual\n\nUsage examples:\n\nusing BallArithmetic\nusing LinearAlgebra\n\nA = randn(100, 100) + 5I\n\n# LU decomposition\nresult_lu = verified_lu(A)\n# result_lu.L, result_lu.U are BallMatrix enclosures\n# result_lu.residual_norm is the rigorous error bound\n\n# QR decomposition\nresult_qr = verified_qr(A)\n# result_qr.Q, result_qr.R are BallMatrix enclosures\n# result_qr.orthogonality_defect bounds ‖QᴴQ - I‖\n\n# Cholesky (for symmetric positive definite)\nA_spd = A'A + 100I\nresult_chol = verified_cholesky(A_spd)\n# result_chol.L is the lower Cholesky factor\n\n# Polar decomposition A = UH\nresult_polar = verified_polar(A)\n# result_polar.U (unitary), result_polar.H (Hermitian positive semidefinite)\n\n# Takagi factorization (for complex symmetric)\nA_symm = A + transpose(A)\nresult_takagi = verified_takagi(A_symm)\n# A = U Σ Uᵀ (not Uᴴ!)","category":"section"},{"location":"decompositions/#Iterative-Refinement-Methods","page":"Matrix Decompositions","title":"Iterative Refinement Methods","text":"For decompositions not supported by GLA, we provide iterative refinement using extended precision arithmetic.","category":"section"},{"location":"decompositions/#Float64-Iterative-Refinement-(5-iterations)","page":"Matrix Decompositions","title":"Float64 Iterative Refinement (5 iterations)","text":"Decomposition Time Residual Orthogonality Defect\nCholesky 0.97s 8.9×10⁻¹⁷ N/A\nQR (CholQR2) 0.12s 6.8×10⁻¹⁶ 2.8×10⁻¹⁵\nLU 0.96s 1.5×10⁻¹⁵ N/A\nPolar (Newton-Schulz) 0.22s 1.4×10⁻¹⁵ 2.1×10⁻¹⁵","category":"section"},{"location":"decompositions/#Double64-Iterative-Refinement-(5-iterations)","page":"Matrix Decompositions","title":"Double64 Iterative Refinement (5 iterations)","text":"Double64 provides ~106 bits of precision, dramatically improving orthogonality:\n\nDecomposition Time Residual Orthogonality Defect\nCholesky 0.90s 7.2×10⁻¹⁸ N/A\nQR (CholQR2) 1.69s 7.1×10⁻¹⁶ 2.1×10⁻³¹\nLU 4.53s 1.2×10⁻¹⁵ N/A\nPolar (Newton-Schulz) 2.76s 1.3×10⁻¹⁵ 2.0×10⁻³¹\n\nKey observation: Double64 achieves 16 orders of magnitude better orthogonality for QR and Polar decompositions, while residuals remain similar (limited by Float64 input precision).\n\nUsage:\n\nusing BallArithmetic, DoubleFloats, LinearAlgebra\n\nA = randn(100, 100) + 5I\nF_qr = qr(A)\n\n# Float64 refinement\nresult_f64 = refine_qr_cholqr2(A, Matrix(F_qr.Q), Matrix(F_qr.R); max_iterations=5)\n\n# Double64 refinement (better orthogonality)\nresult_d64 = refine_qr_double64(A, Matrix(F_qr.Q), Matrix(F_qr.R);\n    method=:cholqr2, max_iterations=5)\n\n# Polar refinement\nF_svd = svd(A)\nQ0 = F_svd.U * F_svd.Vt\nresult_polar = refine_polar_double64(A, Q0; method=:newton_schulz, max_iterations=10)","category":"section"},{"location":"decompositions/#Schur-Complement-Bounds-(Oishi-2023-/-Rump-Oishi-2024)","page":"Matrix Decompositions","title":"Schur Complement Bounds (Oishi 2023 / Rump-Oishi 2024)","text":"For block-structured matrices, the Schur complement method provides efficient σ_min bounds:\n\nresult = rump_oishi_2024_sigma_min_bound(G; block_size=m)\n\nThis implements:\n\nOishi 2023: Base Schur complement algorithm\nRump-Oishi 2024: Improved ψ(N) formula that works for ‖N‖ ≥ 1\n\nKey advantages:\n\nWorks on matrices too large for full SVD\nExploits block diagonal dominance structure\nAutomatic optimal block size selection","category":"section"},{"location":"decompositions/#References","page":"Matrix Decompositions","title":"References","text":"Ogita, T. & Aishima, K. (2020), \"Iterative refinement for singular value decomposition based on matrix multiplication\"\nRump, S.M. & Ogita, S. (2024), \"A Note on Oishi's Lower Bound for the Smallest Singular Value of Linearized Galerkin Equations\"\nOishi, S. (2023), \"Lower bounds for the smallest singular values of generalized asymptotic diagonal dominant matrices\"","category":"section"},{"location":"#BallArithmetic","page":"Home","title":"BallArithmetic","text":"Documentation for BallArithmetic.\n\nIn this package we use the tecniques first introduced in Ref. [1], following the more recent work Ref. [2] to implement a rigorous matrix product in mid-radius arithmetic.\n\nThis allows to implement numerous algorithms developed by Rump, Miyajima, Ogita and collaborators to obtain a posteriori guaranteed bounds.\n\nThe main object are BallMatrices, i.e., midpoint matrices equipped with non-negative radii that provide rigorous entrywise enclosures.","category":"section"},{"location":"#Sylvester-equations","page":"Home","title":"Sylvester equations","text":"sylvester_miyajima_enclosure provides a componentwise enclosure for solutions of the Sylvester equation following the fast verification method of Ref. [3].  When the data originate from an upper triangular Schur factor T, triangular_sylvester_miyajima_enclosure extracts the blocks T₁₁, T₁₂, and T₂₂, solves the associated Sylvester system T₂₂' Y₂ - Y₂ T₁₁' = T₁₂', and returns the Miyajima enclosure for the unknown block Y₂.","category":"section"},{"location":"#BallMatrix","page":"Home","title":"BallMatrix","text":"BallMatrix is the midpoint-radius companion of the scalar Ball type.  The midpoint matrix stores the approximation we would normally compute in floating-point arithmetic, whereas the radius matrix captures all sources of uncertainty (input radii, floating-point error, subnormal padding, …).  Each method documented below updates both components so the result remains a rigorous enclosure.","category":"section"},{"location":"#Constructors-and-accessors","page":"Home","title":"Constructors and accessors","text":"The constructors delegate to the underlying BallArray to perform shape and type validation.  Working through them in order provides a tour of how the storage is organised:","category":"section"},{"location":"#Arithmetic","page":"Home","title":"Arithmetic","text":"Binary operations follow a common pattern: operate on the midpoint data as if the values were exact, then grow the radius using outward rounding. The comments inside src/types/matrix.jl walk through the steps in more detail.\n\nusing BallArithmetic\nA = ones((2, 2))\nbA = BallMatrix(A, A/128)\nbA^2","category":"section"},{"location":"#Rounding-mode-controlled-products","page":"Home","title":"Rounding-mode controlled products","text":"Some matrix enclosures benefit from explicitly steering the floating-point rounding mode.  The wrapper BallArithmetic.oishi_MMul implements the Oishi–Rump product, which evaluates the real and imaginary parts of F*G with downward and upward rounding and returns the result as a BallMatrix.  The routine is particularly useful when replicating the eigenvalue and singular value enclosures described in Ref. [4].\n\nInternally we also expose the auxiliary kernels from Ref. [5].  The helpers _ccrprod, _cr, _iprod, and _ciprod implement Algorithms 4–7 and propagate rectangular or ball bounds through matrix products.  They are available for advanced workflows that need direct access to the underlying interval data.\n\nusing BallArithmetic\nsetprecision(BigFloat, 128) do\n    F = Complex{BigFloat}[1 + im 2; 3 - im 4]\n    G = Complex{BigFloat}[2 - im 1; -1 3 + im]\n    B = BallArithmetic.oishi_MMul(F, G)\n    (mid(B), rad(B))\nend","category":"section"}]
}
